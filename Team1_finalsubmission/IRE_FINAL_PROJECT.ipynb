{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wrLDIxGM31s",
        "outputId": "cd6d743a-5e36-4905-aa3c-370e61f25cb8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\pchhl\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers -q\n",
        "!pip install language_tool_python -q\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import nltk\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from torch import tensor\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "# AdamW\n",
        "import tqdm\n",
        "import numpy as np\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from transformers import BertTokenizer, BertModel, AdamW\n",
        "import random\n",
        "import sklearn\n",
        "import language_tool_python\n",
        "tool = language_tool_python.LanguageTool('en-US')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xISgEr5YZRub"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4gXEel0o7IY"
      },
      "source": [
        "### BERT EMBEDDINGS USING INBUILT FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK1QcZRIg3Sz",
        "outputId": "b8245bad-7712-4d3b-8fae-e5f68b8e818b"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "y8OlERAX24Cs"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers\n",
        "# from transformers import BertModel, BertTokenizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_name = \"bert-base-uncased\"\n",
        "model = BertModel.from_pretrained(model_name).to(device)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wm-Of-NkpHtK"
      },
      "source": [
        "### READING FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUtvVsuHPeI2",
        "outputId": "b13deaf0-87b8-4e8e-aad2-83358dfdd3c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['essay_id', 'essay_set', 'essay', 'rater1_domain1', 'rater2_domain1',\n",
              "       'rater3_domain1', 'domain1_score', 'rater1_domain2', 'rater2_domain2',\n",
              "       'domain2_score', 'rater1_trait1', 'rater1_trait2', 'rater1_trait3',\n",
              "       'rater1_trait4', 'rater1_trait5', 'rater1_trait6', 'rater2_trait1',\n",
              "       'rater2_trait2', 'rater2_trait3', 'rater2_trait4', 'rater2_trait5',\n",
              "       'rater2_trait6', 'rater3_trait1', 'rater3_trait2', 'rater3_trait3',\n",
              "       'rater3_trait4', 'rater3_trait5', 'rater3_trait6'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "content=r\"C:\\Users\\pchhl\\Downloads\\training_set_rel3.xls\\training_set_rel3.xls\"\n",
        "\n",
        "df = pd.read_excel(content)\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "pHFIpFUJcfCu",
        "outputId": "39410bd5-af85-4d0b-f777-57153f62deda"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>rater1_domain1</th>\n",
              "      <th>rater2_domain1</th>\n",
              "      <th>rater3_domain1</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>rater1_domain2</th>\n",
              "      <th>rater2_domain2</th>\n",
              "      <th>domain2_score</th>\n",
              "      <th>...</th>\n",
              "      <th>rater2_trait3</th>\n",
              "      <th>rater2_trait4</th>\n",
              "      <th>rater2_trait5</th>\n",
              "      <th>rater2_trait6</th>\n",
              "      <th>rater3_trait1</th>\n",
              "      <th>rater3_trait2</th>\n",
              "      <th>rater3_trait3</th>\n",
              "      <th>rater3_trait4</th>\n",
              "      <th>rater3_trait5</th>\n",
              "      <th>rater3_trait6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear local newspaper, I think effects computer...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   essay_id  essay_set                                              essay  \\\n",
              "0         1          1  Dear local newspaper, I think effects computer...   \n",
              "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
              "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
              "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
              "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
              "\n",
              "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
              "0             4.0             4.0             NaN            8.0   \n",
              "1             5.0             4.0             NaN            9.0   \n",
              "2             4.0             3.0             NaN            7.0   \n",
              "3             5.0             5.0             NaN           10.0   \n",
              "4             4.0             4.0             NaN            8.0   \n",
              "\n",
              "   rater1_domain2  rater2_domain2  domain2_score  ...  rater2_trait3  \\\n",
              "0             NaN             NaN            NaN  ...            NaN   \n",
              "1             NaN             NaN            NaN  ...            NaN   \n",
              "2             NaN             NaN            NaN  ...            NaN   \n",
              "3             NaN             NaN            NaN  ...            NaN   \n",
              "4             NaN             NaN            NaN  ...            NaN   \n",
              "\n",
              "   rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  rater3_trait2  \\\n",
              "0            NaN            NaN            NaN            NaN            NaN   \n",
              "1            NaN            NaN            NaN            NaN            NaN   \n",
              "2            NaN            NaN            NaN            NaN            NaN   \n",
              "3            NaN            NaN            NaN            NaN            NaN   \n",
              "4            NaN            NaN            NaN            NaN            NaN   \n",
              "\n",
              "   rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
              "0            NaN            NaN            NaN            NaN  \n",
              "1            NaN            NaN            NaN            NaN  \n",
              "2            NaN            NaN            NaN            NaN  \n",
              "3            NaN            NaN            NaN            NaN  \n",
              "4            NaN            NaN            NaN            NaN  \n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCMB4yV-pOX2"
      },
      "source": [
        "### FILE INFO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxQjrGOXjw03",
        "outputId": "a6edee27-1261-4e9c-b540-595791b32f1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 12978 entries, 0 to 12977\n",
            "Data columns (total 28 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   essay_id        12978 non-null  int64  \n",
            " 1   essay_set       12978 non-null  int64  \n",
            " 2   essay           12978 non-null  object \n",
            " 3   rater1_domain1  12977 non-null  float64\n",
            " 4   rater2_domain1  12977 non-null  float64\n",
            " 5   rater3_domain1  128 non-null    float64\n",
            " 6   domain1_score   12977 non-null  float64\n",
            " 7   rater1_domain2  1800 non-null   float64\n",
            " 8   rater2_domain2  1800 non-null   float64\n",
            " 9   domain2_score   1800 non-null   float64\n",
            " 10  rater1_trait1   2292 non-null   float64\n",
            " 11  rater1_trait2   2292 non-null   float64\n",
            " 12  rater1_trait3   2292 non-null   float64\n",
            " 13  rater1_trait4   2292 non-null   float64\n",
            " 14  rater1_trait5   723 non-null    float64\n",
            " 15  rater1_trait6   723 non-null    float64\n",
            " 16  rater2_trait1   2292 non-null   float64\n",
            " 17  rater2_trait2   2292 non-null   float64\n",
            " 18  rater2_trait3   2292 non-null   float64\n",
            " 19  rater2_trait4   2292 non-null   float64\n",
            " 20  rater2_trait5   723 non-null    float64\n",
            " 21  rater2_trait6   723 non-null    float64\n",
            " 22  rater3_trait1   128 non-null    float64\n",
            " 23  rater3_trait2   128 non-null    float64\n",
            " 24  rater3_trait3   128 non-null    float64\n",
            " 25  rater3_trait4   128 non-null    float64\n",
            " 26  rater3_trait5   128 non-null    float64\n",
            " 27  rater3_trait6   128 non-null    float64\n",
            "dtypes: float64(25), int64(2), object(1)\n",
            "memory usage: 2.8+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "ERW2p3QcOkYf",
        "outputId": "4ac7675f-d2db-4705-dd6b-c546c2bbd108"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Dear local newspaper, I think effects computers have on people are great learning skills/affects because they give us time to chat with friends/new people, helps us learn about the globe(astronomy) and keeps us out of troble! Thing about! Dont you think so? How would you feel if your teenager is always on the phone with friends! Do you ever time to chat with your friends or buisness partner about things. Well now - there's a new way to chat the computer, theirs plenty of sites on the internet to do so: @ORGANIZATION1, @ORGANIZATION2, @CAPS1, facebook, myspace ect. Just think now while your setting up meeting with your boss on the computer, your teenager is having fun on the phone not rushing to get off cause you want to use it. How did you learn about other countrys/states outside of yours? Well I have by computer/internet, it's a new way to learn about what going on in our time! You might think your child spends a lot of time on the computer, but ask them so question about the economy, sea floor spreading or even about the @DATE1's you'll be surprise at how much he/she knows. Believe it or not the computer is much interesting then in class all day reading out of books. If your child is home on your computer or at a local library, it's better than being out with friends being fresh, or being perpressured to doing something they know isnt right. You might not know where your child is, @CAPS2 forbidde in a hospital bed because of a drive-by. Rather than your child on the computer learning, chatting or just playing games, safe and sound in your home or community place. Now I hope you have reached a point to understand and agree with me, because computers can have great effects on you or child because it gives us time to chat with friends/new people, helps us learn about the globe and believe or not keeps us out of troble. Thank you for listening.\""
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['essay'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFE6dzuipRxc"
      },
      "source": [
        "### ESSAY PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fs35Y5pkQ2oa"
      },
      "outputs": [],
      "source": [
        "string.punctuation\n",
        "punct = string.punctuation\n",
        "punct = punct.replace('.', '')\n",
        "punct += '@'\n",
        "'.' in punct\n",
        "\n",
        "def get_lower(text):\n",
        "    return text.lower()\n",
        "\n",
        "def remove_punctuations(text):\n",
        "    return ''.join([char for char in text if char not in punct])\n",
        "\n",
        "def tokenize(text):\n",
        "    # text = text.strip()\n",
        "    return word_tokenize(text)\n",
        "\n",
        "def remove_alpha_numeric(sentence):\n",
        "    # return ' '.join(word for word in tokens if word.isalpha())\n",
        "    words = sentence.split()\n",
        "    alphabetic_words = [word for word in words if word.isalpha()]\n",
        "    return ' '.join(alphabetic_words)\n",
        "\n",
        "def remove_tags(text):\n",
        "    return BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "def remove_extra_gaps(text):\n",
        "    return ' '.join(text.split())\n",
        "\n",
        "def pipeline(text):\n",
        "    text = get_lower(text)\n",
        "    text = remove_punctuations(text)\n",
        "    # tokens = tokenize(text)\n",
        "    # text = remove_alpha_numeric(text)\n",
        "    # text = remove_tags(text)\n",
        "    text = remove_extra_gaps(text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tNM00SluS0o-"
      },
      "outputs": [],
      "source": [
        "df['essay'] = df['essay'].apply(pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "masTBZ1oTWwH",
        "outputId": "f4f0a68d-e86e-4cc0-ed72-d64f0d4a9da9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'dear caps1 caps2 i believe that using computers will benefit us in many ways like talking and becoming friends will others through websites like facebook and mysace. using computers can help us find coordibates locations and able ourselfs to millions of information. also computers will benefit us by helping with jobs as in planning a house plan and typing a num1 page report for one of our jobs in less than writing it. now lets go into the wonder world of technology. using a computer will help us in life by talking or making friends on line. many people have myspace facebooks aim these all benefit us by having conversations with one another. many people believe computers are bad but how can you make friends if you can never talk to them i am very fortunate for having a computer that can help with not only school work but my social life and how i make friends. computers help us with finding our locations coordibates and millions of information online. if we didnt go on the internet a lot we wouldnt know how to go onto websites that month1 help us with locations and coordinates like location1. would you rather use a computer or be in location3. when your supposed to be vacationing in location2. million of information is found on the internet. you can as almost every question and a computer will have it. would you rather easily draw up a house plan on the computers or take num1 hours doing one by hand with ugly erazer marks all over it you are garrenteed that to find a job with a drawing like that. also when appling for a job many workers must write very long papers like a num3 word essay on why this job fits you the most and many people i know dont like writing num3 words nonstopp for hours when it could take them i hav an a computer. that is why computers we needed a lot now adays. i hope this essay has impacted your descion on computers because they are great machines to work with. the other day i showed my mom how to use a computer and she said it was the greatest invention sense sliced bread now go out and buy a computer to help you chat online with friends find locations and millions of information on one click of the button and help your self with getting a job with neat prepared printed work that your boss will love.'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['essay'][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgvAaiBEUJW4",
        "outputId": "f36d3f3d-ea21-485f-d5cd-762e351c97e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3.0     2830\n",
              "2.0     2445\n",
              "1.0     1736\n",
              "4.0     1424\n",
              "8.0      737\n",
              "0.0      419\n",
              "9.0      383\n",
              "10.0     372\n",
              "16.0     199\n",
              "11.0     165\n",
              "7.0      163\n",
              "40.0     161\n",
              "17.0     160\n",
              "6.0      137\n",
              "12.0     133\n",
              "18.0     118\n",
              "14.0     105\n",
              "20.0     103\n",
              "24.0      99\n",
              "5.0       96\n",
              "19.0      88\n",
              "15.0      86\n",
              "13.0      82\n",
              "21.0      70\n",
              "36.0      65\n",
              "22.0      63\n",
              "23.0      53\n",
              "30.0      49\n",
              "35.0      47\n",
              "37.0      39\n",
              "34.0      39\n",
              "32.0      37\n",
              "31.0      34\n",
              "33.0      32\n",
              "45.0      31\n",
              "42.0      23\n",
              "41.0      22\n",
              "38.0      20\n",
              "43.0      15\n",
              "44.0      14\n",
              "50.0      13\n",
              "46.0      13\n",
              "28.0      11\n",
              "39.0       8\n",
              "29.0       8\n",
              "47.0       7\n",
              "27.0       6\n",
              "25.0       5\n",
              "26.0       4\n",
              "48.0       3\n",
              "55.0       2\n",
              "49.0       2\n",
              "60.0       1\n",
              "Name: domain1_score, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(df.domain1_score.value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "3g6PF_Qe24HV",
        "outputId": "31bdeb96-837c-4250-c87d-2e171ca0dee1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>rater1_domain1</th>\n",
              "      <th>rater2_domain1</th>\n",
              "      <th>rater3_domain1</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>rater1_domain2</th>\n",
              "      <th>rater2_domain2</th>\n",
              "      <th>domain2_score</th>\n",
              "      <th>...</th>\n",
              "      <th>rater2_trait3</th>\n",
              "      <th>rater2_trait4</th>\n",
              "      <th>rater2_trait5</th>\n",
              "      <th>rater2_trait6</th>\n",
              "      <th>rater3_trait1</th>\n",
              "      <th>rater3_trait2</th>\n",
              "      <th>rater3_trait3</th>\n",
              "      <th>rater3_trait4</th>\n",
              "      <th>rater3_trait5</th>\n",
              "      <th>rater3_trait6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>dear local newspaper i think effects computers...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>dear caps1 caps2 i believe that using computer...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>dear caps1 caps2 caps3 more and more people us...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>dear local newspaper caps1 i have found that m...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>dear location1 i know having computers has a p...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   essay_id  essay_set                                              essay  \\\n",
              "0         1          1  dear local newspaper i think effects computers...   \n",
              "1         2          1  dear caps1 caps2 i believe that using computer...   \n",
              "2         3          1  dear caps1 caps2 caps3 more and more people us...   \n",
              "3         4          1  dear local newspaper caps1 i have found that m...   \n",
              "4         5          1  dear location1 i know having computers has a p...   \n",
              "\n",
              "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
              "0             4.0             4.0             NaN            8.0   \n",
              "1             5.0             4.0             NaN            9.0   \n",
              "2             4.0             3.0             NaN            7.0   \n",
              "3             5.0             5.0             NaN           10.0   \n",
              "4             4.0             4.0             NaN            8.0   \n",
              "\n",
              "   rater1_domain2  rater2_domain2  domain2_score  ...  rater2_trait3  \\\n",
              "0             NaN             NaN            NaN  ...            NaN   \n",
              "1             NaN             NaN            NaN  ...            NaN   \n",
              "2             NaN             NaN            NaN  ...            NaN   \n",
              "3             NaN             NaN            NaN  ...            NaN   \n",
              "4             NaN             NaN            NaN  ...            NaN   \n",
              "\n",
              "   rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  rater3_trait2  \\\n",
              "0            NaN            NaN            NaN            NaN            NaN   \n",
              "1            NaN            NaN            NaN            NaN            NaN   \n",
              "2            NaN            NaN            NaN            NaN            NaN   \n",
              "3            NaN            NaN            NaN            NaN            NaN   \n",
              "4            NaN            NaN            NaN            NaN            NaN   \n",
              "\n",
              "   rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
              "0            NaN            NaN            NaN            NaN  \n",
              "1            NaN            NaN            NaN            NaN  \n",
              "2            NaN            NaN            NaN            NaN  \n",
              "3            NaN            NaN            NaN            NaN  \n",
              "4            NaN            NaN            NaN            NaN  \n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temp_df = df[df['domain1_score'] < 21]\n",
        "temp_df.reset_index(drop=True, inplace=True)\n",
        "temp_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8KW39rXpdWU"
      },
      "source": [
        "### HISTOGRAM WITH NUMBER OF ARTICLES WITH GIVEN FREQUENCY OF SENTENCE LENGTH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qP9Uo5bvxV_R"
      },
      "outputs": [],
      "source": [
        "ess = df['essay']\n",
        "maxi = 0\n",
        "d = {}\n",
        "for e in ess:\n",
        "  size = len(sent_tokenize(e))\n",
        "  if size in d:\n",
        "    d[size] += 1\n",
        "  else:\n",
        "    d[size] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "Qy3awbf4x6Lp",
        "outputId": "99acfcf5-e9fb-42be-b841-0c95f3637dd2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "keys = list(d.keys())\n",
        "values = list(d.values())\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Create bar chart\n",
        "plt.bar(keys, values, color='blue')\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Dictionary Visualization')\n",
        "plt.xlabel('Keys')\n",
        "plt.ylabel('Values')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvknq3Fz24K6",
        "outputId": "917466d9-f090-49b4-ee5f-67410c46d863"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[  101,  1045,  2097,  3422,  2033, 23065,  3892,  1012,  2079,   102]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_text = 'I will watch Memento tonight. Do you'\n",
        "bert_input = tokenizer(example_text,padding='max_length', max_length = 10,\n",
        "                       truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "print(bert_input['input_ids'])\n",
        "print(bert_input['token_type_ids'])\n",
        "print(bert_input['attention_mask'])\n",
        "tensor([[  101,   146,  1209,  2824,  2508, 26173,  3568,   102,     0,     0]])\n",
        "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
        "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTjqWuuWpu6-"
      },
      "source": [
        "### NORMALIZING EACH ESSAY SET VALUE BETWEEN 0 AND 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EyWzcr124FP",
        "outputId": "fa22a47e-66cc-4dfd-8375-ad01ae57b852"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.0 12.0\n",
            "1.0 6.0\n",
            "0.0 3.0\n",
            "0.0 3.0\n",
            "0.0 4.0\n",
            "0.0 4.0\n",
            "2.0 20.0\n",
            "10.0 20.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\pchhl\\AppData\\Local\\Temp\\ipykernel_25820\\3294479561.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  temp_df.loc[temp_df['essay_set'] == essay_set, 'normalized_score'] = (temp['domain1_score'] - min_value) / (max_value - min_value)\n"
          ]
        }
      ],
      "source": [
        "# Change the range to cover all 8 essay sets\n",
        "for essay_set in range(1, 9):\n",
        "    temp = temp_df[temp_df['essay_set'] == essay_set]\n",
        "    min_value = temp['domain1_score'].min()\n",
        "    max_value = temp['domain1_score'].max()\n",
        "    print(min_value, max_value)\n",
        "    temp_df.loc[temp_df['essay_set'] == essay_set, 'normalized_score'] = (temp['domain1_score'] - min_value) / (max_value - min_value)\n",
        "\n",
        "# print(temp_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ii8eIretV0K7",
        "outputId": "ddfb131c-b2b5-4ab3-8edf-1506bbba3f8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0 1.0\n",
            "0.0 1.0\n",
            "0.0 1.0\n",
            "0.0 1.0\n",
            "0.0 1.0\n",
            "0.0 1.0\n",
            "0.0 1.0\n",
            "0.0 1.0\n"
          ]
        }
      ],
      "source": [
        "for essay_set in range(1, 9):\n",
        "    temp = temp_df[temp_df['essay_set'] == essay_set]\n",
        "    min_value = temp['normalized_score'].min()\n",
        "    max_value = temp['normalized_score'].max()\n",
        "    print(min_value, max_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "JLC9ZrCqWP4U",
        "outputId": "fcc6d7c0-a29c-4784-abcf-78239b7d0915"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>rater1_domain1</th>\n",
              "      <th>rater2_domain1</th>\n",
              "      <th>rater3_domain1</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>rater1_domain2</th>\n",
              "      <th>rater2_domain2</th>\n",
              "      <th>domain2_score</th>\n",
              "      <th>...</th>\n",
              "      <th>rater2_trait4</th>\n",
              "      <th>rater2_trait5</th>\n",
              "      <th>rater2_trait6</th>\n",
              "      <th>rater3_trait1</th>\n",
              "      <th>rater3_trait2</th>\n",
              "      <th>rater3_trait3</th>\n",
              "      <th>rater3_trait4</th>\n",
              "      <th>rater3_trait5</th>\n",
              "      <th>rater3_trait6</th>\n",
              "      <th>normalized_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>dear local newspaper i think effects computers...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>dear caps1 caps2 i believe that using computer...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>dear caps1 caps2 caps3 more and more people us...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>dear local newspaper caps1 i have found that m...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>dear location1 i know having computers has a p...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   essay_id  essay_set                                              essay  \\\n",
              "0         1          1  dear local newspaper i think effects computers...   \n",
              "1         2          1  dear caps1 caps2 i believe that using computer...   \n",
              "2         3          1  dear caps1 caps2 caps3 more and more people us...   \n",
              "3         4          1  dear local newspaper caps1 i have found that m...   \n",
              "4         5          1  dear location1 i know having computers has a p...   \n",
              "\n",
              "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
              "0             4.0             4.0             NaN            8.0   \n",
              "1             5.0             4.0             NaN            9.0   \n",
              "2             4.0             3.0             NaN            7.0   \n",
              "3             5.0             5.0             NaN           10.0   \n",
              "4             4.0             4.0             NaN            8.0   \n",
              "\n",
              "   rater1_domain2  rater2_domain2  domain2_score  ...  rater2_trait4  \\\n",
              "0             NaN             NaN            NaN  ...            NaN   \n",
              "1             NaN             NaN            NaN  ...            NaN   \n",
              "2             NaN             NaN            NaN  ...            NaN   \n",
              "3             NaN             NaN            NaN  ...            NaN   \n",
              "4             NaN             NaN            NaN  ...            NaN   \n",
              "\n",
              "   rater2_trait5  rater2_trait6  rater3_trait1  rater3_trait2  rater3_trait3  \\\n",
              "0            NaN            NaN            NaN            NaN            NaN   \n",
              "1            NaN            NaN            NaN            NaN            NaN   \n",
              "2            NaN            NaN            NaN            NaN            NaN   \n",
              "3            NaN            NaN            NaN            NaN            NaN   \n",
              "4            NaN            NaN            NaN            NaN            NaN   \n",
              "\n",
              "   rater3_trait4  rater3_trait5  rater3_trait6  normalized_score  \n",
              "0            NaN            NaN            NaN               0.6  \n",
              "1            NaN            NaN            NaN               0.7  \n",
              "2            NaN            NaN            NaN               0.5  \n",
              "3            NaN            NaN            NaN               0.8  \n",
              "4            NaN            NaN            NaN               0.6  \n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temp_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "cRW-cxck26lu"
      },
      "outputs": [],
      "source": [
        "text = \"Hello, how are you?\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
        "outputs = model(**inputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wilM0SKrRUXv",
        "outputId": "213b9730-2581-4e59-c488-68d6239c64e3"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0UmXYZHqELq"
      },
      "source": [
        "### WORD EMBEDDINGS FROM PENULTIMATE LAYER OF BERT MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I84xiwkxKqU_",
        "outputId": "847f75d9-df6f-4018-e90d-2d1fe7dc19e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10, 768)\n"
          ]
        }
      ],
      "source": [
        "class BertSentenceEmbedding(nn.Module):\n",
        "    def __init__(self, pretrained_model_name='bert-base-uncased'):\n",
        "        super(BertSentenceEmbedding, self).__init__()  # Call the super class's __init__ first\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(pretrained_model_name)\n",
        "        self.model = BertModel.from_pretrained(pretrained_model_name, output_hidden_states=True)\n",
        "        self.model.eval()\n",
        "\n",
        "\n",
        "    def get_embedding(self, text):\n",
        "        sentences = sent_tokenize(text)\n",
        "        sentence_embeddings = []\n",
        "\n",
        "        for sentence in sentences:\n",
        "            processed_sentence = pipeline(sentence)\n",
        "            inputs = self.tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(**inputs.to(self.device))\n",
        "\n",
        "            # Use the last four layers' hidden states\n",
        "            hidden_states = outputs.hidden_states[-4:]\n",
        "            # print(\"hidden_states :\", hidden_states[0].cpu().numpy().shape)\n",
        "\n",
        "\n",
        "            # Concatenate the hidden states from the last four layers along the second dimension\n",
        "            concatenated_hidden_states = torch.cat(hidden_states, dim=1)\n",
        "            # print(\"concatenated_hidden_states :\",concatenated_hidden_states.shape)\n",
        "\n",
        "\n",
        "            # Compute the mean of all tokens embeddings for this sentence\n",
        "            sentence_embedding = torch.mean(concatenated_hidden_states, dim=1).squeeze().cpu().numpy()\n",
        "            # print(\"sentence_embedding :\",sentence_embedding.shape)\n",
        "\n",
        "            sentence_embeddings.append(sentence_embedding)\n",
        "\n",
        "        return np.array(sentence_embeddings)\n",
        "\n",
        "# Assuming you've defined device somewhere above\n",
        "bert_embedder = BertSentenceEmbedding().to(device)\n",
        "essay = df['essay'][0]\n",
        "embeddings = bert_embedder.get_embedding(essay)\n",
        "print(embeddings.shape)  # It should print (number_of_sentences_in_essay, 768)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8qufj4lWXpm"
      },
      "outputs": [],
      "source": [
        "# class BertSentenceEmbedding(nn.Module):\n",
        "#     def __init__(self, pretrained_model_name='bert-base-uncased'):\n",
        "#         super(BertSentenceEmbedding, self).__init__()  # Call the super class's __init__ first\n",
        "\n",
        "#         self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#         self.tokenizer = BertTokenizer.from_pretrained(pretrained_model_name)\n",
        "#         self.model = BertModel.from_pretrained(pretrained_model_name, output_hidden_states=True)\n",
        "#         self.model.eval()\n",
        "\n",
        "#     def get_embedding(self, text):\n",
        "\n",
        "#         # Tokenize the essay into sentences\n",
        "#         sentences = sent_tokenize(text)\n",
        "\n",
        "#         # List to hold embeddings for each sentence\n",
        "#         sentence_embeddings = []\n",
        "\n",
        "#         for sentence in sentences:\n",
        "#             # I noticed you were using a \"pipeline\" function that was not defined in the given code\n",
        "#             processed_sentence = pipeline(sentence)\n",
        "#             inputs = self.tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "#             with torch.no_grad():\n",
        "#                 outputs = self.model(**inputs.to(self.device))\n",
        "\n",
        "#             # Use the penultimate layer's hidden states\n",
        "#             hidden_states = outputs.hidden_states[-2]\n",
        "\n",
        "#             # Compute the mean of all tokens embeddings for this sentence\n",
        "#             sentence_embedding = torch.mean(hidden_states, dim=1).squeeze().cpu().numpy()\n",
        "#             sentence_embeddings.append(sentence_embedding)\n",
        "\n",
        "#         return np.array(sentence_embeddings)  # Return embeddings for all sentences in the essay\n",
        "\n",
        "# # Assuming you've defined device somewhere above\n",
        "# bert_embedder = BertSentenceEmbedding().to(device)\n",
        "# essay = df['essay'][0]\n",
        "# embeddings = bert_embedder.get_embedding(essay)\n",
        "# print(embeddings.shape)  # It should print (number_of_sentences_in_essay, 768)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6ByQsKHOeSP",
        "outputId": "c198235b-7de0-4279-f1b7-33618250b856"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9ztNl49qOc2"
      },
      "source": [
        "### SEMANTIC MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mwAUjCVvJDWV"
      },
      "outputs": [],
      "source": [
        "class SemanticScore(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SemanticScore, self).__init__()\n",
        "\n",
        "        self.bert_emb_dim = 768\n",
        "        self.dropout_prob = 0.5\n",
        "        self.lstm_hidden_size = 1024\n",
        "        self.lstm_layers_num = 1\n",
        "        self.fnn_hidden_size = []\n",
        "        self.bidirectional = False\n",
        "\n",
        "        self.lstm = nn.LSTM(self.bert_emb_dim,\n",
        "                            self.lstm_hidden_size,\n",
        "                            self.lstm_layers_num,\n",
        "                            bidirectional=self.bidirectional,\n",
        "                            batch_first=True)\n",
        "        self.dropout = nn.Dropout(self.dropout_prob)\n",
        "\n",
        "        in_features = self.lstm_hidden_size * 2 if self.bidirectional else self.lstm_hidden_size\n",
        "        layers = []\n",
        "        for hs in self.fnn_hidden_size:\n",
        "            layers.append(nn.Linear(in_features, hs))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(self.dropout_prob))\n",
        "            in_features = hs\n",
        "\n",
        "        layers.append(nn.Linear(in_features, 400))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.Dropout(self.dropout_prob))\n",
        "        layers.append(nn.Linear(400, 1))\n",
        "        layers.append(nn.Sigmoid())\n",
        "        self.fnn = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, batch_doc_encodes, batch_doc_sent_nums):\n",
        "        packed_input = pack_padded_sequence(batch_doc_encodes, batch_doc_sent_nums, batch_first=True, enforce_sorted=False)\n",
        "        packed_output, _ = self.lstm(packed_input)\n",
        "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
        "        logits = self.fnn(output[:, -1, :]) # Using the output of the last timestep\n",
        "        return logits.squeeze(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuPY2ie3g9d6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7A4CB7qqZBB"
      },
      "source": [
        "### PROMPTS CORRESPONDING TO EACH SET FROM 1 TO 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "24Krn3JtggZ4"
      },
      "outputs": [],
      "source": [
        "prompts = [\n",
        "    \"\"\"More and more people use computers, but not everyone agrees that this benefits society.\n",
        "    Those who support advances in technology believe that computers have a positive effect on people.\n",
        "    They teach hand-eye coordination, give people the ability to learn about faraway places and people, and\n",
        "    even allow people to talk online with other people. Others have different ideas. Some experts are concerned\n",
        "    that people are spending too much time on their computers and less time exercising, enjoying nature, and interacting with family and friends.\n",
        "    Write a letter to your local newspaper in which you state your opinion on the effects computers have on people. Persuade the readers to agree with you.\n",
        "\"\"\" ,\n",
        "\n",
        "    \"\"\"Censorship in the Libraries\n",
        "    All of us can think of a book that we hope none of our children or any other children have taken off the shelf. But if I have the right to remove that book from the shelf --\n",
        "    that work I abhor -- then you also have exactly the same right and so does everyone else. And then we have no books left on the shelf for any of us.\" --Katherine Paterson, Author\n",
        "    Write a persuasive essay to a newspaper reflecting your vies on censorship in libraries. Do you believe that certain materials, such as books, music, movies, magazines, etc.,\n",
        "    should be removed from the shelves if they are found offensive? Support your position with convincing arguments from your own experience, observations, and/or reading.\n",
        "\"\"\",\n",
        "\n",
        "      \"\"\"ROUGH ROAD AHEAD: Do Not Exceed Posted Speed Limit\n",
        "    FORGET THAT OLD SAYING ABOUT NEVER taking candy from strangers. No, a better piece of advice for the solo cyclist would be, “Never accept travel advice from a collection of old-timers who haven’t left the confines of their porches since Carter was in office.” It’s not that a group of old guys doesn’t know the terrain. With age comes wisdom and all that, but the world is a fluid place. Things change.\n",
        "    At a reservoir campground outside of Lodi, California, I enjoyed the serenity of an early-summer evening and some lively conversation with these old codgers. What I shouldn’t have done was let them have a peek at my map. Like a foolish youth, the next morning I followed their advice and launched out at first light along a “shortcut” that was to slice away hours from my ride to Yosemite National Park.\n",
        "    They’d sounded so sure of themselves when pointing out landmarks and spouting off towns I would come to along this breezy jaunt. Things began well enough. I rode into the morning with strong legs and a smile on my face. About forty miles into the pedal, I arrived at the first “town.” This place might have been a thriving little spot at one time—say, before the last world war—but on that morning it fit the traditional definition of a ghost town. I chuckled, checked my water supply, and moved on. The sun was beginning to beat down, but I barely noticed it. The cool pines and rushing rivers of Yosemite had my name written all over them.\n",
        "    Twenty miles up the road, I came to a fork of sorts. One ramshackle shed, several rusty pumps, and a corral that couldn’t hold in the\n",
        "    lamest mule greeted me. This sight was troubling. I had been hitting my water bottles pretty regularly, and I was traveling through the high deserts of California in June.\n",
        "    I got down on my hands and knees, working the handle of the rusted water pump with all my strength. A tarlike substance oozed out, followed by\n",
        "    brackish water feeling somewhere in the neighborhood of two hundred degrees. I pumped that handle for several minutes, but the water\n",
        "    wouldn’t cool down. It didn’t matter. When I tried a drop or two, it had the flavor of battery acid.\n",
        "    The old guys had sworn the next town was only eighteen miles down the road. I could make that! I would conserve my water and go inward for an hour or so—a test of my inner spirit.\n",
        "    Not two miles into this next section of the ride, I noticed the terrain changing. Flat road was replaced by short, rolling hills.\n",
        "    After I had crested the first few of these, a large highway sign jumped out at me. It read: ROUGH ROAD AHEAD: DO NOT EXCEED POSTED SPEED LIMIT.\n",
        "    The speed limit was 55 mph. I was doing a water-depleting 12 mph. Sometimes life can feel so cruel.\n",
        "    I toiled on. At some point, tumbleweeds crossed my path and a ridiculously large snake—it really did look like a diamondback—blocked the majority of the pavement in front of me.\n",
        "    I eased past, trying to keep my balance in my dehydrated state.\n",
        "    The water bottles contained only a few tantalizing sips. Wide rings of dried sweat circled my shirt, and the growing realization that I could drop from heatstroke on a gorgeous day in June simply because I listened to some gentlemen who hadn’t been off their porch in decades, caused me to laugh.\n",
        "    It was a sad, hopeless laugh, mind you, but at least I still had the energy to feel sorry for myself. There was no one in sight, not a building, car, or structure of any kind. I began breaking the ride down into distances I could see on the horizon, telling myself that if I could make it that far, I’d be fi ne.\n",
        "    Over one long, crippling hill, a building came into view. I wiped the sweat from my eyes to make sure it wasn’t a mirage, and tried not to get too excited. With what I believed was my last burst of energy, I maneuvered down the hill.\n",
        "    In an ironic twist that should please all sadists reading this, the building—abandoned years earlier, by the looks of it—had been a Welch’s Grape Juice factory and bottling plant. A sandblasted picture of a young boy pouring a refreshing glass of juice into his mouth could still be seen.\n",
        "    I hung my head.\n",
        "    That smoky blues tune “Summertime” rattled around in the dry honeycombs of my deteriorating brain.\n",
        "    I got back on the bike, but not before I gathered up a few pebbles and stuck them in my mouth. I’d read once that sucking on stones helps take your mind off thirst by allowing what spit you have left to circulate. With any luck I’d hit a bump and lodge one in my throat.\n",
        "    It didn’t really matter. I was going to die and the birds would pick me clean, leaving only some expensive outdoor gear and a diary with the last entry in praise of old men, their wisdom, and their keen sense of direction. I made a mental note to change that paragraph if it looked like I was going to lose consciousness for the last time.\n",
        "    Somehow, I climbed away from the abandoned factory of juices and dreams, slowly gaining elevation while losing hope. Then, as easily as rounding a bend, my troubles, thirst, and fear were all behind me.\n",
        "    GARY AND WILBER’S FISH CAMP—IF YOU WANT BAIT FOR THE BIG ONES, WE’RE YOUR BEST BET!\n",
        "    “And the only bet,” I remember thinking.\n",
        "    As I stumbled into a rather modern bathroom and drank deeply from the sink, I had an overwhelming urge to seek out Gary and Wilber, kiss them, and buy some bait—any bait, even though I didn’t own a rod or reel.\n",
        "    An old guy sitting in a chair under some shade nodded in my direction. Cool water dripped from my head as I slumped against the wall beside him.\n",
        "    “Where you headed in such a hurry?”\n",
        "    “Yosemite,” I whispered.\n",
        "    “Know the best way to get there?”\n",
        "    I watched him from the corner of my eye for a long moment. He was even older than the group I’d listened to in Lodi.\n",
        "    “Yes, sir! I own a very good map.”\n",
        "    And I promised myself right then that I’d always stick to it in the future.\n",
        "    Write a response that explains how the features of the setting affect the cyclist. In your response, include examples from the essay that support your conclusion.\n",
        "    \"\"\",\n",
        "\n",
        "    \"\"\"Read the last paragraph of the story.\n",
        "    \"When they come back, Saeng vowed silently to herself, in the spring, when the snows melt and the geese return and this hibiscus is budding, then I will take that test again.\"\n",
        "    Write a response that explains why the author concludes the story with this paragraph. In your response, include details and examples from the story that support your ideas.\n",
        "    \"\"\",\n",
        "\n",
        "    \"\"\"My parents, originally from Cuba, arrived in the United States in 1956. After living for a year in a furnished one-room apartment, twenty-one-year-old Rawedia Maria and twenty-seven-year-old Narciso Rodriguez, Sr., could afford to move into a modest, three-room apartment I would soon call home.\n",
        "    In 1961, I was born into this simple house, situated in a two-family, blond-brick building in the Ironbound section of Newark, New Jersey. Within its walls, my young parents created our traditional Cuban home, the very heart of which was the kitchen. My parents both shared cooking duties and unwittingly passed on to me their rich culinary skills and a love of cooking that is still with me today (and for which I am eternally grateful). Passionate Cuban music (which I adore to this day) filled the air, mixing with the aromas of the kitchen. Here, the innocence of childhood, the congregation of family and friends, and endless celebrations that encompassed both, formed the backdrop to life in our warm home.\n",
        "    Growing up in this environment instilled in me a great sense that “family” had nothing to do with being a blood relative. Quite the contrary, our neighborhood was made up of mostly Spanish, Cuban, and Italian immigrants at a time when overt racism was the norm and segregation prevailed in the United States. In our neighborhood, despite customs elsewhere, all of these cultures came together in great solidarity and friendship. It was a close-knit community of honest, hardworking immigrants who extended a hand to people who, while not necessarily their own kind, were clearly in need.\n",
        "    Our landlord and his daughter, Alegria (my babysitter and first friend), lived above us, and Alegria graced our kitchen table for meals more often than not. Also at the table were Sergio and Edelmira, my surrogate grandparents who lived in the basement apartment. (I would not know my “real” grandparents, Narciso the Elder and Consuelo, until 1970 when they were allowed to leave Cuba.) My aunts Bertha and Juanita and my cousins Arnold, Maria, and Rosemary also all lived nearby and regularly joined us at our table. Countless extended family members came and went — and there was often someone staying with us temporarily until they were able to get back on their feet. My parents always kept their arms and their door open to the many people we considered family, knowing that they would do the same for us.\n",
        "    My mother and father had come to this country with such courage, without any knowledge of the language or the culture. They came selflessly, as many immigrants do, to give their children a better life, even though it meant leaving behind their families, friends, and careers in the country they loved. They struggled both personally and financially, braving the harsh northern winters while yearning for their native tropics and facing cultural hardships. The barriers to work were strong and high, and my parents both had to accept that they might not be able to find the kind of jobs they deserved. In Cuba, Narciso, Sr., had worked in a laboratory and Rawedia Maria had studied chemical engineering. In the United States, they had to start their lives over entirely, taking whatever work they could find. The faith that this struggle would lead them and their children to better times drove them to endure these hard times.\n",
        "    I will always be grateful to my parents for their love and sacrifice. I’ve often told them that what they did was a much more courageous thing than I could have ever done. I’ve often told them of my admiration for their strength and perseverance, and I’ve thanked them repeatedly. But, in reality, there is no way to express my gratitude for the spirit of generosity impressed upon me at such an early age and the demonstration of how important family and friends are. These are two lessons that my parents did not just tell me. They showed me with their lives, and these teachings have been the basis of my life.\n",
        "    It was in this simple house that my parents welcomed other refugees to celebrate their arrival to this country and where I celebrated my first birthdays. It was in the warmth of the kitchen in this humble house where a Cuban feast (albeit a frugal Cuban feast) always filled the air with not just scent and music but life and love. It was here where I learned the real definition of “family.” And for this, I will never forget that house or its gracious neighborhood or the many things I learned there about how to love. I will never forget how my parents turned this simple house into a home.\n",
        "    Describe the mood created by the author in the memoir. Support your answer with relevant and specific information from the memoir\n",
        "\"\"\",\n",
        "\n",
        "    \"\"\"Based on the excerpt, describe the obstacles the builders of the Empire State Building faced in attempting to allow dirigibles to dock there.\n",
        "    Support your answer with relevant and specific information from the excerpt.\"\"\",\n",
        "\n",
        "    \"\"\"Write about patience. Being patient means that you are understanding and tolerant. A patient person experience difficulties without complaining.\n",
        "      Do only one of the following: write a story about a time when you were patient OR write a story about a time when someone you know was patient OR write a story in your own way about patience.\n",
        "\"\"\",\n",
        "\n",
        "    \"\"\"We all understand the benefits of laughter. For example, someone once said, “Laughter is the shortest distance between two people.”\n",
        "    Many other people believe that laughter is an important part of any relationship. Tell a true story in which laughter was one element or part.\"\"\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "5a7OlznQ__fB",
        "outputId": "5513bfa7-a4ce-4be5-cd76-1e1fb54cb2e3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>rater1_domain1</th>\n",
              "      <th>rater2_domain1</th>\n",
              "      <th>rater3_domain1</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>rater1_domain2</th>\n",
              "      <th>rater2_domain2</th>\n",
              "      <th>domain2_score</th>\n",
              "      <th>...</th>\n",
              "      <th>rater2_trait4</th>\n",
              "      <th>rater2_trait5</th>\n",
              "      <th>rater2_trait6</th>\n",
              "      <th>rater3_trait1</th>\n",
              "      <th>rater3_trait2</th>\n",
              "      <th>rater3_trait3</th>\n",
              "      <th>rater3_trait4</th>\n",
              "      <th>rater3_trait5</th>\n",
              "      <th>rater3_trait6</th>\n",
              "      <th>normalized_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>dear local newspaper i think effects computers...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>dear caps1 caps2 i believe that using computer...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>dear caps1 caps2 caps3 more and more people us...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>dear local newspaper caps1 i have found that m...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>dear location1 i know having computers has a p...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   essay_id  essay_set                                              essay  \\\n",
              "0         1          1  dear local newspaper i think effects computers...   \n",
              "1         2          1  dear caps1 caps2 i believe that using computer...   \n",
              "2         3          1  dear caps1 caps2 caps3 more and more people us...   \n",
              "3         4          1  dear local newspaper caps1 i have found that m...   \n",
              "4         5          1  dear location1 i know having computers has a p...   \n",
              "\n",
              "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
              "0             4.0             4.0             NaN            8.0   \n",
              "1             5.0             4.0             NaN            9.0   \n",
              "2             4.0             3.0             NaN            7.0   \n",
              "3             5.0             5.0             NaN           10.0   \n",
              "4             4.0             4.0             NaN            8.0   \n",
              "\n",
              "   rater1_domain2  rater2_domain2  domain2_score  ...  rater2_trait4  \\\n",
              "0             NaN             NaN            NaN  ...            NaN   \n",
              "1             NaN             NaN            NaN  ...            NaN   \n",
              "2             NaN             NaN            NaN  ...            NaN   \n",
              "3             NaN             NaN            NaN  ...            NaN   \n",
              "4             NaN             NaN            NaN  ...            NaN   \n",
              "\n",
              "   rater2_trait5  rater2_trait6  rater3_trait1  rater3_trait2  rater3_trait3  \\\n",
              "0            NaN            NaN            NaN            NaN            NaN   \n",
              "1            NaN            NaN            NaN            NaN            NaN   \n",
              "2            NaN            NaN            NaN            NaN            NaN   \n",
              "3            NaN            NaN            NaN            NaN            NaN   \n",
              "4            NaN            NaN            NaN            NaN            NaN   \n",
              "\n",
              "   rater3_trait4  rater3_trait5  rater3_trait6  normalized_score  \n",
              "0            NaN            NaN            NaN               0.6  \n",
              "1            NaN            NaN            NaN               0.7  \n",
              "2            NaN            NaN            NaN               0.5  \n",
              "3            NaN            NaN            NaN               0.8  \n",
              "4            NaN            NaN            NaN               0.6  \n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temp_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwFE5fAxqqe_"
      },
      "source": [
        "### ADD PROMPTS TO DATAFRAME FOR EACH SET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZUo_SwFE3ND",
        "outputId": "e53ac749-7978-4dbe-de0e-6450b5a6318d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\pchhl\\AppData\\Local\\Temp\\ipykernel_25820\\3854521186.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  custom_df['prompt'] = prompt\n"
          ]
        }
      ],
      "source": [
        "prompt = list(prompts[sets - 1] for sets in temp_df['essay_set'])\n",
        "custom_df = temp_df[['essay_id', 'essay_set', 'essay', 'normalized_score']]\n",
        "custom_df['prompt'] = prompt\n",
        "custom_df.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "qQ2xqEPDLyVm",
        "outputId": "3f048512-832f-4902-cf42-4d39daf0bf31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11981\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>normalized_score</th>\n",
              "      <th>prompt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>dear local newspaper i think effects computers...</td>\n",
              "      <td>0.6</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>dear caps1 caps2 i believe that using computer...</td>\n",
              "      <td>0.7</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>dear caps1 caps2 caps3 more and more people us...</td>\n",
              "      <td>0.5</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>dear local newspaper caps1 i have found that m...</td>\n",
              "      <td>0.8</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>dear location1 i know having computers has a p...</td>\n",
              "      <td>0.6</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   essay_id  essay_set                                              essay  \\\n",
              "0         1          1  dear local newspaper i think effects computers...   \n",
              "1         2          1  dear caps1 caps2 i believe that using computer...   \n",
              "2         3          1  dear caps1 caps2 caps3 more and more people us...   \n",
              "3         4          1  dear local newspaper caps1 i have found that m...   \n",
              "4         5          1  dear location1 i know having computers has a p...   \n",
              "\n",
              "   normalized_score                                             prompt  \n",
              "0               0.6  More and more people use computers, but not ev...  \n",
              "1               0.7  More and more people use computers, but not ev...  \n",
              "2               0.5  More and more people use computers, but not ev...  \n",
              "3               0.8  More and more people use computers, but not ev...  \n",
              "4               0.6  More and more people use computers, but not ev...  "
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# custom_df = read_asap_dataset(temp_df, prompts)\n",
        "\n",
        "print(len(custom_df))\n",
        "\n",
        "custom_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf6Q_sCwC1tE",
        "outputId": "a6c02e06-7a49-4a83-ac1e-7981b02b1a9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 2, 3, 4, 5, 6, 7, 8], dtype=int64)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.unique(np.array(custom_df['essay_set']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UapV2D6kq2AD"
      },
      "source": [
        "### PREPROCESSING ESSAY i.e. ESSAYS ARE CONVERTED INTO WORD EMBEDDINGS BEFORE PASSING IT TO SOME MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "vvOvSgR2hliz"
      },
      "outputs": [],
      "source": [
        "def preprocess_essay(essays):\n",
        "    # print(essays)\n",
        "    essay_embeddings = [torch.tensor(bert_embedder.get_embedding(essay)) for essay in essays]\n",
        "\n",
        "    # Find the maximum number of sentences in all essays\n",
        "    max_sentences = max(embed.shape[0] for embed in essay_embeddings)\n",
        "\n",
        "    # Calculate the number of dimensions (features) in the embeddings\n",
        "    num_features = essay_embeddings[0].shape[1]  # Assumes all embeddings have the same number of features\n",
        "\n",
        "    # Pad the sentence embeddings to have the same number of sentences\n",
        "    padded_embeddings = []\n",
        "    for embed in essay_embeddings:\n",
        "        padding = max_sentences - embed.shape[0]\n",
        "        padded_embed = torch.cat((embed, torch.zeros(padding, num_features)), dim=0)\n",
        "        padded_embeddings.append(padded_embed)\n",
        "\n",
        "    embeddings_batch = torch.stack(padded_embeddings)  # batch * sentences * num_features\n",
        "    lengths_batch = torch.tensor([max_sentences] * len(essays), dtype=torch.int64)\n",
        "\n",
        "    return embeddings_batch, lengths_batch\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYq0TGLdq0FF"
      },
      "source": [
        "### DATALOADER WITH INITIAL DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "-85xJAcPIOww"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, essay_id, essay_set, essay, prompt, normalized_score):\n",
        "        self.essay_id = essay_id\n",
        "        self.essay_set = essay_set\n",
        "        self.essay = essay\n",
        "        self.prompt = prompt\n",
        "        self.normalized_score = normalized_score\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.essay_id)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        essay_id, essay_set, essay, prompt, normalized_score = self.essay_id.iloc[idx], self.essay_set.iloc[idx], self.essay.iloc[idx], self.prompt.iloc[idx], self.normalized_score.iloc[idx]\n",
        "        return essay_id, essay_set, essay, prompt, normalized_score\n",
        "\n",
        "# # Create a DataLoader\n",
        "custom_dataset = CustomDataset(custom_df['essay_id'], custom_df['essay_set'], custom_df['essay'], custom_df['prompt'], custom_df['normalized_score'])\n",
        "dataloader = DataLoader(custom_dataset, batch_size=32, shuffle=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjKgUln4ZRu-",
        "outputId": "57009d98-00fd-4998-db43-643ef6b87a55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the mood created by the author in the memoir. growing up in this environment instilled in me a great sense that family had nothing the memoir life was hard. quite the contrary our neighborhood was made up of mostly spanish cuban and italian immigrants at a time when overt recism. in their neighborhood despite customs elsewhere all of these cultures came together in great solidary and friendship. over all these was hard for the author memoir\n",
            "the mood that the author created in the memmoir was very thankful. he was very thankful for his parents coming to the caps1 from cuba. the opertunties it gave him a better education and to be successful. in the memmoir he was thankfull for al the people that helped him in this new country and supported him and his family as he did the same to the people that supoorted him. thankfull was the mood that narciso rodriguez showd in this memoir.\n",
            "builders trying to allow dirigibles to dock ontop of the empire state building faced problems. the dirigibles waight and the wind pressure would add stress to the building. wich caps1 to be transmitted more then num1 ft down to the buildings foundation. construction wasnt the only problem. most caps2american dirigibles are held afloat by hellium wich is extremely flammable and if it was caps3 over busy crowded new york streets many people could have been killed. nature added to the problems. wind currents had the pottential to push dirigibles into caps4 buildings causing them to pop. the finall problem was caps5 already implace wich didnt allow low flying aircrafts. builders faced problems with nature caps5 safety and construction wich lead to the demise of the use of the mooring system.\n",
            "i was patient at the dentist office. when i went to the dentist office i was getting my bracts put on. when i was sitting there they told me they had to get my brackets and wire. while they were getting the brackets and wire i got to pick out colors. i waited about num1 mins. without complaining. next they started putting the brackets on the glue. when they put one bracket on i felt so weird and kido tasted like heated metal “caps1” i said. after they had put on the brockets and then they put colors. my mouth hurt like crazy when it was all over i noticed it had been num2 hours i was surprised because i didn’t know i sat there for num2 hours but i was very patient and waited that whole time that’s the time i was patient at the dentist office.\n",
            "in this excerpt from the book home the blue prints of our lives narciso rodriguez describes his first home in location1. the feeling of this story is first loving with how caps1 explains his parents sacrifice theycame selflessly as many immigrants do to give their children a better life even though it meant leaving behind their families friends and careers in the country they loved. this story also gave a feeling of closeness and how family had nothing to do with being a blood relative caps1 and his family opened up there house to many people. this story also gave a warm feeling by the story of his family celebrating together in paragraph seven. overall the story had a happy mood to it showing love kindness and what a family should be like\n",
            "the author concluded the story with that specific paragraph because saeng feels most comfortable taking the test again when what she explained happens. saeng misses where she came from alot. she promised herself that she would take the test again when that happens. with saeng saying that it makes you wonder why she wont take the test again the snow melts the geese return and the hibiscus is budding. it makes her feel really comfortable when that does happen.\n",
            "the author uses this paragraph to conclude her story to show that there was thought a process gone through where she was learning growing. at first saeng is very uneasy disappointed in herself. ii failed the test saeng says. for a long moment mrs. pan ouvong said nothing. you can tell at first the mother is disappointed then as they talk the are planting which eases the mood. how would you like an omelet w slices of the bitter melon i’d love it saeng said. her mood has now lightened she is thaking a calm collective decision to try again which is a reasonable decision to make when she is in a good frame of mind rather than upset distraught.\n",
            "the builders of the empire state building faced obstacles in attempting to allow dirigibles to dock there. the obstacles included safety issues nature and the law. safety issues was a problem because in the excerpt it says most dirigibles from outside united states used hydrogen rather than helium and hydrogen is highly flammable. this explains why they couldnt do it because of one of the dirigibles would explode in downtown new york it would cause severe damage and losses of life because its a populated area. another obstacle was nature. nature played its role because the winds on top of the building were constantly changing due to violent air currents. this would have made the back of the dirigibles swivel around which was either practical or safe. the last obstacle was that there was a law about airships flying to low over urban areas. this would have made it illegal to tie a ship to the empire state building. these obstacles had made the builders face problems to allow dirigibles to land on the empire state building.\n",
            "the features of the setting affected the cyclist in many ways. one way is that they would drink up all of there water because it was hot and they would get thirsty from all of that\n",
            "censorship in libraries today i believe are not a big problem. but many would disagree with that. books and movies can be a very important resource for anyone of any age. they can gives us facts about a certain topic that we month1 not find any where else. everyone has thier own definition of offensive. i belive that it is not only up to the library to rate the books movies and magazines offensive but it is also up to the participants using these resources. for many kids no matter what age they only rent books from a library for two main reasons pleasure and projects. to sensor a book from a teenager or child is just like more of an invitation to see whats inside of it. for the people who do pleasure reading they most of the time stick to only one type of genre. if someone wanted to rent a book and it was not appropriate for them to read then the librarian or teacher would restrict that book from them. for projects such as for school it would depend upon the librarian to censor the book to a child. but books are not rated such as movies are. so it really all depends upon the use of the book and the maturity of the person who is renting it. if they feel that it will not be appropriate for some then they could give a suggestion to censor it. movies and books are different in many ways. books allow you to create a mental description and picture in your mind for what you are reading. movies on the other hand create a visual image right in front of your eyes. no matter how gruesome or vile of a description a book can give it still does not compare with the visual picture of a video. movies are rated today as to the age of a person and they say why they are rated as such. movies rated above the num1 level are most of the time not held in libraries. they month1 still be censored if they create too vile of an image but that is up to the one who watches it. music is a major part of each one of our lives and without it the world would be a much different place. everyone finds themselves quite fond of a certain genre of music and most of the time sticks to it. music like movies is also rated by the content of the song. if it has a word or two that should be sensored then it is most likely already labeled explicit. i think that music just like movies should not be able to be censored because they are already rated accordingly. some books magazines and movies contain cold hard facts about the past years of our world and are too vile for anyone. and even though those events are in our past they are still very important to our present. books can be a magical place for children as well as adults to go and create their own world. to censor a book movie or magazine would be taking away that chance for someone to enjoy life just a little bit more for that small moment in time.\n",
            "i dont think there should be any censorship good books and music shouldint be removed just becaus one person finds it offensive. becaus the opinions of one month1 be diffrent with another.i beleave music is cencord the most becaus not many people get offendid by books but censorship in music i think is destroying it.becaus its an artists way of expresion and if people dont wana listen to what there saying then they should just not listen to it.books i think shouldint be taken offensivly forthe same reason music shouldint its a writers oppinion and expresion its like telling someone they cant voice there oppinion on anything like racesim or use curse words if they want.\n",
            "the builders of the empire state building faced many obstacles in attempting to allow dirigibles to dock there. they had to face being up in the air for so long they also had to face trying to dock the dirigible on top of the roof while still stay saft themselfs\n",
            "the mood created by the author in the memoir would be how fortunite we are to be living here in the united states and how lucky we are to have our education and our friends and families here with us. for example in paragraph num1 when he says i will always be greatful to my parents for their love and sacrifice. this is the mood created by the author in the memoir.\n",
            "the features in the setting in the story “rough road ahead do not exceed posted speed limit” greatly affect the biker. for example the heat is constantly drying the biker out. also at the first town the old water pump proved to be a hopeless cause with water tastd like “battery acid”. even after that were more problems. there was a sign that posted a max speed limit. the biker was doing about onefifth of that speed. this affects his mood and he realizes that it will be along ride. the pebbles that he found helps him out. he remembers reading that sticking pebbles in your mouth calms your thirst. finally the bait store gave him the relief that he needed at the end of his trip. in conclusion the setting makes the riders journey an one but in the end the bait store had just what he needed.\n",
            "the author ended the story this way because the plant represents new beginnings in which saeng needs. seang failed her test needed some comfort. she went to the greenhouse spent money1 on a hibiscus plant that reminded her of her home. it the same time the hibiscus plant reminded her that her new home is another new beginning. the hibiscus plant gives saeng better hopes that starting over can be a good thing that the next time she takes the test shell pass.\n",
            "the setting effected the cyclist in a great way. the snakes blocked his pathways and hi short water supply made it hard to continue. he felt as if he could drop of a heatstroke. his environment and the information from the old man made his ride very hard to continue. all in all his settings had a big effect on him.\n",
            "how can writing be offensive many caps1 find swear words in writing or violence to be very offensive. yet others find that those things make their writing more interesting. writing can cover all aspects of life and give us ideas like racism and other inappropriate thoughts. it seems like in todays writing you can pick up just about anything and somone will find it offensive. that means if we censored our libraries to the extreme there would be no books left. it is just like katherine paterson says in the quote ...then we have no books left on the shelf for any of us. caps1 cant deny that books and any other writing place ideas in our head. that idea is a seed and we can either choose to water that seed and let it grow or cause it to die out. i believe we have a choice to either except or deny those offensive ideas in our head. if we find something offensive simply set the book down and use that better judgemnt. we know what is right therefore we decide what is ok to read. everyone sees things differently. what about children can we trust their better judgement i fear that children dont have as great of judgement as more mature adults. the resposibility of judgement lies more on the parents of that child than the libraries. the libraries place books for kids in a certain section to make sure they find appropriate books for their age. both the adults and children get to find books that fit them and dont offend them. if libraries did do censorchip it would deny us our rights and freedom to speek our minds clearly without a haze being placed to confuse it. we as a country were built off the radical and offensive things written about the caps2. those words are what fired us up to become an independent country. just think if they would have censored those ideas. would we still be location1 today what it all comes down to is not that we should censore our reading but that we should use our better judgement.\n",
            "beforewhen i had to go to the doctor i had to wait fourty minutes. so i just played my caps1. i was playing mario cart.i got board so i just fell asleep. my mom woke me up because it was time. so we went in did my apointment and went home. then we had to wait twenty minuts for my dad to get home from work.\n",
            "his mood of this author is caps1 and detailed. he describes the life of this person and tells life about the family. he says and describes how he lives in a two family blond brick house in location1 and passionate about cuban music. there was cuban and italian immagrants who were racist and didnt care.\n",
            "the mood created by the author in the memoir is joyfull and grateful. the author is joyfull because in stanza two narciso states passionate cuban music which i adored to this day filled the air mixing with the aromas of the kitchen. this shows that the childhood of this person was joyful with the culture family friends foods and smells. this person is very grateful for all of the things he parents did. such as when the author states i will always be grateful to my parents for their love and sacrafice. ive often told them that what they did was a much more courageous thing than i couldve ever done. i thank them repeatedly. but in reality there is no way to express my gratitude for this period of generosity impressed upon me at such an early age and the demonstration of how important family and friends are. this shows that the author is truly grateful for everything the parents had done for him or her and he or she is really joyful now thinking back and makes the mood of the memoir joyful and grateful.\n",
            "the doctor appointment. oct num1 date1 me and my mom were getting ready to go to the doctors. once we got their it was so crowded. i felt like we had been their for weeks days even caps1 their were a lot of kids crying and playing. i was so exhausted i was still waiting for my turn to see the doctor num2 mins later still not my turn i was trying my hard to be patient but it didn’t help at all with all the noise of the kids running around tell . i walked up to the regiester and that’s where i found out my appointment i want till num3 oclock and it was only num4.\n",
            "the author concludes the story with the paragraph about the geese because it shows how saeng like the geese will adopt to her new environment. it shows that she will do what needs to be done in order to survive just like the geese have to do. she will take the test again and will not give up. the paragraph shows how she wants to adapt to the new country. for example the narration states “… she noticed the tearstains on her daughter’s cheeks and her puffy eyes”no. this example shows how saeng is not used to being in the new country and that she does not like it. however she will get used to it and do her best to do so as shown in the closing paragraph. also the narration states “…she admitted to herself she much preferred it to a big mac”ho. this proves how even though she month1 not like things at times saeng is willing to try them to get used to the new country. the narration states “…she realized that many of the things that she had thought of as strange before had become familiar to her now “num1.saeng is getting more and more used to her surrounding and is adopting to them just like the geese adapt which is the reason the author ended the story with the paragraph about geese.\n",
            "the cyclist had very little water. it was very hot. he had a long way to go. the road was very bumpy so he couldn’t go to fast or he’s tire’s might bust. there were know cars in site so if he did break down it would have taken even longer.\n",
            "the author concludes the story with this paragraph because she wanted to get her point across. also because she wanted to create an under standing of the complexitier of the passage. the author wanted the reader to feel her message as if they were there to witness it.\n",
            "a time when someone else i know was patient was when my mom was looking for a job. my mom is very very busy. she was the president of a club named caps1caps2 for about one or two years. but now that she is not the president anymore she is less busy but still has an important position that requires a lot of work. but with either position she wasn’t earning only money. so she decided that she would get a job. she started looking for jobs online and in the newspapers and things. she couldn’t find a job that was right for her. she never complained about it even though she was having a hard time finding a job. she kept on looking and looking. she kept looking for about another year until finally she found a job at caps3.c.c. she now teaches a computer class for collage or older people. if she liked she would have ended up with a job that didn’t enjoy.\n",
            "according to the essay features of the setting affect the cyclist. if the cyclist is in the middle of a hot desert in june with no water the cyclist will become excessively thirsty the longer they go. for example the author states “i had been hitting my bottles pritty regularly and i was traveling through the high desert of california in june”. the terrain changes to short rolling hills from flat land causing the cyclist to push herself to get the next town to get water. for instance she states “over one long crippling hill a building came into view”. this cause the cyclist to use what they thought of as their last burst of energy to get down there but the building was abandoned thus making the cyclist feel let down. as the cyclist continued on a setting of a bait store came and the cyclist felt relief because now she could get water. these examples show the change of setting on the cyclist’s trip and how it affected her.\n",
            "the obstacles the builders of the empire state building faced in attempting to allow dirigibles to dock there were that the most dirigibles from outside of the united states used hydrogen rather than helium and the hydrogen is highly flammable. the architects could not simply drop a mooring mast on top of the empire state buildings flat roof. the steel frame of the empire state building would have to be modified and strengthened to accommodate this new situation. when the german dirigible hindenburg was destroyed the owners of the empire state building realized how much worse the accident could have been if it had taken place above a densely populated area for example downtown new york. the greatest obstacle was nature itself the winds on top of the building were constantly shifting due to violent air currents. even if the dirigible were tethered to the mooring mast the back of the ship with swivel around and around the mooring mast. dirigibles moored in open landing fields could be weighted down in the back with lead weights but using these at the empire state building where they would be dangling high above pedestrians on the street was neither practical nor safe.\n",
            "mingfong ho concludes “winter hibiscus” with the paragraph”when they come back saeng vowed silently to herself in the spring when the snows melt and the geese return and the hibiscus is budding then i will take that test again. this ending paragraph shows that saeng will not give up in her struggle to adapt in this new place. saeng has been going throug hard times moving to the united states and failing her driver’s test. in the greenhouse saeng even breaks down and crys. the hibiscus flower that saeng bought cost the family a lot of money but to saeng it was very important. this flower represented hope. when the flower buds again it would be the right time to take her driver’s test. the flower also represents adapting to a new place. as saeng adapts to the united states the hibiscus adapts to the new garden.\n",
            "i believe that everyone should be free to read listen or watch what they choose to. anything publically exposed is goin to be seen anyhow. i think it shall be up to that person if they want to read something to mature or organization1 for themself. if it is a child i think the parent shall be in charge of that decision not the libarian. books movies and music are forms of entertainment. people read organization1 material to entertain themselves and there is nothing wrong with entertainment. everyone loves entertainment but to put a limit on it is unfair. if it is public that mean it should be released under certin circomstances or age and maturity. regaurdless of in a book or magazine everything that you dont want people to see will always show up somewere else such as the tv or the internet. the public library is were people go to get books to larn more about something so if u yake that book off the shelve someone might miss out on on education about somthing. i wouldnt take any book off the shelf because it was put there to read and it might be a good thing that child gets that book so that they have knowledge about somethings that are out there. if its there to read then let it be read instead of hiding it from them it only makes children more anxious to read or see it. if its in a public library let it be read people and children shall be free to anything in the library unless other wise consented by a parent. anything publically exposed in a book magazine or movie will be shown on the internet or tv so children will see what they want rather elders agree to it or not. nudity perfanity violence and provocative materialare in everything now days even cartoons so there is no way of kepping it from children or people its apart of everyday livng.\n",
            "construction always has challenges. in the excerpt from the mooring mask by marcia amidon lüsted there are many challenges for the builders of the empire state building faced in attempting to land dirigibles there. some of the obstacles the builders faced included the enormous size of the dirigibles the frame would need to be modified the cost and nature itself.landing the dirigibles would be a hard task. for one the dirigibles are enormous they are a thousandfoot long flying devices. this would make it extremely difficult to land just because of its weight. the stress of the dirigibles load and wind pressure would have to be transmitted all the way to the buildings foundation. this is a struggle because the steel frame of the empire state building would have to be modified. this modification would take lots of effort and planning. plus modification also brings up the problem of cost. there would have to be over sixty thousand dollars worth of modifications. that cost is mindblowing and would create challenges of how to get that money. in addition nature itself was an obstacle. winds at the top of the building were constantly shifting due to violent air currents. nature would bring up many challenges for the builders to have to work around. overall the builders of the empire state building faced many obstacles in attempt to allow dirigibles to dock there.\n",
            "patience not all of us have it. it is hard to learn theme but even harder to master theme. it is all ways a good time to use your patience.\n",
            "my story of when i was patient was when me and my family were going to the monster jam. it was one of the most exciting things of my life. but the trip there was almost num1 then it took half an hour to find a place to park. then eleast num2 minutes for my moms friends to show up. and finally an hour in line. last but not leas num3 minutes to find our seat thank you for listening to my report about patience and sitting through it\n"
          ]
        }
      ],
      "source": [
        "for essay_id, essay_set, essays, normalized_score, prompt in dataloader:\n",
        "    for essay in essays:\n",
        "        print(essay)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ODS0UaXQ_gDv",
        "outputId": "8f347dfb-7a89-4f56-c34f-2b6c0eb60a86"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d038d42e-d183-4366-90d0-1050fccfac7f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>normalized_score</th>\n",
              "      <th>prompt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>dear local newspaper i think effects computers...</td>\n",
              "      <td>0.6</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>dear caps1 caps2 i believe that using computer...</td>\n",
              "      <td>0.7</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>dear caps1 caps2 caps3 more and more people us...</td>\n",
              "      <td>0.5</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>dear local newspaper caps1 i have found that m...</td>\n",
              "      <td>0.8</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>dear location1 i know having computers has a p...</td>\n",
              "      <td>0.6</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d038d42e-d183-4366-90d0-1050fccfac7f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d038d42e-d183-4366-90d0-1050fccfac7f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d038d42e-d183-4366-90d0-1050fccfac7f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c1ed3f47-10a6-4759-90e8-a62858f7b964\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c1ed3f47-10a6-4759-90e8-a62858f7b964')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c1ed3f47-10a6-4759-90e8-a62858f7b964 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   essay_id  essay_set                                              essay  \\\n",
              "0         1          1  dear local newspaper i think effects computers...   \n",
              "1         2          1  dear caps1 caps2 i believe that using computer...   \n",
              "2         3          1  dear caps1 caps2 caps3 more and more people us...   \n",
              "3         4          1  dear local newspaper caps1 i have found that m...   \n",
              "4         5          1  dear location1 i know having computers has a p...   \n",
              "\n",
              "   normalized_score                                             prompt  \n",
              "0               0.6  More and more people use computers, but not ev...  \n",
              "1               0.7  More and more people use computers, but not ev...  \n",
              "2               0.5  More and more people use computers, but not ev...  \n",
              "3               0.8  More and more people use computers, but not ev...  \n",
              "4               0.6  More and more people use computers, but not ev...  "
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "custom_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR5JEOWRrLpM"
      },
      "source": [
        "## SEMANTIC MODEL TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "jfeJfx90pisT"
      },
      "outputs": [],
      "source": [
        "model_semantic=SemanticScore().to(device)\n",
        "adam_optimizer=torch.optim.Adam(model_semantic.parameters(), lr=0.001)\n",
        "criteria=torch.nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id8yZ7OxpeWV",
        "outputId": "b6a12063-820a-43ff-918c-ceb35d37c937"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [1:20:01<00:00, 1600.55s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "optimizer=adam_optimizer\n",
        "train_loss = []\n",
        "\n",
        "for epoch in tqdm(range(3)):\n",
        "    out_loss = 0\n",
        "\n",
        "    num_samples_processed_1=0\n",
        "\n",
        "    for batch_idx, (essay_id, essay_set, essays, prompt, normalized_score) in (enumerate(dataloader)):\n",
        "\n",
        "        # if torch.cuda.is_available():\n",
        "        #     essay_id, essay_set, essays, prompt, normalized_score = essay_id.cuda(), essay_set.cuda(), essays.cuda(), prompt.cuda(), normalized_score.cuda()\n",
        "        # normalized_score = normalized_score.to(device)\n",
        "\n",
        "        # num_samples_processed_1 += essay_id.size(0)\n",
        "\n",
        "        # if num_samples_processed_1 >= 5000:\n",
        "        #   break\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        essays, lengths_batch = preprocess_essay(essays)\n",
        "        essays = essays.to(device)\n",
        "        normalized_score = normalized_score.to(device)\n",
        "        # print(lengths_batch.dtype)\n",
        "        # print(essays.dtype)\n",
        "        out = model_semantic(essays, lengths_batch)\n",
        "\n",
        "\n",
        "        out = out.float()\n",
        "        normalized_score = normalized_score.float()\n",
        "\n",
        "        loss = criteria(out, normalized_score)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        out_loss += loss.item()\n",
        "\n",
        "    train_loss.append(out_loss/len(dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "IiTyBUX7ZRvA",
        "outputId": "aa9669fb-c323-40f1-c5d3-7ee82f8c02c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7d337d5e59c0>]"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs=[1,2,3]\n",
        "\n",
        "plt.plot(epochs,train_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mB_QwzZSeyUf"
      },
      "outputs": [],
      "source": [
        "# torch.save(model_semantic.state_dict(),  \"/content/drive/MyDrive/ire_v2t/semantic_model.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CCganf7HIy2",
        "outputId": "8920a221-6f7d-474b-ada5-534784c9951c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# model_semantic.load_state_dict(torch.load(\"semantic_model_final.pth\"),map_location=torch.device('cpu'))\n",
        "\n",
        "# semantic_model_ = torch.load('semantic_model_final.pth', map_location=torch.device('cpu'))\n",
        "\n",
        "model_semantic.load_state_dict(torch.load(r\"semantic_model_final.pth\",map_location=torch.device('cpu')))\n",
        "\n",
        "\n",
        "# if 'model' in semantic_model_:\n",
        "#     semantic_model_['model'] = semantic_model_['model'].to(torch.device('cpu'))\n",
        "#     semantic_model_['model'].eval()\n",
        "\n",
        "# semantic_model_.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BR_xvIeJrlHP"
      },
      "source": [
        "### CREATING A NEW DATASET BY PERMUTING ESSAYS AND ASSIGNING ZERO GOLD SCORE TO PERMUTED ESSAYS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1CpSfCexVzvo",
        "outputId": "7e2504f0-f46e-4f64-9910-db982c07ef46"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>normalized_score</th>\n",
              "      <th>prompt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>dear local newspaper i think effects computers...</td>\n",
              "      <td>0.6</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>dear caps1 caps2 i believe that using computer...</td>\n",
              "      <td>0.7</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>dear caps1 caps2 caps3 more and more people us...</td>\n",
              "      <td>0.5</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>dear local newspaper caps1 i have found that m...</td>\n",
              "      <td>0.8</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>dear location1 i know having computers has a p...</td>\n",
              "      <td>0.6</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   essay_id  essay_set                                              essay  \\\n",
              "0         1          1  dear local newspaper i think effects computers...   \n",
              "1         2          1  dear caps1 caps2 i believe that using computer...   \n",
              "2         3          1  dear caps1 caps2 caps3 more and more people us...   \n",
              "3         4          1  dear local newspaper caps1 i have found that m...   \n",
              "4         5          1  dear location1 i know having computers has a p...   \n",
              "\n",
              "   normalized_score                                             prompt  \n",
              "0               0.6  More and more people use computers, but not ev...  \n",
              "1               0.7  More and more people use computers, but not ev...  \n",
              "2               0.5  More and more people use computers, but not ev...  \n",
              "3               0.8  More and more people use computers, but not ev...  \n",
              "4               0.6  More and more people use computers, but not ev...  "
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "custom_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "_H-LlLK1V9Ne"
      },
      "outputs": [],
      "source": [
        "def permute_essay(essay):\n",
        "    sentences = essay.split('. ')  # Splitting the essay into sentences using \". \"\n",
        "    random.shuffle(sentences)\n",
        "    return '. '.join(sentences)\n",
        "\n",
        "# Creating a new DataFrame for permuted essays\n",
        "permuted_df = custom_df.copy()\n",
        "permuted_df['essay'] = permuted_df['essay'].apply(permute_essay)\n",
        "permuted_df['normalized_score'] = 0\n",
        "permuted_df['essay_id'] = range(100000, 100000 + len(custom_df))\n",
        "\n",
        "# Concatenating the original and permuted DataFrames\n",
        "combined_df = pd.concat([custom_df[:1000], permuted_df[:1000]]).reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nb40RccyZkQY",
        "outputId": "a57cff0f-e778-47c1-c24d-9bce058d10fb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>normalized_score</th>\n",
              "      <th>prompt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>100995</td>\n",
              "      <td>1</td>\n",
              "      <td>it caps1 is preinstalled into many organizatio...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>100996</td>\n",
              "      <td>1</td>\n",
              "      <td>there adveances in communication through compu...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>100997</td>\n",
              "      <td>1</td>\n",
              "      <td>computers can predict natural disasters and wi...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>100998</td>\n",
              "      <td>1</td>\n",
              "      <td>that is why you should have computers all the ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>100999</td>\n",
              "      <td>1</td>\n",
              "      <td>they help us instanly when we have to find som...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      essay_id  essay_set                                              essay  \\\n",
              "1995    100995          1  it caps1 is preinstalled into many organizatio...   \n",
              "1996    100996          1  there adveances in communication through compu...   \n",
              "1997    100997          1  computers can predict natural disasters and wi...   \n",
              "1998    100998          1  that is why you should have computers all the ...   \n",
              "1999    100999          1  they help us instanly when we have to find som...   \n",
              "\n",
              "      normalized_score                                             prompt  \n",
              "1995               0.0  More and more people use computers, but not ev...  \n",
              "1996               0.0  More and more people use computers, but not ev...  \n",
              "1997               0.0  More and more people use computers, but not ev...  \n",
              "1998               0.0  More and more people use computers, but not ev...  \n",
              "1999               0.0  More and more people use computers, but not ev...  "
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "combined_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "PV78lJtWgEV3"
      },
      "outputs": [],
      "source": [
        "combined_df = combined_df.sample(frac=1, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEoNrMm1ryLO"
      },
      "source": [
        "#### CREATING A DATALOADER FROM NEW DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "WF-MHEN0aNiO"
      },
      "outputs": [],
      "source": [
        "\n",
        "combined_dataset = CustomDataset(combined_df['essay_id'], combined_df['essay_set'], combined_df['essay'], combined_df['prompt'], combined_df['normalized_score'])\n",
        "\n",
        "combined_dataloader = DataLoader(combined_dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_WA7rM5r4ai"
      },
      "source": [
        "## COHERENCE MODEL TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CoherenceScore(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CoherenceScore, self).__init__()\n",
        "\n",
        "        self.bert_emb_dim = 768\n",
        "        self.dropout_prob = 0.5\n",
        "        self.lstm_hidden_size = 1024\n",
        "        self.lstm_layers_num = 2\n",
        "        self.fnn_hidden_size = []\n",
        "        self.bidirectional = False\n",
        "\n",
        "        self.lstm = nn.LSTM(self.bert_emb_dim,\n",
        "                            self.lstm_hidden_size,\n",
        "                            self.lstm_layers_num,\n",
        "                            bidirectional=self.bidirectional,\n",
        "                            batch_first=True)\n",
        "        self.dropout = nn.Dropout(self.dropout_prob)\n",
        "\n",
        "        in_features = self.lstm_hidden_size * 2 if self.bidirectional else self.lstm_hidden_size\n",
        "        layers = []\n",
        "        # for hs in self.fnn_hidden_size:\n",
        "        #     layers.append(nn.Linear(in_features, hs))\n",
        "        #     layers.append(nn.ReLU())\n",
        "        #     layers.append(nn.Dropout(self.dropout_prob))\n",
        "        #     in_features = hs\n",
        "\n",
        "        layers.append(nn.Linear(in_features, 400))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.Dropout(self.dropout_prob))\n",
        "        layers.append(nn.Linear(400, 1))\n",
        "        layers.append(nn.Sigmoid())\n",
        "        self.fnn = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, batch_doc_encodes, batch_doc_sent_nums):\n",
        "        packed_input = pack_padded_sequence(batch_doc_encodes, batch_doc_sent_nums, batch_first=True, enforce_sorted=False)\n",
        "        # print(packed_input.data.shape,\"packed_input\")\n",
        "        packed_output, _ = self.lstm(packed_input)\n",
        "        # print(packed_output.data.shape,\"packed_out\")\n",
        "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
        "        logits = self.fnn(output[:, -1, :]) # Using the output of the last timestep\n",
        "        return logits.squeeze(-1)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "LYlnebo9ccTt"
      },
      "outputs": [],
      "source": [
        "model_coher=CoherenceScore().to(device)\n",
        "adam_optimizer_coher=torch.optim.Adam(model_coher.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
        "criteria=torch.nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm9sLbSccqML",
        "outputId": "f33b5996-c7cd-4a91-ac74-312e69071118"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [44:45<00:00, 537.15s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "optimizer=adam_optimizer_coher\n",
        "batch_size = 32\n",
        "train_loss_coher = []\n",
        "\n",
        "for epoch in tqdm(range(5)):\n",
        "    out_loss = 0\n",
        "    # num_samples_processed_2=0\n",
        "\n",
        "    for batch_idx, (essay_id, essay_set, essays, prompt, normalized_score) in (enumerate(combined_dataloader)):\n",
        "\n",
        "        # if torch.cuda.is_available():\n",
        "        #     essay_id, essay_set, essays, prompt, normalized_score = essay_id.cuda(), essay_set.cuda(), essays.cuda(), prompt.cuda(), normalized_score.cuda()\n",
        "        # normalized_score = normalized_score.to(device)\n",
        "\n",
        "\n",
        "        num_samples_processed_2 += essay_id.size(0)\n",
        "\n",
        "        if num_samples_processed_2 >= 10000:\n",
        "          break\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        essays, lengths_batch = preprocess_essay(essays)\n",
        "        essays = essays.to(device)\n",
        "        normalized_score = normalized_score.to(device)\n",
        "        # print(lengths_batch.dtype)\n",
        "        # print(essays.dtype)\n",
        "        out = model_coher(essays, lengths_batch)\n",
        "\n",
        "\n",
        "        out = out.float()\n",
        "        normalized_score = normalized_score.float()\n",
        "\n",
        "        loss = criteria(out, normalized_score)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        out_loss += loss.item()\n",
        "        # print(f\"Epoch [{epoch + 1}/5], Batch [{batch_idx + 1}/{len(combined_dataloader)}], Batch Loss: {loss.item():.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "    train_loss_coher.append(out_loss/len(combined_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dVvcQcoMZRvF",
        "outputId": "89b6fd47-c9c7-4e55-e0af-9620bc87a23a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7c72b785e9b0>]"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs=[1,2,3,4,5]\n",
        "plt.plot(epochs,train_loss_coher)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zq5naX_HjreD"
      },
      "outputs": [],
      "source": [
        "# torch.save(model_coher.state_dict(),  \"/content/drive/MyDrive/ire_v2t/coherence_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAcH0O0FIPip",
        "outputId": "ed638911-80a7-47ab-941b-c3de03276ceb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# coher_model_ = torch.load('coherence_model_final.pth', map_location=torch.device('cpu'))\n",
        "\n",
        "model_coher.load_state_dict(torch.load(r\"coherence_model_final.pth\",map_location=torch.device('cpu')))\n",
        "\n",
        "# if 'model' in coher_model_:\n",
        "#     coher_model_['model'] = coher_model_['model'].to(torch.device('cpu'))\n",
        "#     coher_model_['model'].eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrvujsuynoe2"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Na6eX-0Qugbv",
        "outputId": "a385a1c7-78ae-4768-9c6e-7acd792c8c74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.005422969174649671, 0.005878951654176368, 0.005782355919967745, 0.005795177073530027, 0.0054640802909161285]\n",
            "[0.11938978388668998, 0.11932287980166692, 0.11760396238357301, 0.11438029886238159, 0.10552108003979638]\n"
          ]
        }
      ],
      "source": [
        "print(train_loss)\n",
        "print(train_loss_coher)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtI1WvyXr-Ff"
      },
      "source": [
        "### CREATING DATASET FOR PROMPT RELEVANT SCORE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "SlnsR7v2dw4_"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "\n",
        "# For each essay, combine with a random set of prompts\n",
        "for index, row in custom_df.iterrows():\n",
        "\n",
        "    num_prompts = np.random.randint(1, 4)\n",
        "\n",
        "    sample_prompts = custom_df[custom_df['essay_set'] != row['essay_set']].sample(num_prompts)\n",
        "\n",
        "    for _, prompt_row in sample_prompts.iterrows():\n",
        "        new_row = row.copy()\n",
        "        new_row['essay'] = prompt_row['prompt'] + \".\" + row['essay']\n",
        "        new_row['normalized_score'] = 0\n",
        "        data.append(new_row)\n",
        "\n",
        "result_df = pd.DataFrame(data).reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "t8jdGekv29mZ"
      },
      "outputs": [],
      "source": [
        "prompt_df=custom_df.copy();\n",
        "prompt_df['essay'] = prompt_df['prompt'] + \" \" + prompt_df['essay']\n",
        "\n",
        "final_prompt_df = pd.concat([prompt_df[:1000], result_df[:1000]], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Nf7cQDmqfkqz"
      },
      "outputs": [],
      "source": [
        "prompt_df=custom_df.copy();\n",
        "prompt_df['essay'] = prompt_df['prompt'] + \" \" + prompt_df['essay']\n",
        "\n",
        "final_prompt_df = pd.concat([prompt_df[:1000], result_df[:1000]], ignore_index=True)\n",
        "final_prompt_df = final_prompt_df.sample(frac=1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-yEqe7XjXaC",
        "outputId": "025385f7-6f7a-4afe-b43b-1792f9a105f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1006"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(final_prompt_df[final_prompt_df['normalized_score'] == 0.0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KmbhhrlG3DqJ",
        "outputId": "6d44b4d8-8075-4f7e-9e19-1234012b9bd1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>normalized_score</th>\n",
              "      <th>prompt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1130</th>\n",
              "      <td>66</td>\n",
              "      <td>1</td>\n",
              "      <td>Read the last paragraph of the story.\\n    \"Wh...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1294</th>\n",
              "      <td>147</td>\n",
              "      <td>1</td>\n",
              "      <td>Censorship in the Libraries\\n    All of us can...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>863</td>\n",
              "      <td>1</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "      <td>0.8</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1459</th>\n",
              "      <td>232</td>\n",
              "      <td>1</td>\n",
              "      <td>Censorship in the Libraries\\n    All of us can...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1126</th>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "      <td>Censorship in the Libraries\\n    All of us can...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      essay_id  essay_set                                              essay  \\\n",
              "1130        66          1  Read the last paragraph of the story.\\n    \"Wh...   \n",
              "1294       147          1  Censorship in the Libraries\\n    All of us can...   \n",
              "860        863          1  More and more people use computers, but not ev...   \n",
              "1459       232          1  Censorship in the Libraries\\n    All of us can...   \n",
              "1126        64          1  Censorship in the Libraries\\n    All of us can...   \n",
              "\n",
              "      normalized_score                                             prompt  \n",
              "1130               0.0  More and more people use computers, but not ev...  \n",
              "1294               0.0  More and more people use computers, but not ev...  \n",
              "860                0.8  More and more people use computers, but not ev...  \n",
              "1459               0.0  More and more people use computers, but not ev...  \n",
              "1126               0.0  More and more people use computers, but not ev...  "
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_prompt_df.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YdYiYBgsFGw"
      },
      "source": [
        "#### CREATING A DATALOADER FOR PROMPT RELEVANCE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "BJzC6y004jb8"
      },
      "outputs": [],
      "source": [
        "prompt_dataset = CustomDataset(final_prompt_df['essay_id'], final_prompt_df['essay_set'], final_prompt_df['essay'], final_prompt_df['prompt'], final_prompt_df['normalized_score'])\n",
        "prompt_dataloader = DataLoader(prompt_dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucSoTEBYsMST"
      },
      "source": [
        "## PROMPT RELEVANCE MODEL TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "1bZ8bno-k31g"
      },
      "outputs": [],
      "source": [
        "class PromptEmbedding(nn.Module):\n",
        "    def __init__(self, pretrained_model_name='bert-base-uncased'):\n",
        "        super(PromptEmbedding, self).__init__()  # Call the super class's __init_ first\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(pretrained_model_name)\n",
        "        self.model = BertModel.from_pretrained(pretrained_model_name, output_hidden_states=True)\n",
        "        self.model.eval()\n",
        "\n",
        "\n",
        "    def get_embedding(self, prompt, essay):\n",
        "        essay = sent_tokenize(essay)\n",
        "        sentence_embeddings = []\n",
        "\n",
        "        for sentence in essay:\n",
        "            processed_sentence = pipeline(sentence)\n",
        "            inputs = self.tokenizer(prompt, sentence, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(**inputs.to(self.device))\n",
        "\n",
        "            hidden_states = outputs.hidden_states[-4:]\n",
        "            # print(\"hidden_states :\",hidden_states[0].shape)\n",
        "\n",
        "            # Concatenate the hidden states along the third dimension\n",
        "            concatenated_hidden_states = torch.cat(hidden_states, dim=1)\n",
        "            # print(\"concatenated_hidden_states :\",concatenated_hidden_states.shape)\n",
        "\n",
        "            # Compute the mean of all tokens embeddings for this sentence along the second dimension\n",
        "            sentence_embedding = torch.mean(concatenated_hidden_states, dim=1).squeeze().cpu().numpy()\n",
        "            # print(\"sentence_embedding :\",sentence_embedding.shape)\n",
        "\n",
        "            sentence_embeddings.append(sentence_embedding)\n",
        "\n",
        "        return np.array(sentence_embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "lsd4BOrwk_0n"
      },
      "outputs": [],
      "source": [
        "prompt_embedder = PromptEmbedding().to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "rjmHgG_Ik9t_"
      },
      "outputs": [],
      "source": [
        "def prompt_essay(prompts, essays):\n",
        "    # print(essays)\n",
        "    essay_embeddings = [torch.tensor(prompt_embedder.get_embedding(prompt, essay)) for prompt, essay in zip(prompts, essays)]\n",
        "\n",
        "    # Find the maximum number of sentences in all essays\n",
        "    max_sentences = max(embed.shape[0] for embed in essay_embeddings)\n",
        "\n",
        "    # Calculate the number of dimensions (features) in the embeddings\n",
        "    num_features = essay_embeddings[0].shape[1]  # Assumes all embeddings have the same number of features\n",
        "\n",
        "    # Pad the sentence embeddings to have the same number of sentences\n",
        "    padded_embeddings = []\n",
        "    for embed in essay_embeddings:\n",
        "        padding = max_sentences - embed.shape[0]\n",
        "        padded_embed = torch.cat((embed, torch.zeros(padding, num_features)), dim=0)\n",
        "        padded_embeddings.append(padded_embed)\n",
        "\n",
        "    embeddings_batch = torch.stack(padded_embeddings)  # batch * sentences * num_features\n",
        "    lengths_batch = torch.tensor([max_sentences] * len(essays), dtype=torch.int64)\n",
        "\n",
        "    return embeddings_batch, lengths_batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "gf47S1-Qk7ML"
      },
      "outputs": [],
      "source": [
        "class PromptScore(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PromptScore, self).__init__()\n",
        "        self.bert_emb_dim = 768\n",
        "        self.dropout_prob = 0.5\n",
        "        self.lstm_hidden_size = 1024\n",
        "        self.lstm_layers_num = 1\n",
        "        self.fnn_hidden_size = []\n",
        "        self.bidirectional = False\n",
        "\n",
        "        self.lstm = nn.LSTM(self.bert_emb_dim,\n",
        "                            self.lstm_hidden_size,\n",
        "                            self.lstm_layers_num,\n",
        "                            bidirectional=self.bidirectional,\n",
        "                            batch_first=True)\n",
        "        self.dropout = nn.Dropout(self.dropout_prob)\n",
        "\n",
        "        in_features = self.lstm_hidden_size * 2 if self.bidirectional else self.lstm_hidden_size\n",
        "        layers = []\n",
        "        for hs in self.fnn_hidden_size:\n",
        "            layers.append(nn.Linear(in_features, hs))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(self.dropout_prob))\n",
        "            in_features = hs\n",
        "\n",
        "        layers.append(nn.Linear(in_features, 400))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.Dropout(self.dropout_prob))\n",
        "        layers.append(nn.Linear(400, 1))\n",
        "        layers.append(nn.Sigmoid())\n",
        "        self.fnn = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, batch_doc_encodes, batch_doc_sent_nums):\n",
        "        packed_input = pack_padded_sequence(batch_doc_encodes, batch_doc_sent_nums, batch_first=True, enforce_sorted=False)\n",
        "        packed_output, _ = self.lstm(packed_input)\n",
        "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
        "        logits = self.fnn(output[:, -1, :]) # Using the output of the last timestep\n",
        "        return logits.squeeze(-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "cCgEpmV_7msX"
      },
      "outputs": [],
      "source": [
        "model_prompt=PromptScore().to(device)\n",
        "adam_optimizer_prompt=torch.optim.Adam(model_prompt.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
        "criteria=torch.nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kH7ng7_8E9y",
        "outputId": "73ae0774-6d46-4d38-9ab1-e9a3ecbec3b5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [57:59<00:00, 1159.73s/it]\n"
          ]
        }
      ],
      "source": [
        "optimizer=adam_optimizer_prompt\n",
        "batch_size = 32\n",
        "train_loss_ = []\n",
        "final_loss=[]\n",
        "epochs = 3\n",
        "import tqdm as tqdm_module  # Change the name to avoid conflict\n",
        "\n",
        "for epoch in tqdm_module.tqdm(range(epochs)):\n",
        "    out_loss = 0\n",
        "    batch_loss=[]\n",
        "    num_samples_processed=0\n",
        "\n",
        "    for essay_id, essay_set, essays, prompt, normalized_score in prompt_dataloader:\n",
        "\n",
        "        num_samples_processed += essay_id.size(0)\n",
        "\n",
        "        if num_samples_processed >= 12000:\n",
        "          break\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        essays, lengths_batch = prompt_essay(prompt, essays)\n",
        "        essays = essays.to(device)\n",
        "        normalized_score = normalized_score.to(device)\n",
        "        # print(essays.is_cuda,lengths_batch.is_cuda)\n",
        "\n",
        "        out = model_prompt(essays, lengths_batch)\n",
        "\n",
        "        out = out.float()\n",
        "        normalized_score = normalized_score.float()\n",
        "\n",
        "        loss = criteria(out, normalized_score)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        out_loss += loss.item()\n",
        "        # print(f\"Epoch [{epoch + 1}/5], Batch [{batch_idx + 1}/{len(prompt_dataloader)}], Batch Loss: {loss.item():.4f}\")\n",
        "\n",
        "\n",
        "    # final_loss.append(batch_loss)\n",
        "    train_loss_.append(out_loss/len(prompt_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "zuD_05piZRvK",
        "outputId": "912519e2-883e-41db-9bbe-62bc0d2019e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.11201139172864338, 0.10900232385075281, 0.10886628015173806]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7c70e8ab0340>]"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj4AAAGdCAYAAAASUnlxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABI+klEQVR4nO3de1xUdf4/8NcZYIbrDCI3US4i3hUwFaKtsJVEa03NUltL1i3b+mqb0kXZMrptUFpSLr91L132UomW2mZpGaKWoRY4XkDJC95QQCRmuMht5vP7A50cAWUQOHN5PR+P84g585kz7w9Hdl774Zw3khBCgIiIiMgBKOQugIiIiKinMPgQERGRw2DwISIiIofB4ENEREQOg8GHiIiIHAaDDxERETkMBh8iIiJyGAw+RERE5DCc5S7AmhiNRpw9exZeXl6QJEnucoiIiKgDhBCorq5GUFAQFIprr+kw+Fzh7NmzCA4OlrsMIiIi6oTTp0+jX79+1xzD4HMFLy8vAC3fOLVaLXM1RERE1BF6vR7BwcGmz/FrYfC5wuVfb6nVagYfIiIiG9ORy1R4cTMRERE5DAYfIiIichgMPkREROQwGHyIiIjIYTD4EBERkcNg8CEiIiKHweBDREREDoPBh4iIiBwGgw8RERE5DAYfIiIichgMPkREROQwOhV8MjMzERYWBldXV8TGxmLPnj3tji0oKMD06dMRFhYGSZKQkZHRasyOHTswefJkBAUFQZIkbNiwwez5pqYmLF68GCNHjoSHhweCgoIwZ84cnD171mxcZWUlZs+eDbVaDW9vbzz88MOoqanpzBSJiIjIDlkcfLKyspCcnIzU1FTk5+cjKioKiYmJKC8vb3N8XV0dwsPDkZ6ejsDAwDbH1NbWIioqCpmZme0eIz8/H0uXLkV+fj7WrVuHoqIi3HPPPWbjZs+ejYKCAmzZsgUbN27Ejh078Oijj1o6xS5X09CMxZ/sx4a9JXKXQkRE5NAkIYSw5AWxsbEYO3Ys/vKXvwAAjEYjgoOD8cQTT2DJkiXXfG1YWBgWLlyIhQsXtl+QJGH9+vWYOnXqNY/1ww8/ICYmBidPnkRISAgOHTqEYcOG4YcffsCYMWMAAJs3b8Zdd92FM2fOICgo6Lpz0+v10Gg00Ol0XfrX2d/9rhivbCyEl6szNj15G/r1cu+yYxMRETk6Sz6/LVrxaWxsRF5eHhISEn45gEKBhIQE5Obmdq7aTtLpdJAkCd7e3gCA3NxceHt7m0IPACQkJEChUGD37t1tHqOhoQF6vd5s6w5JcaEYFeKN6vpmPLVmHwxGi7ImERERdRGLgk9FRQUMBgMCAgLM9gcEBKC0tLRLC7uW+vp6LF68GA888IAp2ZWWlsLf399snLOzM3x8fNqtLS0tDRqNxrQFBwd3S73OTgpkzIyGu9IJu4sr8c9vj3fL+xAREdG12dxdXU1NTZgxYwaEEPjrX/96Q8dKSUmBTqczbadPn+6iKlsL7e2B1MnDAADLvy5CwVldt70XERERtc2i4OPr6wsnJyeUlZWZ7S8rK2v3wuWudDn0nDx5Elu2bDH7PV5gYGCrC6ybm5tRWVnZbm0qlQpqtdps604zxgRjwrAANBkEFmVpUd9k6Nb3IyIiInMWBR+lUonRo0cjOzvbtM9oNCI7OxtxcXFdXtyVLoeeI0eO4JtvvkHv3r3Nno+Li0NVVRXy8vJM+7Zu3Qqj0YjY2Nhura2jJElC2r0j4eupwk9lNXh982G5SyIiInIoFv+qKzk5Gf/4xz/wr3/9C4cOHcLjjz+O2tpazJ07FwAwZ84cpKSkmMY3NjZCq9VCq9WisbERJSUl0Gq1OHr0qGlMTU2NaQwAFBcXQ6vV4tSpUwBaQs99992HH3/8ER9++CEMBgNKS0tRWlqKxsZGAMDQoUMxceJEzJs3D3v27MHOnTuxYMECzJo1q0N3dPWU3p4qLLsvEgDw/s4T+PbIeZkrIiIiciCiE1auXClCQkKEUqkUMTExYteuXabn4uPjRVJSkulxcXGxANBqi4+PN43Jyclpc8zl47R3DAAiJyfHdJwLFy6IBx54QHh6egq1Wi3mzp0rqqurOzwvnU4nAAidTteZb4tFnl9/QIQu3ihi/rxF/Fzb0O3vR0REZK8s+fy2uI+PPeuuPj5tudhowN0rv8Xx87W4a2QgMn97EyRJ6tb3JCIiskfd1seHuo6b0gkZM6PhrJDw5YFSrMtnV2ciIqLuxuAjo8h+3liYMBAAkPq/ApyurJO5IiIiIvvG4COzx8dFYExoL9Q0NCN5jZZdnYmIiLoRg4/MnBQSVsyMhqfKGT+c+Bmrth+TuyQiIiK7xeBjBYJ93E1dnVds+QkHS9jVmYiIqDsw+FiJ+0b3w6QRgWg2Cjy5ei8uNrKrMxERUVdj8LESkiThtWkj4e+lwrHztUjfdEjukoiIiOwOg48V6eWhxLL7owAA/8o9iW1F5dd5BREREVmCwcfKxA/yw+9uCQMAPPPJflTWNspbEBERkR1h8LFCSyYNQYS/J85XNyBl3X6wuTYREVHXYPCxQq4uLV2dXZwkfFVQhrV5Z+QuiYiIyC4w+FipEX01SL5zMADgpf8V4NQFdnUmIiK6UQw+VuzR28MRE+aD2kYDFq3RotlglLskIiIim8bgY8WcFBLenBEFL5Uz8k7+jL9uY1dnIiKiG8HgY+WCfdzx8tThAICM7CPYd7pK3oKIiIhsGIOPDZga3Rd3R/aBwSiwKEuLusZmuUsiIiKySQw+NkCSJPx56ggEql1xvKIWf/6CXZ2JiIg6g8HHRni7K/HmjJauzh/uPoWth8tkroiIiMj2MPjYkF9F+OLhW/sDAJ79ZD8qahpkroiIiMi2MPjYmGcSB2NwgBcqahqx5NMD7OpMRERkAQYfG+Pq4oQVM6OhdFLgm0NlWP3DablLIiIishkMPjZoWJAaTycOAgC8/HkhiitqZa6IiIjINjD42KhHbg1HXHhvXGwyYFEWuzoTERF1BIOPjVJc7urs6gzt6Sr8Jeeo3CURERFZPQYfGxbk7YZXp44AAKzcehT5p36WuSIiIiLrxuBj46ZE98U9UUGmrs61DezqTERE1B4GHzvwypQRCNK44uSFOrz6RaHc5RAREVktBh87oHF3wfIZUZAk4OM9p7GlkF2diYiI2sLgYyduGeCLebeFAwAWf7of5dX1MldERERkfRh87MhTEwZhSKAXKmsbsfiT/ezqTEREdBUGHzuicnbC27NGQemsQE7ReXy4+5TcJREREVkVBh87MzjQC4snDgEAvPpFIY6dr5G5IiIiIuvB4GOH5t4Shl9F9EZ9kxGLsrRoYldnIiIiAAw+dkmhkLD8/iho3Fyw/4wO72QfkbskIiIiq8DgY6f6aNzw52ktXZ0zc44i72SlzBURERHJj8HHjv0mMgj3juoLowAWZe1DDbs6ExGRg2PwsXMvThmOvt5uOFVZh5c/L5C7HCIiIlkx+Ng5tasL3rrU1XnNj2ew+eA5uUsiIiKSDYOPA4gN743H4gcAAFLWHUC5nl2diYjIMTH4OIhFCYMwPEiNn+ua8DS7OhMRkYNi8HEQSmcFMmZGQ+WswI6fzuPfuSflLomIiKjHMfg4kIEBXkiZ1NLV+bUvD+FoebXMFREREfWsTgWfzMxMhIWFwdXVFbGxsdizZ0+7YwsKCjB9+nSEhYVBkiRkZGS0GrNjxw5MnjwZQUFBkCQJGzZsaDVm3bp1mDBhAnr37g1JkqDValuNGTduHCRJMtsee+yxzkzRbs2JC8Ptg/zQ0GzEk6u1aGxmV2ciInIcFgefrKwsJCcnIzU1Ffn5+YiKikJiYiLKy8vbHF9XV4fw8HCkp6cjMDCwzTG1tbWIiopCZmZmu+9bW1uLW2+9Fa+//vo165s3bx7OnTtn2t54442OT84BKBQSlt0XCW93FxSc1SPjm5/kLomIiKjHOFv6grfeegvz5s3D3LlzAQCrVq3CF198gffeew9LlixpNX7s2LEYO3YsALT5PABMmjQJkyZNuub7PvTQQwCAEydOXHOcu7t7uwGLWgSoXZF+70g89t98/HX7MYwb7I+Y/j5yl0VERNTtLFrxaWxsRF5eHhISEn45gEKBhIQE5ObmdnlxnfHhhx/C19cXI0aMQEpKCurq6tod29DQAL1eb7Y5iokj+uC+0f0gBLAoSwt9fZPcJREREXU7i4JPRUUFDAYDAgICzPYHBASgtLS0SwvrjN/+9rf473//i5ycHKSkpOA///kPHnzwwXbHp6WlQaPRmLbg4OAerFZ+qZOHIdjHDSVVF/Hi/9jVmYiI7J/Fv+qyZo8++qjp65EjR6JPnz4YP348jh07hgEDBrQan5KSguTkZNNjvV7vUOHHy9UFK2ZEY8bfcrEuvwTjhwTg7sg+cpdFRETUbSxa8fH19YWTkxPKysrM9peVlVnldTWxsbEAgKNHj7b5vEqlglqtNtsczZgwH/zfuAgAwJ/WH0Cpjl2diYjIflkUfJRKJUaPHo3s7GzTPqPRiOzsbMTFxXV5cTfq8i3vffpwFeNankwYiJF9NdBdbMIzn+yD0ciuzkREZJ8s/lVXcnIykpKSMGbMGMTExCAjIwO1tbWmu7zmzJmDvn37Ii0tDUDLBdGFhYWmr0tKSqDVauHp6YmIiJaVhpqaGrNVmeLiYmi1Wvj4+CAkJAQAUFlZiVOnTuHs2bMAgKKiIgBAYGAgAgMDcezYMXz00Ue466670Lt3b+zfvx+LFi3C7bffjsjIyM5+fxyCi5MCK2ZG4zcrv8W3Ryrwwfcn8Ptb+8tdFhERUdcTnbBy5UoREhIilEqliImJEbt27TI9Fx8fL5KSkkyPi4uLBYBWW3x8vGlMTk5Om2OuPM7777/f5pjU1FQhhBCnTp0St99+u/Dx8REqlUpERESIZ555Ruh0ug7PS6fTCQAWvcae/Dv3hAhdvFEMfO5LcficXu5yiIiIOsSSz29JCP61ysv0ej00Gg10Op1DXu8jhMDvP/gBOUXnMbSPGhvm3wKVs5PcZREREV2TJZ/f/FtdZCJJEl6/LxI+HkocOqfHW1+zqzMREdkXBh8y4+/V0tUZAP7+7XHkHrsgc0VERERdh8GHWpkwPBCzxgZDCOCpNVroLrKrMxER2QcGH2rT0t8MQ2hvd5zV1SP1s4Nyl0NERNQlGHyoTR4qZ6yYGQ0nhYQN2rP4376zcpdERER0wxh8qF03hfTC/Dtaei09v/4AzlZdlLkiIiKiG8PgQ9f0xK8jEBXsDX19M55aw67ORERk2xh86JpcnBTImBkNNxcn5B6/gPd2FstdEhERUacx+NB19ff1wNLfDAMAvLG5CIfO6WWuiIiIqHMYfKhDHogJRsJQfzQajFi4Wov6JoPcJREREVmMwYc6RJIkpE+PhK+nEkVl1Vj+VZHcJREREVmMwYc6zNdThdent/yl+39+V4ydRytkroiIiMgyDD5kkfFDA/Db2BAAwFNr9kFXx67ORERkOxh8yGLP3z0U/X09UKqvx3MbDkAI3uJORES2gcGHLOau/KWr88b95/CZll2diYjINjD4UKdEB3vjyfEDAQBLNxzEmZ/rZK6IiIjo+hh8qNP+b9wAjArxRnVDS1dnA7s6ExGRlWPwoU5zvtTV2V3phN3FlfjHt8flLomIiOiaGHzohoT29kDq5Jauzm9+XYSCszqZKyIiImofgw/dsBljgjFhWACaDIJdnYmIyKox+NANu9zV2c9LhSPlNXh982G5SyIiImoTgw91CR8PJd64r6Wr8/s7T2DHT+dlroiIiKg1Bh/qMncM9secuFAAwNNr9+Hn2kaZKyIiIjLH4ENdKmXSUAzw80B5dQP+tJ5dnYmIyLow+FCXclM6IWPmKDgrJGw6WIpP80vkLomIiMiEwYe63Mh+Giy6cxAA4MX/FeB0Jbs6ExGRdWDwoW7xWPwAjAnthZqGZizK0rKrMxERWQUGH+oWTgoJK2ZGw1PljB9P/oxV24/JXRIRERGDD3WfYB93vHjPcADAii0/4cAZdnUmIiJ5MfhQt5p+U19MGhGIZqPAwqy9uNjIrs5ERCQfBh/qVpIk4bVpI+HvpcKx87VI23RI7pKIiMiBMfhQt+vlocTy+6MAAP/OPYmconKZKyIiIkfF4EM94vZBfvjdLWEAgGc/2Y8LNQ3yFkRERA6JwYd6zJJJQzDQ3xPnqxuQso5dnYmIqOcx+FCPcXVxQsasaLg4Sfi6sAxrfzwjd0lERORgGHyoRw0P0uCpCYMBAC9+XoCTF2plroiIiBwJgw/1uHm3hSOmvw/qGg1YlKVFs8Eod0lEROQgGHyoxzkpJLw1IwpeKmfkn6rC/9vGrs5ERNQzGHxIFv16uePlqS1dnd/OPgLt6Sp5CyIiIofA4EOymRrdF7+J7AODUWBRlhZ1jc1yl0RERHaOwYdkI0kS/jx1JALVriiuqMWfv2BXZyIi6l4MPiQrjbsL3pzR0tX5w92nkH2oTOaKiIjInnUq+GRmZiIsLAyurq6IjY3Fnj172h1bUFCA6dOnIywsDJIkISMjo9WYHTt2YPLkyQgKCoIkSdiwYUOrMevWrcOECRPQu3dvSJIErVbbakx9fT3mz5+P3r17w9PTE9OnT0dZGT9Ird2vInzx8K39AQCLP92PCnZ1JiKibmJx8MnKykJycjJSU1ORn5+PqKgoJCYmory87b+/VFdXh/DwcKSnpyMwMLDNMbW1tYiKikJmZma771tbW4tbb70Vr7/+ertjFi1ahM8//xxr167F9u3bcfbsWdx7772WTZBk8UziYAwO8EJFTSOWfLqfXZ2JiKhbSMLCT5jY2FiMHTsWf/nLXwAARqMRwcHBeOKJJ7BkyZJrvjYsLAwLFy7EwoUL2y9IkrB+/XpMnTq1zedPnDiB/v37Y+/evYiOjjbt1+l08PPzw0cffYT77rsPAHD48GEMHToUubm5uPnmm687N71eD41GA51OB7Vafd3x1LUOndNjyl92otFgRNq9I/FATIjcJRERkQ2w5PPbohWfxsZG5OXlISEh4ZcDKBRISEhAbm5u56rtInl5eWhqajKrbciQIQgJCZG9NuqYoX3UeCaxpavzy58XoriCXZ2JiKhrWRR8KioqYDAYEBAQYLY/ICAApaWlXVqYpUpLS6FUKuHt7W22/1q1NTQ0QK/Xm20kr4dv7Y+48N642GTAwiwtmtjVmYiIupBD39WVlpYGjUZj2oKDg+UuyeEpFBLenBEFtasz9p2uwl+2HpW7JCIisiMWBR9fX184OTm1ulOqrKys3QuXe0pgYCAaGxtRVVVltv9ataWkpECn05m206dP90CldD1B3m54ddpIAMBfco4i/9TPMldERET2wqLgo1QqMXr0aGRnZ5v2GY1GZGdnIy4ursuLs8To0aPh4uJiVltRURFOnTrVbm0qlQpqtdpsI+twT1QQpkQHmbo61zawqzMREd04Z0tfkJycjKSkJIwZMwYxMTHIyMhAbW0t5s6dCwCYM2cO+vbti7S0NAAtF0QXFhaavi4pKYFWq4WnpyciIiIAADU1NTh69JdfaRQXF0Or1cLHxwchIS139lRWVuLUqVM4e/YsgJZQA7Ss9AQGBkKj0eDhhx9GcnIyfHx8oFar8cQTTyAuLq5Dd3SR9Xl5ygj8UFyJkxfq8MrGQqRPj5S7JCIisnWiE1auXClCQkKEUqkUMTExYteuXabn4uPjRVJSkulxcXGxANBqi4+PN43Jyclpc8yVx3n//ffbHJOammoac/HiRfF///d/olevXsLd3V1MmzZNnDt3rsPz0ul0AoDQ6XSd+bZQN/j+aIUIW7JRhC7eKL462PFzSUREjsOSz2+L+/jYM/bxsU5pXx7C33Ych4+HEpsX3gZ/L1e5SyIiIivSbX18iOSQPGEQhvZRo7K2EYs/YVdnIiLqPAYfsnoqZydkzIyG0lmBnKLz+O/uU3KXRERENorBh2zC4EAvLJ44BADw5y8Kcex8jcwVERGRLWLwIZsx95Yw3Brhi/omIxaxqzMREXUCgw/ZDIVCwvL7o6Bxc8H+Mzq8k31E7pKIiMjGMPiQTQnUuOK1S12dM3OO4scTlTJXREREtoTBh2zO3ZF9cO9NfWEUwKI1WlTXN8ldEhER2QgGH7JJL94zHH293XC68iJe/rxQ7nKIiMhGMPiQTVK7umDFzGhIErA27ww2Hzwnd0lERGQDGHzIZsX098Fj8QMAAEvWHUCZvl7mioiIyNox+JBNW5QwCMOD1Kiqa8Iz7OpMRETXweBDNk3prMDbs6KhclZgx0/n8e/ck3KXREREVozBh2xehL8X/nTXUADAa18ewpGyapkrIiIia8XgQ3ZhTlwobh/kh4ZmIxZmadHYzK7ORETUGoMP2QVJkrDsvkj0cndBwVk9Vnzzk9wlERGRFWLwIbsRoHZF2r0tXZ1XbT+GPcXs6kxEROYYfMiuTBzRB/eP7gchgEVZWujZ1ZmIiK7A4EN2J/We4QjxcUdJ1UW8+FmB3OUQEZEVYfAhu+OpcsaKmVFQSMC6vSXYuP+s3CUREZGVYPAhuzQ61Afz74gAADy3/iBKdezqTEREDD5kx/44fiAi+2mgu9iEp9fug9HIrs5ERI6OwYfslouTAitmRsPVRYHvjlbg/e9PyF0SERHJjMGH7NoAP088d/cwAMDrmw+jqJRdnYmIHBmDD9m9B2NDcMdgPzQ2G/Hk6r1oaDbIXRIREcmEwYfsniRJeP2+SPh4KHG4tBpvfc2uzkREjorBhxyCv5cr0i91df77t8eRe+yCzBUREZEcGHzIYUwYHohZY4MhBPDUGi10F9nVmYjI0TD4kENZ+pthCO3tjrO6erzw2UG5yyEioh7G4EMOxUPljBUzo+GkkPCZ9iw+05bIXRIREfUgBh9yODeF9MKCS12dn99wECVVF2WuiIiIegqDDzmkBb+OQHSwN6rrm/H0GnZ1JiJyFAw+5JAud3V2c3FC7vELePe7YrlLIiKiHsDgQw6rv68HXpjc0tV52VdFOHROL3NFRETU3Rh8yKHNGhuMhKEBaDQYsXC1FvVN7OpMRGTPGHzIoUmShPTpI+HrqURRWTWWfVUkd0lERNSNGHzI4fl6qvDGfZEAgHe/K8bOoxUyV0RERN2FwYcIwK+HBGB2bAgA4Kk1+1BV1yhzRURE1B0YfIguee7uoejv64FSfT2e23AQQvAWdyIie8PgQ3SJu9IZGZe6On+x/xw2sKszEZHdYfAhukJUsDcWjh8IAHhhQwHO/Fwnc0VERNSVGHyIrvL4uAG4KcQb1Q3NSF6zDwZ2dSYishsMPkRXcb7U1dlD6YQ9xZX4x7fH5S6JiIi6CIMPURtCe3sgdfJwAMCbXxfhYIlO5oqIiKgrdCr4ZGZmIiwsDK6uroiNjcWePXvaHVtQUIDp06cjLCwMkiQhIyOj1ZgdO3Zg8uTJCAoKgiRJ2LBhQ6sxQgi88MIL6NOnD9zc3JCQkIAjR46Yjbn8Hldu6enpnZkiEe4f0w+JwwPQZBBYmMWuzkRE9sDi4JOVlYXk5GSkpqYiPz8fUVFRSExMRHl5eZvj6+rqEB4ejvT0dAQGBrY5pra2FlFRUcjMzGz3fd944w288847WLVqFXbv3g0PDw8kJiaivr7ebNzLL7+Mc+fOmbYnnnjC0ikSAWjp6px2byT8vFQ4Wl6D9E2H5S6JiIhukMXB56233sK8efMwd+5cDBs2DKtWrYK7uzvee++9NsePHTsWy5Ytw6xZs6BSqdocM2nSJLz66quYNm1am88LIZCRkYHnn38eU6ZMQWRkJP7973/j7NmzrVaHvLy8EBgYaNo8PDwsnSKRiY+HEssudXX+4PsT2PHTeZkrIiKiG2FR8GlsbEReXh4SEhJ+OYBCgYSEBOTm5nZ5cZcVFxejtLTU7H01Gg1iY2NbvW96ejp69+6NUaNGYdmyZWhubm73uA0NDdDr9WYb0dXGDfbHnLhQAMDTa/fh51p2dSYislUWBZ+KigoYDAYEBASY7Q8ICEBpaWmXFnaly8e+3vv+8Y9/xOrVq5GTk4M//OEPeO211/Dss8+2e9y0tDRoNBrTFhwc3D0TIJuXMmkoBvh5oLy6AX9af4BdnYmIbJRd3dWVnJyMcePGITIyEo899hjefPNNrFy5Eg0NDW2OT0lJgU6nM22nT5/u4YrJVrgpnfD2rFFwVkjYdLAUn+azqzMRkS2yKPj4+vrCyckJZWVlZvvLysravXC5K1w+tqXvGxsbi+bmZpw4caLN51UqFdRqtdlG1J4RfTVYdOcgAMCL/yvA6Up2dSYisjUWBR+lUonRo0cjOzvbtM9oNCI7OxtxcXFdXtxl/fv3R2BgoNn76vV67N69+5rvq9VqoVAo4O/v3221kWN5LH4Axob1Qk1DMxZladnVmYjIxjhb+oLk5GQkJSVhzJgxiImJQUZGBmprazF37lwAwJw5c9C3b1+kpaUBaLkgurCw0PR1SUkJtFotPD09ERERAQCoqanB0aNHTe9RXFwMrVYLHx8fhISEQJIkLFy4EK+++ioGDhyI/v37Y+nSpQgKCsLUqVMBALm5udi9ezfuuOMOeHl5ITc3F4sWLcKDDz6IXr163dA3iegyJ4WEt2ZEY9Lb3+LHkz9j1fZjmH9HhNxlERFRR4lOWLlypQgJCRFKpVLExMSIXbt2mZ6Lj48XSUlJpsfFxcUCQKstPj7eNCYnJ6fNMVcex2g0iqVLl4qAgAChUqnE+PHjRVFRken5vLw8ERsbKzQajXB1dRVDhw4Vr732mqivr+/wvHQ6nQAgdDpdZ74t5EA++fG0CF28UQxI+ULsP10ldzlERA7Nks9vSQjennKZXq+HRqOBTqfj9T50TUIIzP8oH18eKEW4nwe+eOI2uCmd5C6LiMghWfL5bVd3dRH1FEmS8OepIxGgVuH4+Vq89uUhuUsiIqIOYPAh6qReHkosvz8KAPCfXSeRc7jtP9tCRETWg8GH6AbcNtAPc38VBgB45pP9uFDTds8oIiKyDgw+RDdo8cQhGOjviYqaBqSsY1dnIiJrxuBDdINcXZyQMSsaLk4Svi4sw5of2QGciMhaMfgQdYHhQRo8NWEwAOClzwtx8kKtzBUREVFbGHyIusi828IR298HdY0GLMzSotlglLskIiK6CoMPURdxUkh4c0YUvFTO2HuqCv9v2zG5SyIioqsw+BB1oX693PHK1BEAgLezj0B7ukregoiIyAyDD1EXmxIdhMlRQTAYBRZlaVHX2Cx3SUREdAmDD1EXkyQJr04ZgT4aVxRX1OLVL9jVmYjIWjD4EHUDjbsL3rzU1fmj3aeQfahM5oqIiAhg8CHqNrdE+OKRW/sDAJ79ZD/OV7OrMxGR3Bh8iLrR04mDMSTQCxdqG7Hk0/3s6kxEJDMGH6JudLmrs9JJgezD5fh4D7s6ExHJicGHqJsNCVTj2YktXZ1f2ViI4+drZK6IiMhxMfgQ9YDf/6o/bhnQGxebDFi0Zh+a2NWZiEgWDD5EPUChkLD8/iioXZ2x73QVVm49KndJREQOicGHqIcEebvh1WkjAQCZOUeRd/JnmSsiInI8DD5EPeieqCBMjW7p6py8RovaBnZ1JiLqSQw+RD3spSkjEKRxxckLdXhlY6Hc5RARORQGH6IepnFzwZszoiFJwOofTuOrglK5SyIichgMPkQyiBvQG4/eHg4ASFl3AOXV9TJXRETkGBh8iGSSfOcgDO2jRmVtI579hF2diYh6AoMPkUxUzk54e1Y0lM4KbCs6j//uOil3SUREdo/Bh0hGgwK8sGTiEADAn788hKPl7OpMRNSdGHyIZPa7W8Jw20Bf1DcZsShLi8ZmdnUmIuouDD5EMlMoJCy7LwoaNxccKNHhnewjcpdERGS3GHyIrECgxhVp97Z0df5/247ixxOVMldERGSfGHyIrMRdI/vg3pv6wiiARWu0qK5vkrskIiK7w+BDZEVeumc4+vVyw+nKi3jpc3Z1JiLqagw+RFbEy9UFb13q6vxJ3hlsOnBO7pKIiOwKgw+RlYnp74PH4wcAAFLWH0CZnl2diYi6CoMPkRVamDAII/qqUVXXhKfX7oPRyK7ORERdgcGHyAopnRXImBkNlbMC3x6pwL9zT8hdEhGRXWDwIbJSEf5eeO7uoQCAtE2HcaSsWuaKiIhsH4MPkRV76OZQxA/yQ0OzEU+uZldnIqIbxeBDZMUkScKy+yLRy90Fhef0eGvLT3KXRERk0xh8iKycv9oVafdGAgD+tuMYdh+/IHNFRES2i8GHyAZMHBGIGWP6QQggec0+6NnVmYioUxh8iGzEC5OHI8THHSVVF/HiZwVyl0NEZJMYfIhshKfKGStmRkEhAev2lmDj/rNyl0REZHM6FXwyMzMRFhYGV1dXxMbGYs+ePe2OLSgowPTp0xEWFgZJkpCRkdFqzI4dOzB58mQEBQVBkiRs2LCh1RghBF544QX06dMHbm5uSEhIwJEjR8zGVFZWYvbs2VCr1fD29sbDDz+MmpqazkyRyCqNDvXB/DsiAADPrT+Ic7qLMldERGRbLA4+WVlZSE5ORmpqKvLz8xEVFYXExESUl5e3Ob6urg7h4eFIT09HYGBgm2Nqa2sRFRWFzMzMdt/3jTfewDvvvINVq1Zh9+7d8PDwQGJiIurrf2nnP3v2bBQUFGDLli3YuHEjduzYgUcffdTSKRJZtT+OH4jIfhroLrKrMxGRxYSFYmJixPz5802PDQaDCAoKEmlpadd9bWhoqFixYsU1xwAQ69evN9tnNBpFYGCgWLZsmWlfVVWVUKlU4uOPPxZCCFFYWCgAiB9++ME0ZtOmTUKSJFFSUtKBmQmh0+kEAKHT6To0nkguR8urxeDnvxShizeKf357XO5yiIhkZcnnt0UrPo2NjcjLy0NCQoJpn0KhQEJCAnJzc7s0kF2puLgYpaWlZu+r0WgQGxtret/c3Fx4e3tjzJgxpjEJCQlQKBTYvXt3m8dtaGiAXq8324hswQA/Tzx/9zAAwOubD6OolF2diYg6wqLgU1FRAYPBgICAALP9AQEBKC0t7dLCrnT52Nd639LSUvj7+5s97+zsDB8fn3ZrS0tLg0ajMW3BwcHdUD1R95gdG4JfD/FHY7MRT67ei4Zmg9wlERFZPYe+qyslJQU6nc60nT59Wu6SiDpMkiS8Pj0SvT2UOFxajTe/ZldnIqLrsSj4+Pr6wsnJCWVlZWb7y8rK2r1wuStcPva13jcwMLDVBdbNzc2orKxstzaVSgW1Wm22EdkSPy8V0qe3dHX+x7fH8f2xCpkrIiKybhYFH6VSidGjRyM7O9u0z2g0Ijs7G3FxcV1e3GX9+/dHYGCg2fvq9Xrs3r3b9L5xcXGoqqpCXl6eaczWrVthNBoRGxvbbbURye3OYQF4ICYYQgBPrdkHXR27OhMRtcfZ0hckJycjKSkJY8aMQUxMDDIyMlBbW4u5c+cCAObMmYO+ffsiLS0NQMsF0YWFhaavS0pKoNVq4enpiYiIln4kNTU1OHr0qOk9iouLodVq4ePjg5CQEEiShIULF+LVV1/FwIED0b9/fyxduhRBQUGYOnUqAGDo0KGYOHEi5s2bh1WrVqGpqQkLFizArFmzEBQUdEPfJCJr9/zdw5B77AJOXKjD0s8O4p0HRsldEhGRderMbWMrV64UISEhQqlUipiYGLFr1y7Tc/Hx8SIpKcn0uLi4WABotcXHx5vG5OTktDnmyuMYjUaxdOlSERAQIFQqlRg/frwoKioyq+vChQvigQceEJ6enkKtVou5c+eK6urqDs+Lt7OTLcs/WSnCU74QoYs3ig17z8hdDhFRj7Hk81sSQrD72SV6vR4ajQY6nY7X+5BNyvjmJ2R8cwRers7YvPB29PV2k7skIqJuZ8nnt0Pf1UVkbxbcEYHoYG9U1zfjqTVadnUmIroKgw+RHXF2UmDFzGi4K52w63gl/vndcblLIiKyKgw+RHamv68Hlv6mpavz8q9+QuFZdiQnIrqMwYfIDs0aG4yEoQFoNBixMGsv6pvY1ZmICGDwIbJLLV2dR8LXU4Wfymqw7KsiuUsiIrIKDD5Edqq3pwpv3DcSAPDud8X47gi7OhMRMfgQ2bFfDwnAgzeHAACeXrsPVXWNMldERCQvBh8iO/fcXcMQ7uuBUn09nlt/EGzdRUSOjMGHyM65KZ2QMSsazgoJXxw4h/V7S+QuiYhINgw+RA4gsp83nhw/EACQ+lkBTlfWyVwREZE8GHyIHMTj4wZgdGgvVDc046k1+2BgV2cickAMPkQOwtlJgRUzouGhdMKeE5X4+w52dSYix8PgQ+RAQnq7I/We4QCAt7YU4WCJTuaKiIh6FoMPkYO5f3Q/JA4PQJNBYGGWll2dicihMPgQORhJkpB2byT8vFQ4Wl6D9E2H5S6JiKjHMPgQOSAfDyWW3RcJAPjg+xPY/tN5mSsiIuoZDD5EDmrcYH8kxYUCAJ5Zuw8/17KrMxHZPwYfIge2ZNJQRPh7ory6ASnrDrCrMxHZPQYfIgfmpnRCxsyWrs6bC0rxSd4ZuUsiIupWDD5EDm5EXw2SJwwCALz4vwKcusCuzkRkvxh8iAh/uH0AYsJ8UNtoQPIaLZoNRrlLIiLqFgw+RAQnhYQ3Z0TBU+WMH0/+jFXbj8ldEhFRt2DwISIAQLCPO1661NU545sj2H+mSt6CiIi6AYMPEZnce1Nf3D2yD5qNLV2dLzayqzMR2RcGHyIykSQJf542AgFqFY6fr8VrXx6SuyQioi7F4ENEZrzdlVh+fxQA4D+7TiLncLnMFRERdR0GHyJq5baBfpj7qzAAwDOf7MeFmgZ5CyIi6iIMPkTUpsUTh2BQgCcqahqwhF2dichOMPgQUZtcXZyQMXMUlE4KbCksw5ofT8tdEhHRDWPwIaJ2DQtS46lLXZ1f+rwQJypqZa6IiOjGMPgQ0TU9cls4bg73QV2jAYvY1ZmIbByDDxFdU0tX52h4uTpj76kqZOawqzMR2S4GHyK6rr7ebnh16ggAwDtbj0B7ukregoiIOonBh4g6ZEp0X0yOCoLBKLBw9V7UNjTLXRIRkcUYfIiow16dMgJ9NK44caEOr37Brs5EZHsYfIiowzTuLnjzUlfnj/ecwjeFZTJXRERkGQYfIrLILRG+mHdbfwDA4k/343w1uzoTke1g8CEiiz2dOBhDAr1wobYRSz7dz67ORGQzGHyIyGIqZydkzIqG0kmB7MPl+GjPKblLIiLqEAYfIuqUIYFqPDtxMADg1Y2HcPx8jcwVERFdH4MPEXXa73/VH7+K6I2LTQYsytKiiV2dicjKMfgQUacpFBKW3x8Ftasz9p3RYeXWo3KXRER0TQw+RHRD+mjc8OdpIwEAf9l6BHknf5a5IiKi9nUq+GRmZiIsLAyurq6IjY3Fnj172h1bUFCA6dOnIywsDJIkISMjo1PHPHbsGKZNmwY/Pz+o1WrMmDEDZWXmPUQuv8eVW3p6ememSEQWmBwVhGmj+sIogOQ1WtSwqzMRWSmLg09WVhaSk5ORmpqK/Px8REVFITExEeXl5W2Or6urQ3h4ONLT0xEYGNipY9bW1mLChAmQJAlbt27Fzp070djYiMmTJ8NoNL+m4OWXX8a5c+dM2xNPPGHpFImoE16aMhx9vd1w8kIdXvm8UO5yiIjaJiwUExMj5s+fb3psMBhEUFCQSEtLu+5rQ0NDxYoVKyw+5ldffSUUCoXQ6XSmMVVVVUKSJLFly5brHr+jdDqdAGD2PkTUcbnHKkTYko0idPFGsfngObnLISIHYcnnt0UrPo2NjcjLy0NCQoJpn0KhQEJCAnJzczsVvDpyzIaGBkiSBJVKZRrj6uoKhUKB7777zux46enp6N27N0aNGoVly5ahubn9JfeGhgbo9XqzjYg67+bw3nj09nAAwJJP96NcXy9zRURE5iwKPhUVFTAYDAgICDDbHxAQgNLS0k4V0JFj3nzzzfDw8MDixYtRV1eH2tpaPP300zAYDDh37pzpNX/84x+xevVq5OTk4A9/+ANee+01PPvss+2+d1paGjQajWkLDg7u1ByI6BfJdw7CsD5q/FzXhGfZ1ZmIrIxN3NXl5+eHtWvX4vPPP4enpyc0Gg2qqqpw0003QaH4ZQrJyckYN24cIiMj8dhjj+HNN9/EypUr0dDQ9t8SSklJgU6nM22nT5/uqSkR2S1TV2dnBbYVncd/d52UuyQiIhOLgo+vry+cnJxa3U1VVlbW7oXLXXXMCRMm4NixYygvL0dFRQX+85//oKSkBOHh4e0eOzY2Fs3NzThx4kSbz6tUKqjVarONiG7coAAvpEwaAgB49YtDOFrOrs5EZB0sCj5KpRKjR49Gdna2aZ/RaER2djbi4uI6VYClx/T19YW3tze2bt2K8vJy3HPPPe0eW6vVQqFQwN/fv1O1EVHnJcWF4baBvmhoNmJh1l40NrOrMxHJz9nSFyQnJyMpKQljxoxBTEwMMjIyUFtbi7lz5wIA5syZg759+yItLQ1Ay8XLhYWFpq9LSkqg1Wrh6emJiIiIDh0TAN5//30MHToUfn5+yM3NxZNPPolFixZh8OCWvxWUm5uL3bt344477oCXlxdyc3OxaNEiPPjgg+jVq9eNfZeIyGKXuzonZuzAwRI93s7+Cc8kDpG7LCJydJ25bWzlypUiJCREKJVKERMTI3bt2mV6Lj4+XiQlJZkeFxcXCwCttvj4+A4fUwghFi9eLAICAoSLi4sYOHCgePPNN4XRaDQ9n5eXJ2JjY4VGoxGurq5i6NCh4rXXXhP19fUdnhdvZyfqel/sPytCF28U/ZdsFHuKL8hdDhHZIUs+vyUheMvFZXq9HhqNBjqdjtf7EHWhp9bsw6f5Z9Cvlxs2PXkbvFxd5C6JiOyIJZ/fNnFXFxHZthfvGYZ+vdxw5ueLeIldnYlIRgw+RNTtvFxdsGJmNBQS8EneGWw6cO76LyIi6gYMPkTUI8aG+eDxcQMAACnrD6CMXZ2JSAYMPkTUY54cPwgj+qpRVdeEp9fug9HISwyJqGcx+BBRj1E6K5AxcxRcXRT49kgF/pV7Qu6SiMjBMPgQUY+K8PfEn+4aCgBI33QYP5VVy1wRETkSBh8i6nEP3RyK+EF+LV2dV2vZ1ZmIegyDDxH1OEmSsOy+SPRyd0HhOT3e2vKT3CURkYNg8CEiWfirXZF2byQA4G87jmHX8QsyV0REjoDBh4hkM3FEIGaOCYYQLd2d9fVNcpdERHaOwYeIZLV08jCE+LijpOoiUj8rkLscIrJzDD5EJCtPlbOpq/P6vSX4fN9ZuUsiIjvG4ENEshsd2gsL7ogAADy3/gDO6S7KXBER2SsGHyKyCk+MH4iofhro65vZ1ZmIug2DDxFZBRcnBVbMjIabixN2Hr2A93YWy10SEdkhBh8ishrhfp54/jctXZ3f+KoIh0v1MldERPaGwYeIrMpvY0Iwfog/Gi91da5vMshdEhHZEQYfIrIqkiQhfXokensocbi0Gm9+XSR3SURkRxh8iMjq+Hmp8Pr0lq7O//yuGN8frZC5IiKyFww+RGSVEoYF4IGYkJauzmv3QVfHrs5EdOMYfIjIaj1/91CE9XbHOV09ln52UO5yiMgOMPgQkdXyuNTV2Ukh4X/7zuIzbYncJRGRjWPwISKrNiqkF/7464EAgOc3HERJFbs6E1HnMfgQkdWbf8cAjArxRnV9M55ao2VXZyLqNAYfIrJ6zk4KrJgRDXelE3Ydr8Q/vzsud0lEZKMYfIjIJoT5euCF3wwDACz7qgiFZ9nVmYgsx+BDRDZj5thg3DksAE0GgYVZe9nVmYgsxuBDRDZDkiSk3zsSvp4q/FRWgzc2s6szEVmGwYeIbEpvTxWW3dfS1fm9ncX49sh5mSsiIlvC4ENENueOIf548OYQAMDTa/ehqq5R5oqIyFYw+BCRTXrurmEI9/NAmb4Bz60/CCF4izsRXR+DDxHZJDelEzJmRsNZIeGLA+ewfi+7OhPR9TH4EJHNiuznjYUJLV2dX/isAKcr62SuiIisHYMPEdm0x8dFYExoL9Q0NOOpNftgYFdnIroGBh8ismlOCgkrZkbDQ+mEPScq8bcdx+QuiYisGIMPEdm8YB93vHjPcADAii0/4WCJTuaKiMhaMfgQkV24b3Q/TBweeKmrs5ZdnYmoTQw+RGQXJEnCa/eOhL+XCkfLa5C+6bDcJRGRFWLwISK74eOhxLL7owAAH3x/Att/YldnIjLH4ENEdiV+kB9+d0sYgJauzpW17OpMRL9g8CEiu7Nk0hBE+HvifHUD/rTuALs6E5EJgw8R2R1Xl5auzi5OEjYXlGJt3hm5SyIiK9Gp4JOZmYmwsDC4uroiNjYWe/bsaXdsQUEBpk+fjrCwMEiShIyMjE4d89ixY5g2bRr8/PygVqsxY8YMlJWVmY2prKzE7NmzoVar4e3tjYcffhg1NTWdmSIR2bgRfTVYdOcgAMBL/yvAqQvs6kxEnQg+WVlZSE5ORmpqKvLz8xEVFYXExESUl5e3Ob6urg7h4eFIT09HYGBgp45ZW1uLCRMmQJIkbN26FTt37kRjYyMmT54Mo9FoOs7s2bNRUFCALVu2YOPGjdixYwceffRRS6dIRHbiD7cPQEyYD2obDVi0Rotmg/H6LyIi+yYsFBMTI+bPn296bDAYRFBQkEhLS7vua0NDQ8WKFSssPuZXX30lFAqF0Ol0pjFVVVVCkiSxZcsWIYQQhYWFAoD44YcfTGM2bdokJEkSJSUlHZqbTqcTAMzeh4hs26kLtWL4C5tF6OKNImPLT6Kx2SB3SUTUxSz5/Ha2JCQ1NjYiLy8PKSkppn0KhQIJCQnIzc3tVPDqyDEbGhogSRJUKpVpjKurKxQKBb777jvTWG9vb4wZM8Y0JiEhAQqFArt378a0adNavXdDQwMaGhpMj/V6fafmQETWK9jHHS9PGY7kNfuw4pufsOKbn+Dm4gSNmwvUbs4t/3V1ufT40ubqbHpset69Zb+nyhmSJMk9LSLqJIuCT0VFBQwGAwICAsz2BwQE4PDhzjUL68gxb775Znh4eGDx4sV47bXXIITAkiVLYDAYcO7cOQBAaWkp/P39zY7h7OwMHx8flJaWtvneaWlpeOmllzpVNxHZjmmj+uJgiR7vf18MIYCLTQZcbDKgtBP/X0chwTwQXf7azflSaHK5KjT9EqLUri5QOvOeEiI5WRR85OLn54e1a9fi8ccfxzvvvAOFQoEHHngAN910ExSKzv+PSEpKCpKTk02P9Xo9goODu6JkIrIikiThhcnD8NzdQ1Fd3wT9xWboLjZBX9/U8t+LTWaPdRebzfZd/rrJIGAUQFVdE6rqmjpVC1ebiORlUfDx9fWFk5NTq7upysrK2r1wuauOOWHCBBw7dgwVFRVwdnaGt7c3AgMDER4eDgAIDAxsdYF1c3MzKisr261NpVKZ/fqMiOybk0KCt7sS3u5Ki18rhEB9k7HtsFTXBH19cxshqiVA6S82obqhGUDXrzZdGaDU7aw0abjaRGRiUfBRKpUYPXo0srOzMXXqVACA0WhEdnY2FixY0KkCLD2mr68vAGDr1q0oLy/HPffcAwCIi4tDVVUV8vLyMHr0aNMYo9GI2NjYTtVGRHSZJElwUzrBTemEALWrxa83GEWHVptaP98SnhoNxi5ZbWprpelyUFJfvdJ0RbDiahPZC4t/1ZWcnIykpCSMGTMGMTExyMjIQG1tLebOnQsAmDNnDvr27Yu0tDQALRcvFxYWmr4uKSmBVquFp6cnIiIiOnRMAHj//fcxdOhQ+Pn5ITc3F08++SQWLVqEwYMHAwCGDh2KiRMnYt68eVi1ahWampqwYMECzJo1C0FBQTf2XSIiukE3utrU0Gy8dlC6RoCqrjdfbSrTN1znHVu7vNrU1krTdX9V58bVJrIeFgefmTNn4vz583jhhRdQWlqK6OhobN682XRx8qlTp8yuuzl79ixGjRplerx8+XIsX74c8fHx2LZtW4eOCQBFRUVISUlBZWUlwsLC8Nxzz2HRokVmtX344YdYsGABxo8fD4VCgenTp+Odd96xdIpERFZFkiS4ujjB1aXzq0019ZauNP3yq7quWG1ydVG0u9JkHpyuClZuLvBUOkOh4GoTdQ1JCP4Rm8v0ej00Gg10Oh3UarXc5RARWYX6JkOnVpp0F39ZbboRCgnwusZK0/V+VadyduqC7wJZM0s+v23iri4iIpLP5dUm/xtYbbJspemXi8Ubm1tWm3SX9neufsU1V5rMLw6/Ili5c7XJHjH4EBFRt3FSSNC4t4SIzjQLubza1GZQqrt2gKpuaIYQQH2TEfVNDSiv7ty1TV6ubaw0XdFm4Fq/quNqk/Vh8CEiIqt1w6tNDVf0ZLJgpamt1abTuGhxDSpnxXVXmtprgOml4mpTd2DwISIiu+SkkEydteVabWpoNqK8unOrTZIEeKmcL60stdO/6apf1WmuCFCuLlxtaguDDxERURtuZLXJaBSo7uRqk/5iExqajRAC0Nc3Q1/fDHRytakjK03mwcn+V5sYfIiIiLqYoitWm0x/LqX5quDUToC6tBJ15WrT+eoGnL+B1aZrBSWzlairApQ1rzYx+BAREVkZ02qTVxesNl0KUB1ZadK1sdp05mfLV5uUl69tamOlaUgfL8yODbX4mF2FwYeIiMiOdN1qU/NVwemKoFR31UrT5T+vUt8EIYDGa6w23T7Ij8GHiIiIrMMvq02Wv9ZoFKhpbG518feVv6oL9nHv+qItwOBDREREXUKhkFqu83F1kbuUdvGvxhEREZHDYPAhIiIih8HgQ0RERA6DwYeIiIgcBoMPEREROQwGHyIiInIYDD5ERETkMBh8iIiIyGEw+BAREZHDYPAhIiIih8HgQ0RERA6DwYeIiIgcBoMPEREROQz+dfYrCCEAAHq9XuZKiIiIqKMuf25f/hy/FgafK1RXVwMAgoODZa6EiIiILFVdXQ2NRnPNMZLoSDxyEEajEWfPnoWXlxckSerSY+v1egQHB+P06dNQq9VdemxrwPnZPnufo73PD7D/OXJ+tq+75iiEQHV1NYKCgqBQXPsqHq74XEGhUKBfv37d+h5qtdpu/0EDnJ89sPc52vv8APufI+dn+7pjjtdb6bmMFzcTERGRw2DwISIiIofB4NNDVCoVUlNToVKp5C6lW3B+ts/e52jv8wPsf46cn+2zhjny4mYiIiJyGFzxISIiIofB4ENEREQOg8GHiIiIHAaDDxERETkMBp9O2LFjByZPnoygoCBIkoQNGzZc9zXbtm3DTTfdBJVKhYiICHzwwQetxmRmZiIsLAyurq6IjY3Fnj17ur74DrB0fuvWrcOdd94JPz8/qNVqxMXF4auvvjIb8+KLL0KSJLNtyJAh3TiLa7N0jtu2bWtVvyRJKC0tNRtnq+fwd7/7XZvzGz58uGmMNZ3DtLQ0jB07Fl5eXvD398fUqVNRVFR03detXbsWQ4YMgaurK0aOHIkvv/zS7HkhBF544QX06dMHbm5uSEhIwJEjR7prGu3qzPz+8Y9/4LbbbkOvXr3Qq1cvJCQktPr319Z5njhxYndOpV2dmeMHH3zQqn5XV1ezMbZ8DseNG9fmz+Hdd99tGmMt5/Cvf/0rIiMjTY0I4+LisGnTpmu+xlp+/hh8OqG2thZRUVHIzMzs0Pji4mLcfffduOOOO6DVarFw4UI88sgjZuEgKysLycnJSE1NRX5+PqKiopCYmIjy8vLumka7LJ3fjh07cOedd+LLL79EXl4e7rjjDkyePBl79+41Gzd8+HCcO3fOtH333XfdUX6HWDrHy4qKiszm4O/vb3rOls/h22+/bTav06dPw8fHB/fff7/ZOGs5h9u3b8f8+fOxa9cubNmyBU1NTZgwYQJqa2vbfc3333+PBx54AA8//DD27t2LqVOnYurUqTh48KBpzBtvvIF33nkHq1atwu7du+Hh4YHExETU19f3xLRMOjO/bdu24YEHHkBOTg5yc3MRHByMCRMmoKSkxGzcxIkTzc7hxx9/3N3TaVNn5gi0dPy9sv6TJ0+aPW/L53DdunVmczt48CCcnJxa/Rxawzns168f0tPTkZeXhx9//BG//vWvMWXKFBQUFLQ53qp+/gTdEABi/fr11xzz7LPPiuHDh5vtmzlzpkhMTDQ9jomJEfPnzzc9NhgMIigoSKSlpXVpvZbqyPzaMmzYMPHSSy+ZHqempoqoqKiuK6wLdWSOOTk5AoD4+eef2x1jT+dw/fr1QpIkceLECdM+az6H5eXlAoDYvn17u2NmzJgh7r77brN9sbGx4g9/+IMQQgij0SgCAwPFsmXLTM9XVVUJlUolPv744+4pvIM6Mr+rNTc3Cy8vL/Gvf/3LtC8pKUlMmTKlGyq8cR2Z4/vvvy80Gk27z9vbOVyxYoXw8vISNTU1pn3WfA579eol/vnPf7b5nDX9/HHFpwfk5uYiISHBbF9iYiJyc3MBAI2NjcjLyzMbo1AokJCQYBpjS4xGI6qrq+Hj42O2/8iRIwgKCkJ4eDhmz56NU6dOyVRh50VHR6NPnz648847sXPnTtN+ezuH7777LhISEhAaGmq231rPoU6nA4BW/+audL2fw+LiYpSWlpqN0Wg0iI2Nlf0cdmR+V6urq0NTU1Or12zbtg3+/v4YPHgwHn/8cVy4cKFLa+2sjs6xpqYGoaGhCA4ObrXCYG/n8N1338WsWbPg4eFhtt/azqHBYMDq1atRW1uLuLi4NsdY088fg08PKC0tRUBAgNm+gIAA6PV6XLx4ERUVFTAYDG2OufoaEluwfPly1NTUYMaMGaZ9sbGx+OCDD7B582b89a9/RXFxMW677TZUV1fLWGnH9enTB6tWrcKnn36KTz/9FMHBwRg3bhzy8/MBwK7O4dmzZ7Fp0yY88sgjZvut9RwajUYsXLgQv/rVrzBixIh2x7X3c3j5/Fz+r7Wdw47O72qLFy9GUFCQ2QfJxIkT8e9//xvZ2dl4/fXXsX37dkyaNAkGg6E7Su+wjs5x8ODBeO+99/DZZ5/hv//9L4xGI2655RacOXMGgH2dwz179uDgwYOtfg6t6RweOHAAnp6eUKlUeOyxx7B+/XoMGzaszbHW9PPHv85OXeqjjz7CSy+9hM8++8zs+pdJkyaZvo6MjERsbCxCQ0OxZs0aPPzww3KUapHBgwdj8ODBpse33HILjh07hhUrVuA///mPjJV1vX/961/w9vbG1KlTzfZb6zmcP38+Dh48KOs1Y92pM/NLT0/H6tWrsW3bNrOLf2fNmmX6euTIkYiMjMSAAQOwbds2jB8/vkvrtkRH5xgXF2e2onDLLbdg6NCh+Nvf/oZXXnmlu8vstM6cw3fffRcjR45ETEyM2X5rOoeDBw+GVquFTqfDJ598gqSkJGzfvr3d8GMtuOLTAwIDA1FWVma2r6ysDGq1Gm5ubvD19YWTk1ObYwIDA3uy1BuyevVqPPLII1izZk2rJc2reXt7Y9CgQTh69GgPVdf1YmJiTPXbyzkUQuC9997DQw89BKVSec2x1nAOFyxYgI0bNyInJwf9+vW75tj2fg4vn5/L/7Wmc2jJ/C5bvnw50tPT8fXXXyMyMvKaY8PDw+Hr62sz5/BqLi4uGDVqlKl+ezmHtbW1WL16dYf+D4Wc51CpVCIiIgKjR49GWloaoqKi8Pbbb7c51pp+/hh8ekBcXByys7PN9m3ZssX0/1yUSiVGjx5tNsZoNCI7O7vd35dam48//hhz587Fxx9/bHbrZXtqampw7Ngx9OnTpweq6x5ardZUvz2cQ6DlTpSjR4926H9w5TyHQggsWLAA69evx9atW9G/f//rvuZ6P4f9+/dHYGCg2Ri9Xo/du3f3+DnszPyAlrtiXnnlFWzevBljxoy57vgzZ87gwoULNnMOr2YwGHDgwAFT/fZwDoGW274bGhrw4IMPXnesnOfwakajEQ0NDW0+Z1U/f116qbSDqK6uFnv37hV79+4VAMRbb70l9u7dK06ePCmEEGLJkiXioYceMo0/fvy4cHd3F88884w4dOiQyMzMFE5OTmLz5s2mMatXrxYqlUp88MEHorCwUDz66KPC29tblJaWWv38PvzwQ+Hs7CwyMzPFuXPnTFtVVZVpzFNPPSW2bdsmiouLxc6dO0VCQoLw9fUV5eXlPT4/ISyf44oVK8SGDRvEkSNHxIEDB8STTz4pFAqF+Oabb0xjbPkcXvbggw+K2NjYNo9pTefw8ccfFxqNRmzbts3s31xdXZ1pzEMPPSSWLFlierxz507h7Owsli9fLg4dOiRSU1OFi4uLOHDggGlMenq68Pb2Fp999pnYv3+/mDJliujfv7+4ePGi1c8vPT1dKJVK8cknn5i9prq6WgjR8m/i6aefFrm5uaK4uFh888034qabbhIDBw4U9fX1PTq/zs7xpZdeEl999ZU4duyYyMvLE7NmzRKurq6ioKDANMaWz+Flt956q5g5c2ar/dZ0DpcsWSK2b98uiouLxf79+8WSJUuEJEni66+/FkJY988fg08nXL61+eotKSlJCNFyu2F8fHyr10RHRwulUinCw8PF+++/3+q4K1euFCEhIUKpVIqYmBixa9eu7p9MGyydX3x8/DXHC9Fy+36fPn2EUqkUffv2FTNnzhRHjx7t2YldwdI5vv7662LAgAHC1dVV+Pj4iHHjxomtW7e2Oq6tnkMhWm4ddXNzE3//+9/bPKY1ncO25gbA7OcqPj7e7N+gEEKsWbNGDBo0SCiVSjF8+HDxxRdfmD1vNBrF0qVLRUBAgFCpVGL8+PGiqKioB2ZkrjPzCw0NbfM1qampQggh6urqxIQJE4Sfn59wcXERoaGhYt68ebIEcyE6N8eFCxeafr4CAgLEXXfdJfLz882Oa8vnUAghDh8+LACYAsSVrOkc/v73vxehoaFCqVQKPz8/MX78eLOarfnnTxJCiC5aPCIiIiKyarzGh4iIiBwGgw8RERE5DAYfIiIichgMPkREROQwGHyIiIjIYTD4EBERkcNg8CEiIiKHweBDREREDoPBh4iIiBwGgw8RERE5DAYfIiIichgMPkREROQw/j/Mx+fLRkShOQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs=[1,2,3]\n",
        "print(train_loss_)\n",
        "plt.plot(epochs,train_loss_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrU9UH6TZRvL"
      },
      "outputs": [],
      "source": [
        "# torch.save(model_prompt.state_dict(),  \"/content/drive/MyDrive/ire_v2t/prompt_model1.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSiw5iQlp_Io",
        "outputId": "dd861a50-e5b7-499b-dac7-d73c7f3547ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# model_prompt.load_state_dict(torch.load(\"/content/drive/MyDrive/ire_v2t/prompt_model_final.pth\"))\n",
        "# prompt_model_ = torch.load('prompt_model_final.pth', map_location=torch.device('cpu'))\n",
        "model_prompt.load_state_dict(torch.load(r\"prompt_model_final.pth\",map_location=torch.device('cpu')))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVvPjOYysXb6"
      },
      "source": [
        "## HANDCRAFTED FEATURES (WORD COUNT,CHARACTER COUNT,MEAN LENGTH ,VARIANCE SCORE,GRAMMATICAL SCORE)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Jl1WpnBdmSq",
        "outputId": "d8ca0171-bb43-47a1-c66a-a9524ec2e427"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.43026706231454\n",
            "5.924662539953674\n",
            "0.8783382789317508\n",
            "337\n",
            "1829\n"
          ]
        }
      ],
      "source": [
        "text = \"Your the best but their are allso. good abvfgc!\"\n",
        "text = ['dear local newspaper i think effects computers have on people are great learning skillsaffects because they give us time to chat with friendsnew people helps us learn about the globeastronomy and keeps us out of troble thing about dont you think so how would you feel if your teenager is always on the phone with friends do you ever time to chat with your friends or buisness partner about things. well now theres a new way to chat the computer theirs plenty of sites on the internet to do so organization1 organization2 caps1 facebook myspace ect. just think now while your setting up meeting with your boss on the computer your teenager is having fun on the phone not rushing to get off cause you want to use it. how did you learn about other countrysstates outside of yours well i have by computerinternet its a new way to learn about what going on in our time you might think your child spends a lot of time on the computer but ask them so question about the economy sea floor spreading or even about the date1s youll be surprise at how much heshe knows. believe it or not the computer is much interesting then in class all day reading out of books. if your child is home on your computer or at a local library its better than being out with friends being fresh or being perpressured to doing something they know isnt right. you might not know where your child is caps2 forbidde in a hospital bed because of a driveby. rather than your child on the computer learning chatting or just playing games safe and sound in your home or community place. now i hope you have reached a point to understand and agree with me because computers can have great effects on you or child because it gives us time to chat with friendsnew people helps us learn about the globe and believe or not keeps us out of troble. thank you for listening.']\n",
        "text = text[0]\n",
        "def get_grammatical_score(text, tool=tool):\n",
        "    size = len(text.split())\n",
        "    num = len(tool.check(text))\n",
        "    # print(size, num)\n",
        "    return (size - num) / size\n",
        "\n",
        "def get_word_count(text):\n",
        "    return len(text.split())\n",
        "\n",
        "def get_char_count(text):\n",
        "    return len(text)\n",
        "\n",
        "def get_mean_score(text):\n",
        "    words = text.split()\n",
        "    word_lengths = [len(word) for word in words]\n",
        "    mean_word_length = sum(word_lengths) / len(word_lengths)\n",
        "    return mean_word_length\n",
        "\n",
        "def get_variance_score(text):\n",
        "    words = text.split()\n",
        "    word_lengths = [len(word) for word in words]\n",
        "    mean_word_length = sum(word_lengths) / len(word_lengths)\n",
        "    variance_word_length = sum((length - mean_word_length) ** 2 for length in word_lengths) / len(word_lengths)\n",
        "    return variance_word_length\n",
        "\n",
        "print(get_mean_score(text))\n",
        "print(get_variance_score(text))\n",
        "print(get_grammatical_score(text))\n",
        "print(get_word_count(text) )\n",
        "print(get_char_count(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "7rob6lzV_hYV",
        "outputId": "68fe3f6c-1f18-4418-90ae-b36c0e2a299f"
      },
      "outputs": [],
      "source": [
        "main_data = pd.DataFrame()\n",
        "from tqdm import tqdm\n",
        "total_rows_123=0\n",
        "\n",
        "for essay_id, essay_set, essays, prompt, normalized_score in tqdm(dataloader):\n",
        "    # num_samples_processed += essay_id.size(0)\n",
        "\n",
        "    total_rows_123 += essay_id.size(0)\n",
        "\n",
        "    if total_rows_123 >= 5000:\n",
        "          break\n",
        "\n",
        "    means, variances, grammaticals, word_counts, char_counts = [], [], [], [], []\n",
        "    for i in range(essay_id.size(0)):\n",
        "        means.append(get_mean_score(essays[i]))\n",
        "        variances.append(get_variance_score(essays[i]))\n",
        "        grammaticals.append(get_grammatical_score(essays[i]))\n",
        "        word_counts.append(get_word_count(essays[i]))\n",
        "        char_counts.append(get_char_count(essays[i]))\n",
        "\n",
        "\n",
        "    val = []\n",
        "    for i in range(essay_id.size(0)):\n",
        "        # print(prompt[i])\n",
        "        # print(essays[i])\n",
        "        val.append(prompt[i]+\".\"+essays[i])\n",
        "\n",
        "    # val = prompt+\".\"+essays\n",
        "    val, lengths_batch = preprocess_essay(val)\n",
        "    val = val.to(device)\n",
        "    essays, lengths_batch = preprocess_essay(essays)\n",
        "    essays = essays.to(device)\n",
        "    out_semantic = model_semantic(essays, lengths_batch)\n",
        "    out_coher = model_coher(essays, lengths_batch)\n",
        "    # normalized_score = normalized_score.to(device)\n",
        "\n",
        "    out_prompt = model_prompt(val, lengths_batch)\n",
        "\n",
        "    out_semantic = out_semantic.cpu().detach().numpy()\n",
        "    out_coher = out_coher.cpu().detach().numpy()\n",
        "    out_prompt = out_prompt.cpu().detach().numpy()\n",
        "    normalized_score = normalized_score.cpu().detach().numpy()\n",
        "\n",
        "    # print(normalized_score_np.is_cuda, word_counts.is_cuda)\n",
        "    temp_df = pd.DataFrame({\n",
        "        'means': means,\n",
        "        'variances': variances,\n",
        "        'grammaticals': grammaticals,\n",
        "        'word_counts': word_counts,\n",
        "        'char_counts': char_counts,\n",
        "        'out_semantic': out_semantic,\n",
        "        'out_coher': out_coher,\n",
        "        'out_prompt': out_prompt,\n",
        "        'normalized_score': normalized_score\n",
        "      })\n",
        "\n",
        "    main_data = pd.concat([main_data, temp_df], ignore_index=True)\n",
        "\n",
        "    # break\n",
        "    # print(type(out_semantic), out_semantic.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "ZL338AADEes4",
        "outputId": "124228d4-4dc7-49f8-e879-dd5255fbf21c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "448\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-483bb72f-0279-4040-a7a9-3fb2e66c6d55\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>means</th>\n",
              "      <th>variances</th>\n",
              "      <th>grammaticals</th>\n",
              "      <th>word_counts</th>\n",
              "      <th>char_counts</th>\n",
              "      <th>out_semantic</th>\n",
              "      <th>out_coher</th>\n",
              "      <th>out_prompt</th>\n",
              "      <th>normalized_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.251572</td>\n",
              "      <td>3.710296</td>\n",
              "      <td>0.886792</td>\n",
              "      <td>159</td>\n",
              "      <td>834</td>\n",
              "      <td>0.503148</td>\n",
              "      <td>0.250939</td>\n",
              "      <td>0.001317</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.262391</td>\n",
              "      <td>4.415116</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>343</td>\n",
              "      <td>1804</td>\n",
              "      <td>0.503094</td>\n",
              "      <td>0.496958</td>\n",
              "      <td>0.011970</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.889831</td>\n",
              "      <td>7.064134</td>\n",
              "      <td>0.889831</td>\n",
              "      <td>118</td>\n",
              "      <td>694</td>\n",
              "      <td>0.503148</td>\n",
              "      <td>0.497052</td>\n",
              "      <td>0.368822</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.238462</td>\n",
              "      <td>3.689290</td>\n",
              "      <td>0.915385</td>\n",
              "      <td>130</td>\n",
              "      <td>680</td>\n",
              "      <td>0.503148</td>\n",
              "      <td>0.250860</td>\n",
              "      <td>0.368800</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.277228</td>\n",
              "      <td>3.804333</td>\n",
              "      <td>0.900990</td>\n",
              "      <td>101</td>\n",
              "      <td>532</td>\n",
              "      <td>0.503148</td>\n",
              "      <td>0.497037</td>\n",
              "      <td>0.000722</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-483bb72f-0279-4040-a7a9-3fb2e66c6d55')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-483bb72f-0279-4040-a7a9-3fb2e66c6d55 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-483bb72f-0279-4040-a7a9-3fb2e66c6d55');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a2cbb35e-0e8b-4fdf-b95d-a9038a7ab25f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a2cbb35e-0e8b-4fdf-b95d-a9038a7ab25f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a2cbb35e-0e8b-4fdf-b95d-a9038a7ab25f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      means  variances  grammaticals  word_counts  char_counts  out_semantic  \\\n",
              "0  4.251572   3.710296      0.886792          159          834      0.503148   \n",
              "1  4.262391   4.415116      0.857143          343         1804      0.503094   \n",
              "2  4.889831   7.064134      0.889831          118          694      0.503148   \n",
              "3  4.238462   3.689290      0.915385          130          680      0.503148   \n",
              "4  4.277228   3.804333      0.900990          101          532      0.503148   \n",
              "\n",
              "   out_coher  out_prompt  normalized_score  \n",
              "0   0.250939    0.001317               1.0  \n",
              "1   0.496958    0.011970               0.6  \n",
              "2   0.497052    0.368822               0.5  \n",
              "3   0.250860    0.368800               0.0  \n",
              "4   0.497037    0.000722               0.5  "
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(len(main_data))\n",
        "main_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvK55_d3KHlK"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = main_data[['means', 'variances', 'grammaticals', 'word_counts', 'char_counts', 'out_semantic', 'out_coher', 'out_prompt']]\n",
        "y = main_data['normalized_score']\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGymP1VMZRvO"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpD17u-gsyvm"
      },
      "source": [
        "### XG BOOST MODEL (SECOND STAGE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwGU-ClVKH2G",
        "outputId": "8cf978e5-b3fe-4dba-be95-0ede3df3e941"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\ttrain-rmse:0.25284\tvalid-rmse:0.24645\n",
            "[1]\ttrain-rmse:0.25193\tvalid-rmse:0.24547\n",
            "[2]\ttrain-rmse:0.25103\tvalid-rmse:0.24461\n",
            "[3]\ttrain-rmse:0.25014\tvalid-rmse:0.24376\n",
            "[4]\ttrain-rmse:0.24926\tvalid-rmse:0.24278\n",
            "[5]\ttrain-rmse:0.24840\tvalid-rmse:0.24196\n",
            "[6]\ttrain-rmse:0.24755\tvalid-rmse:0.24111\n",
            "[7]\ttrain-rmse:0.24672\tvalid-rmse:0.24027\n",
            "[8]\ttrain-rmse:0.24589\tvalid-rmse:0.23939\n",
            "[9]\ttrain-rmse:0.24508\tvalid-rmse:0.23858\n",
            "[10]\ttrain-rmse:0.24428\tvalid-rmse:0.23778\n",
            "[11]\ttrain-rmse:0.24349\tvalid-rmse:0.23694\n",
            "[12]\ttrain-rmse:0.24265\tvalid-rmse:0.23619\n",
            "[13]\ttrain-rmse:0.24183\tvalid-rmse:0.23545\n",
            "[14]\ttrain-rmse:0.24107\tvalid-rmse:0.23469\n",
            "[15]\ttrain-rmse:0.24027\tvalid-rmse:0.23389\n",
            "[16]\ttrain-rmse:0.23948\tvalid-rmse:0.23319\n",
            "[17]\ttrain-rmse:0.23870\tvalid-rmse:0.23250\n",
            "[18]\ttrain-rmse:0.23793\tvalid-rmse:0.23183\n",
            "[19]\ttrain-rmse:0.23723\tvalid-rmse:0.23113\n",
            "[20]\ttrain-rmse:0.23649\tvalid-rmse:0.23056\n",
            "[21]\ttrain-rmse:0.23575\tvalid-rmse:0.22993\n",
            "[22]\ttrain-rmse:0.23503\tvalid-rmse:0.22930\n",
            "[23]\ttrain-rmse:0.23437\tvalid-rmse:0.22864\n",
            "[24]\ttrain-rmse:0.23366\tvalid-rmse:0.22811\n",
            "[25]\ttrain-rmse:0.23297\tvalid-rmse:0.22744\n",
            "[26]\ttrain-rmse:0.23229\tvalid-rmse:0.22694\n",
            "[27]\ttrain-rmse:0.23161\tvalid-rmse:0.22637\n",
            "[28]\ttrain-rmse:0.23099\tvalid-rmse:0.22564\n",
            "[29]\ttrain-rmse:0.23034\tvalid-rmse:0.22516\n",
            "[30]\ttrain-rmse:0.22969\tvalid-rmse:0.22463\n",
            "[31]\ttrain-rmse:0.22909\tvalid-rmse:0.22393\n",
            "[32]\ttrain-rmse:0.22846\tvalid-rmse:0.22340\n",
            "[33]\ttrain-rmse:0.22785\tvalid-rmse:0.22297\n",
            "[34]\ttrain-rmse:0.22727\tvalid-rmse:0.22230\n",
            "[35]\ttrain-rmse:0.22667\tvalid-rmse:0.22186\n",
            "[36]\ttrain-rmse:0.22608\tvalid-rmse:0.22145\n",
            "[37]\ttrain-rmse:0.22553\tvalid-rmse:0.22083\n",
            "[38]\ttrain-rmse:0.22495\tvalid-rmse:0.22036\n",
            "[39]\ttrain-rmse:0.22431\tvalid-rmse:0.21970\n",
            "[40]\ttrain-rmse:0.22368\tvalid-rmse:0.21905\n",
            "[41]\ttrain-rmse:0.22313\tvalid-rmse:0.21862\n",
            "[42]\ttrain-rmse:0.22251\tvalid-rmse:0.21799\n",
            "[43]\ttrain-rmse:0.22196\tvalid-rmse:0.21748\n",
            "[44]\ttrain-rmse:0.22137\tvalid-rmse:0.21687\n",
            "[45]\ttrain-rmse:0.22087\tvalid-rmse:0.21624\n",
            "[46]\ttrain-rmse:0.22037\tvalid-rmse:0.21576\n",
            "[47]\ttrain-rmse:0.21980\tvalid-rmse:0.21517\n",
            "[48]\ttrain-rmse:0.21928\tvalid-rmse:0.21470\n",
            "[49]\ttrain-rmse:0.21877\tvalid-rmse:0.21429\n",
            "[50]\ttrain-rmse:0.21822\tvalid-rmse:0.21373\n",
            "[51]\ttrain-rmse:0.21768\tvalid-rmse:0.21319\n",
            "[52]\ttrain-rmse:0.21715\tvalid-rmse:0.21258\n",
            "[53]\ttrain-rmse:0.21667\tvalid-rmse:0.21220\n",
            "[54]\ttrain-rmse:0.21615\tvalid-rmse:0.21167\n",
            "[55]\ttrain-rmse:0.21563\tvalid-rmse:0.21116\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:726: FutureWarning: Pass `evals` as keyword args.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[56]\ttrain-rmse:0.21515\tvalid-rmse:0.21068\n",
            "[57]\ttrain-rmse:0.21469\tvalid-rmse:0.21013\n",
            "[58]\ttrain-rmse:0.21423\tvalid-rmse:0.20978\n",
            "[59]\ttrain-rmse:0.21375\tvalid-rmse:0.20930\n",
            "[60]\ttrain-rmse:0.21324\tvalid-rmse:0.20884\n",
            "[61]\ttrain-rmse:0.21280\tvalid-rmse:0.20832\n",
            "[62]\ttrain-rmse:0.21231\tvalid-rmse:0.20787\n",
            "[63]\ttrain-rmse:0.21191\tvalid-rmse:0.20738\n",
            "[64]\ttrain-rmse:0.21152\tvalid-rmse:0.20692\n",
            "[65]\ttrain-rmse:0.21109\tvalid-rmse:0.20650\n",
            "[66]\ttrain-rmse:0.21066\tvalid-rmse:0.20608\n",
            "[67]\ttrain-rmse:0.21021\tvalid-rmse:0.20569\n",
            "[68]\ttrain-rmse:0.20982\tvalid-rmse:0.20534\n",
            "[69]\ttrain-rmse:0.20936\tvalid-rmse:0.20500\n",
            "[70]\ttrain-rmse:0.20893\tvalid-rmse:0.20466\n",
            "[71]\ttrain-rmse:0.20853\tvalid-rmse:0.20439\n",
            "[72]\ttrain-rmse:0.20809\tvalid-rmse:0.20406\n",
            "[73]\ttrain-rmse:0.20765\tvalid-rmse:0.20374\n",
            "[74]\ttrain-rmse:0.20728\tvalid-rmse:0.20335\n",
            "[75]\ttrain-rmse:0.20691\tvalid-rmse:0.20301\n",
            "[76]\ttrain-rmse:0.20649\tvalid-rmse:0.20271\n",
            "[77]\ttrain-rmse:0.20615\tvalid-rmse:0.20230\n",
            "[78]\ttrain-rmse:0.20580\tvalid-rmse:0.20206\n",
            "[79]\ttrain-rmse:0.20539\tvalid-rmse:0.20177\n",
            "[80]\ttrain-rmse:0.20504\tvalid-rmse:0.20141\n",
            "[81]\ttrain-rmse:0.20465\tvalid-rmse:0.20114\n",
            "[82]\ttrain-rmse:0.20431\tvalid-rmse:0.20079\n",
            "[83]\ttrain-rmse:0.20399\tvalid-rmse:0.20042\n",
            "[84]\ttrain-rmse:0.20361\tvalid-rmse:0.20013\n",
            "[85]\ttrain-rmse:0.20329\tvalid-rmse:0.19975\n",
            "[86]\ttrain-rmse:0.20295\tvalid-rmse:0.19952\n",
            "[87]\ttrain-rmse:0.20259\tvalid-rmse:0.19932\n",
            "[88]\ttrain-rmse:0.20222\tvalid-rmse:0.19908\n",
            "[89]\ttrain-rmse:0.20186\tvalid-rmse:0.19884\n",
            "[90]\ttrain-rmse:0.20153\tvalid-rmse:0.19866\n",
            "[91]\ttrain-rmse:0.20118\tvalid-rmse:0.19840\n",
            "[92]\ttrain-rmse:0.20086\tvalid-rmse:0.19818\n",
            "[93]\ttrain-rmse:0.20051\tvalid-rmse:0.19793\n",
            "[94]\ttrain-rmse:0.20018\tvalid-rmse:0.19780\n",
            "[95]\ttrain-rmse:0.19984\tvalid-rmse:0.19759\n",
            "[96]\ttrain-rmse:0.19955\tvalid-rmse:0.19730\n",
            "[97]\ttrain-rmse:0.19924\tvalid-rmse:0.19704\n",
            "[98]\ttrain-rmse:0.19891\tvalid-rmse:0.19682\n",
            "[99]\ttrain-rmse:0.19863\tvalid-rmse:0.19660\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
        "\n",
        "param = {\n",
        "    'max_depth': 3,\n",
        "    'eta': 0.01,\n",
        "    'objective': 'reg:squarederror'\n",
        "}\n",
        "num_round = 100\n",
        "\n",
        "bst = xgb.train(param, dtrain, num_round, [(dtrain, 'train'), (dvalid, 'valid')])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "VydEsXI4ZRvP",
        "outputId": "62e503e2-be96-4127-dc49-408734b44c49"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-74ba15cf-78b1-4b37-8654-240a9f08371f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>means</th>\n",
              "      <th>variances</th>\n",
              "      <th>grammaticals</th>\n",
              "      <th>word_counts</th>\n",
              "      <th>char_counts</th>\n",
              "      <th>out_semantic</th>\n",
              "      <th>out_coher</th>\n",
              "      <th>out_prompt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>4.657343</td>\n",
              "      <td>4.840628</td>\n",
              "      <td>0.902098</td>\n",
              "      <td>143</td>\n",
              "      <td>808</td>\n",
              "      <td>0.503148</td>\n",
              "      <td>0.250880</td>\n",
              "      <td>0.003049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>3.879032</td>\n",
              "      <td>4.719238</td>\n",
              "      <td>0.862903</td>\n",
              "      <td>248</td>\n",
              "      <td>1209</td>\n",
              "      <td>0.503147</td>\n",
              "      <td>0.251251</td>\n",
              "      <td>0.350609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>4.572917</td>\n",
              "      <td>6.036350</td>\n",
              "      <td>0.927083</td>\n",
              "      <td>96</td>\n",
              "      <td>534</td>\n",
              "      <td>0.503148</td>\n",
              "      <td>0.250951</td>\n",
              "      <td>0.364186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>4.330769</td>\n",
              "      <td>4.882899</td>\n",
              "      <td>0.869231</td>\n",
              "      <td>390</td>\n",
              "      <td>2078</td>\n",
              "      <td>0.503148</td>\n",
              "      <td>0.250902</td>\n",
              "      <td>0.363380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>4.185393</td>\n",
              "      <td>4.510573</td>\n",
              "      <td>0.859551</td>\n",
              "      <td>178</td>\n",
              "      <td>922</td>\n",
              "      <td>0.503148</td>\n",
              "      <td>0.497050</td>\n",
              "      <td>0.364631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>4.504000</td>\n",
              "      <td>5.945984</td>\n",
              "      <td>0.856000</td>\n",
              "      <td>125</td>\n",
              "      <td>687</td>\n",
              "      <td>0.503148</td>\n",
              "      <td>0.497052</td>\n",
              "      <td>0.368829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>367</th>\n",
              "      <td>4.758621</td>\n",
              "      <td>6.458977</td>\n",
              "      <td>0.908046</td>\n",
              "      <td>174</td>\n",
              "      <td>1001</td>\n",
              "      <td>0.503148</td>\n",
              "      <td>0.497053</td>\n",
              "      <td>0.368818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>4.342857</td>\n",
              "      <td>5.101497</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>105</td>\n",
              "      <td>560</td>\n",
              "      <td>0.503146</td>\n",
              "      <td>0.251026</td>\n",
              "      <td>0.338358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>429</th>\n",
              "      <td>4.654545</td>\n",
              "      <td>4.717025</td>\n",
              "      <td>0.927273</td>\n",
              "      <td>110</td>\n",
              "      <td>621</td>\n",
              "      <td>0.503148</td>\n",
              "      <td>0.497036</td>\n",
              "      <td>0.000965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>4.263636</td>\n",
              "      <td>4.594132</td>\n",
              "      <td>0.863636</td>\n",
              "      <td>110</td>\n",
              "      <td>578</td>\n",
              "      <td>0.503148</td>\n",
              "      <td>0.250868</td>\n",
              "      <td>0.368605</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74ba15cf-78b1-4b37-8654-240a9f08371f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-74ba15cf-78b1-4b37-8654-240a9f08371f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-74ba15cf-78b1-4b37-8654-240a9f08371f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-76f91f85-0bed-4a7a-8b3c-ed3cd520affc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-76f91f85-0bed-4a7a-8b3c-ed3cd520affc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-76f91f85-0bed-4a7a-8b3c-ed3cd520affc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        means  variances  grammaticals  word_counts  char_counts  \\\n",
              "285  4.657343   4.840628      0.902098          143          808   \n",
              "296  3.879032   4.719238      0.862903          248         1209   \n",
              "117  4.572917   6.036350      0.927083           96          534   \n",
              "346  4.330769   4.882899      0.869231          390         2078   \n",
              "70   4.185393   4.510573      0.859551          178          922   \n",
              "..        ...        ...           ...          ...          ...   \n",
              "439  4.504000   5.945984      0.856000          125          687   \n",
              "367  4.758621   6.458977      0.908046          174         1001   \n",
              "57   4.342857   5.101497      0.914286          105          560   \n",
              "429  4.654545   4.717025      0.927273          110          621   \n",
              "24   4.263636   4.594132      0.863636          110          578   \n",
              "\n",
              "     out_semantic  out_coher  out_prompt  \n",
              "285      0.503148   0.250880    0.003049  \n",
              "296      0.503147   0.251251    0.350609  \n",
              "117      0.503148   0.250951    0.364186  \n",
              "346      0.503148   0.250902    0.363380  \n",
              "70       0.503148   0.497050    0.364631  \n",
              "..            ...        ...         ...  \n",
              "439      0.503148   0.497052    0.368829  \n",
              "367      0.503148   0.497053    0.368818  \n",
              "57       0.503146   0.251026    0.338358  \n",
              "429      0.503148   0.497036    0.000965  \n",
              "24       0.503148   0.250868    0.368605  \n",
              "\n",
              "[90 rows x 8 columns]"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(X_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bh_rLEjK0Jn",
        "outputId": "5b95cb2f-5992-405c-d1c0-9dc0a37d1b0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(90,)\n",
            "(90,)\n"
          ]
        }
      ],
      "source": [
        "dpredict = xgb.DMatrix(X_valid)\n",
        "y_pred = bst.predict(dpredict)\n",
        "print(y_pred.shape)\n",
        "print(y_valid.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "Y_BrNpYOdgdL"
      },
      "outputs": [],
      "source": [
        "def get_final_score(essays, prompt):\n",
        "    main_data = pd.DataFrame()\n",
        "\n",
        "    means, variances, grammaticals, word_counts, char_counts = get_mean_score(essays[0]), get_variance_score(essays[0]), get_grammatical_score(essays[0]),get_word_count(essays[0]), get_char_count(essays[0])\n",
        "\n",
        "    val = []\n",
        "    for i in range(1):\n",
        "        val.append(prompt[i]+\".\"+essays[i])\n",
        "\n",
        "    val, lengths_batch = preprocess_essay(val)\n",
        "    val = val.to(device)\n",
        "    essays, lengths_batch = preprocess_essay(essays)\n",
        "    essays = essays.to(device)\n",
        "    out_semantic = model_semantic(essays, lengths_batch)\n",
        "    out_coher = model_coher(essays, lengths_batch)\n",
        "\n",
        "    out_prompt = model_prompt(val, lengths_batch)\n",
        "    out_semantic = out_semantic.cpu().detach().numpy()\n",
        "    out_coher = out_coher.cpu().detach().numpy()\n",
        "    out_prompt = out_prompt.cpu().detach().numpy()\n",
        "\n",
        "    main_data = pd.DataFrame()\n",
        "    temp_df = pd.DataFrame({\n",
        "        'means': means,\n",
        "        'variances': variances,\n",
        "        'grammaticals': grammaticals,\n",
        "        'word_counts': word_counts,\n",
        "        'char_counts': char_counts,\n",
        "        'out_semantic': out_semantic[0],\n",
        "        'out_coher': out_coher[0],\n",
        "        'out_prompt': out_prompt[0],\n",
        "        # 'normalized_score': normalized_score\n",
        "      }, index=[0])\n",
        "\n",
        "    main_data = pd.concat([main_data, temp_df], ignore_index=True)\n",
        "    return main_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGgxALbHEd-U",
        "outputId": "a669e76c-4efa-4a6f-f044-7ac67d3565da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['dear location1 i think that computers have a negative affect on us how many people have acess to a camputer daily in america.. num1 and how many people go on at least an hour a num2. that means that num3 people cant exercise are wasting many are have the posibility of physical caps1 that sound good to you think of everything you done when you write a letter. i got up and got all the materials and sit back down. after in done writing have to put all the materials away and then put the letter in the mailbox and walk all the way back. well this is what i had to do. now think how you write an email sitdown and move your fingers. do you see the difference caps2 instead of getting a good walk to your friends house to talk to you just in himer. did you know that you can literally but from on your computer. instead of around with this that can add anything you your computer gives away information they information lead to that and then everthing you have wouldbe gone. all this so you can go online. believe it or not you can phisically get hurt for being on the computer to long. num4 thing is that when you at a computer caps2 what happened to my grandpa is that when you are in a wood chair all day you can get ardthritis in your muscle caps3 thing th.']\n",
            "['More and more people use computers, but not everyone agrees that this benefits society.\\n    Those who support advances in technology believe that computers have a positive effect on people.\\n    They teach hand-eye coordination, give people the ability to learn about faraway places and people, and\\n    even allow people to talk online with other people. Others have different ideas. Some experts are concerned\\n    that people are spending too much time on their computers and less time exercising, enjoying nature, and interacting with family and friends.\\n    Write a letter to your local newspaper in which you state your opinion on the effects computers have on people. Persuade the readers to agree with you.\\n']\n",
            "[7.]\n"
          ]
        }
      ],
      "source": [
        "idx = 5\n",
        "ess = [custom_df['essay'].iloc[idx]]\n",
        "prp = [custom_df['prompt'].iloc[idx]]\n",
        "\n",
        "print(ess)\n",
        "print(prp)\n",
        "output = get_final_score(ess, prp)\n",
        "# print(\"OUTPUT : \", output.shape)\n",
        "dpredict = xgb.DMatrix(output)\n",
        "y_pred = bst.predict(dpredict)\n",
        "print(np.round(y_pred*10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvzW8tJRZRvR",
        "outputId": "ee5d1807-8d53-477b-9810-6ccbc8f0f65a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(90,)\n",
            "(90,)\n"
          ]
        }
      ],
      "source": [
        "dpredict = xgb.DMatrix(X_valid)\n",
        "y_pred = bst.predict(dpredict)\n",
        "print(y_pred.shape)\n",
        "print(y_valid.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46jZMc_wAegg",
        "outputId": "9c5e2f1c-79ff-4e3e-dc8f-b4b82acea671"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.72445637, 0.6331195 , 0.60143906, 0.6195788 , 0.6562967 ,\n",
              "       0.40604752, 0.74283594, 0.6146975 , 0.3683233 , 0.62999195,\n",
              "       0.53647196, 0.5170419 , 0.7223713 , 0.6562967 , 0.5287334 ,\n",
              "       0.5901383 , 0.654788  , 0.58294   , 0.41709897, 0.7257834 ,\n",
              "       0.7223713 , 0.5666761 , 0.53251123, 0.75335586, 0.5948929 ,\n",
              "       0.69630176, 0.6011568 , 0.5299246 , 0.6331195 , 0.37191918,\n",
              "       0.5616797 , 0.6146975 , 0.51065356, 0.5875014 , 0.6562967 ,\n",
              "       0.63787466, 0.3898539 , 0.6011568 , 0.6390048 , 0.6390048 ,\n",
              "       0.5345443 , 0.6562967 , 0.6592023 , 0.6011568 , 0.35558152,\n",
              "       0.6011568 , 0.68200254, 0.63787466, 0.30846247, 0.6124769 ,\n",
              "       0.38522696, 0.6562967 , 0.6011568 , 0.5089371 , 0.63965464,\n",
              "       0.6179459 , 0.67081434, 0.5881908 , 0.6776051 , 0.73205024,\n",
              "       0.6265197 , 0.5330021 , 0.69630176, 0.64509004, 0.61087674,\n",
              "       0.64759463, 0.6011568 , 0.41311216, 0.6011568 , 0.70763475,\n",
              "       0.5901395 , 0.6011568 , 0.7436579 , 0.72445637, 0.5832388 ,\n",
              "       0.6011568 , 0.6303028 , 0.51065356, 0.5709686 , 0.6102558 ,\n",
              "       0.67690337, 0.6146975 , 0.35558152, 0.6303028 , 0.6011568 ,\n",
              "       0.6026891 , 0.69630176, 0.5802079 , 0.6877897 , 0.5502368 ],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q37KKeNlNcts",
        "outputId": "3b011e66-7136-43b2-d9ae-e43427f6a5b1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_qwk(y_true, y_pred, max_rating=10, min_rating=0):\n",
        "    # Construct confusion matrix\n",
        "    conf_mat = np.zeros((max_rating + 1, max_rating + 1))\n",
        "    for a, p in zip(y_true, y_pred):\n",
        "        conf_mat[a][p] += 1\n",
        "\n",
        "    # Compute observed and expected agreement\n",
        "    num_ratings = max_rating - min_rating + 1\n",
        "    O = 0.0\n",
        "    E = 0.0\n",
        "    for i in range(num_ratings):\n",
        "        for j in range(num_ratings):\n",
        "            # Calculate weight\n",
        "            w = ((i - j) ** 2) / ((max_rating - min_rating) ** 2)\n",
        "            O += w * conf_mat[i][j]\n",
        "            E += w * (np.sum(conf_mat[i, :]) * np.sum(conf_mat[:, j])) / np.sum(conf_mat)\n",
        "\n",
        "    # Compute QWK\n",
        "    return 1.0 - O / E\n",
        "\n",
        "# # Example usage\n",
        "# y_true = np.array(y_valid)\n",
        "# y_pred = np.array(y_pred)\n",
        "# y_true = np.round(y_true*10).astype(int)\n",
        "# y_pred = np.round(y_pred*10).astype(int)\n",
        "\n",
        "\n",
        "# print(compute_qwk(y_true, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jeodh13Fs9bW",
        "outputId": "403161db-7cc7-40c0-918e-bc4ba7396365"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([7, 6, 6, 6, 7, 4, 7, 6, 4, 6, 5, 5, 7, 7, 5, 6, 7, 6, 4, 7, 7, 6,\n",
              "       5, 8, 6, 7, 6, 5, 6, 4, 6, 6, 5, 6, 7, 6, 4, 6, 6, 6, 5, 7, 7, 6,\n",
              "       4, 6, 7, 6, 3, 6, 4, 7, 6, 5, 6, 6, 7, 6, 7, 7, 6, 5, 7, 6, 6, 6,\n",
              "       6, 4, 6, 7, 6, 6, 7, 7, 6, 6, 6, 5, 6, 6, 7, 6, 4, 6, 6, 6, 7, 6,\n",
              "       7, 6])"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mz2isLVFZRvS",
        "outputId": "d09450fe-c00a-4638-d565-5c499e5f66a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Score : 7 -> Real Score :  7.0\n",
            "Predicted Score : 6 -> Real Score :  10.0\n",
            "Predicted Score : 6 -> Real Score :  7.0\n",
            "Predicted Score : 6 -> Real Score :  7.0\n",
            "Predicted Score : 7 -> Real Score :  2.0\n",
            "Predicted Score : 4 -> Real Score :  3.0\n",
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 6 -> Real Score :  6.0\n",
            "Predicted Score : 4 -> Real Score :  2.0\n",
            "Predicted Score : 6 -> Real Score :  7.0\n",
            "Predicted Score : 5 -> Real Score :  6.0\n",
            "Predicted Score : 5 -> Real Score :  3.0\n",
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 5 -> Real Score :  5.0\n",
            "Predicted Score : 6 -> Real Score :  7.0\n",
            "Predicted Score : 7 -> Real Score :  7.0\n",
            "Predicted Score : 6 -> Real Score :  8.0\n",
            "Predicted Score : 4 -> Real Score :  0.0\n",
            "Predicted Score : 7 -> Real Score :  7.0\n",
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 6 -> Real Score :  5.0\n",
            "Predicted Score : 5 -> Real Score :  3.0\n",
            "Predicted Score : 8 -> Real Score :  10.0\n",
            "Predicted Score : 6 -> Real Score :  4.0\n",
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 6 -> Real Score :  8.0\n",
            "Predicted Score : 5 -> Real Score :  5.0\n",
            "Predicted Score : 6 -> Real Score :  8.0\n",
            "Predicted Score : 4 -> Real Score :  3.0\n",
            "Predicted Score : 6 -> Real Score :  7.0\n",
            "Predicted Score : 6 -> Real Score :  8.0\n",
            "Predicted Score : 5 -> Real Score :  5.0\n",
            "Predicted Score : 6 -> Real Score :  5.0\n",
            "Predicted Score : 7 -> Real Score :  6.0\n",
            "Predicted Score : 6 -> Real Score :  8.0\n",
            "Predicted Score : 4 -> Real Score :  0.0\n",
            "Predicted Score : 6 -> Real Score :  8.0\n",
            "Predicted Score : 6 -> Real Score :  8.0\n",
            "Predicted Score : 6 -> Real Score :  8.0\n",
            "Predicted Score : 5 -> Real Score :  5.0\n",
            "Predicted Score : 7 -> Real Score :  10.0\n",
            "Predicted Score : 7 -> Real Score :  5.0\n",
            "Predicted Score : 6 -> Real Score :  8.0\n",
            "Predicted Score : 4 -> Real Score :  3.0\n",
            "Predicted Score : 6 -> Real Score :  9.0\n",
            "Predicted Score : 7 -> Real Score :  6.0\n",
            "Predicted Score : 6 -> Real Score :  8.0\n",
            "Predicted Score : 3 -> Real Score :  0.0\n",
            "Predicted Score : 6 -> Real Score :  3.0\n",
            "Predicted Score : 4 -> Real Score :  2.0\n",
            "Predicted Score : 7 -> Real Score :  4.0\n",
            "Predicted Score : 6 -> Real Score :  6.0\n",
            "Predicted Score : 5 -> Real Score :  3.0\n",
            "Predicted Score : 6 -> Real Score :  8.0\n",
            "Predicted Score : 6 -> Real Score :  5.0\n",
            "Predicted Score : 7 -> Real Score :  5.0\n",
            "Predicted Score : 6 -> Real Score :  4.0\n",
            "Predicted Score : 7 -> Real Score :  10.0\n",
            "Predicted Score : 7 -> Real Score :  10.0\n",
            "Predicted Score : 6 -> Real Score :  8.0\n",
            "Predicted Score : 5 -> Real Score :  5.0\n",
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 6 -> Real Score :  6.0\n",
            "Predicted Score : 6 -> Real Score :  10.0\n",
            "Predicted Score : 6 -> Real Score :  8.0\n",
            "Predicted Score : 6 -> Real Score :  6.0\n",
            "Predicted Score : 4 -> Real Score :  3.0\n",
            "Predicted Score : 6 -> Real Score :  4.0\n",
            "Predicted Score : 7 -> Real Score :  10.0\n",
            "Predicted Score : 6 -> Real Score :  3.0\n",
            "Predicted Score : 6 -> Real Score :  8.0\n",
            "Predicted Score : 7 -> Real Score :  10.0\n",
            "Predicted Score : 7 -> Real Score :  10.0\n",
            "Predicted Score : 6 -> Real Score :  5.0\n",
            "Predicted Score : 6 -> Real Score :  7.0\n",
            "Predicted Score : 6 -> Real Score :  2.0\n",
            "Predicted Score : 5 -> Real Score :  7.0\n",
            "Predicted Score : 6 -> Real Score :  8.0\n",
            "Predicted Score : 6 -> Real Score :  7.0\n",
            "Predicted Score : 7 -> Real Score :  10.0\n",
            "Predicted Score : 6 -> Real Score :  6.0\n",
            "Predicted Score : 4 -> Real Score :  3.0\n",
            "Predicted Score : 6 -> Real Score :  7.0\n",
            "Predicted Score : 6 -> Real Score :  8.0\n",
            "Predicted Score : 6 -> Real Score :  0.0\n",
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 6 -> Real Score :  7.0\n",
            "Predicted Score : 7 -> Real Score :  5.0\n",
            "Predicted Score : 6 -> Real Score :  7.0\n"
          ]
        }
      ],
      "source": [
        "y_true = np.array(y_valid)\n",
        "y_pred = np.array(y_pred)\n",
        "for i in range(len(y_pred)):\n",
        "    print(f\"Predicted Score : {y_pred[i]} -> Real Score :  {np.round(y_true[i]*10)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egjz0Ea0ZRvS"
      },
      "source": [
        "### NOVELITY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UG1boMIZRvS"
      },
      "source": [
        "#### Document and token LEVEL REPRESENTATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAJvg9uzZRvT"
      },
      "outputs": [],
      "source": [
        "class EssayBERTModel(nn.Module):\n",
        "    def __init__(self, bert_model_name='bert-base-uncased', regression_output_size=1):\n",
        "        super(EssayBERTModel, self).__init__()\n",
        "\n",
        "        # BERT model and tokenizer\n",
        "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
        "\n",
        "        # Regression layer with dropout\n",
        "        self.regression_layer = nn.Sequential(\n",
        "            nn.Linear(2 * self.bert.config.hidden_size, 512),  # Adjust the size as needed\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(512, regression_output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_text):\n",
        "        # Tokenize input essay\n",
        "        tokens = self.tokenizer.encode_plus(input_text, add_special_tokens=True, return_tensors='pt', max_length=512, truncation=True, padding='max_length')\n",
        "        input_ids = tokens['input_ids']\n",
        "        token_type_ids = tokens['token_type_ids']\n",
        "        attention_mask = tokens['attention_mask']\n",
        "\n",
        "        # Obtain token-scale and document-scale representations\n",
        "        outputs = self.bert(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Max pooling over the sequence outputs for token-scale representation\n",
        "        token_representation, _ = torch.max(outputs.last_hidden_state, dim=1)\n",
        "\n",
        "        # Document-scale representation (pooler output)\n",
        "        document_representation = outputs.pooler_output\n",
        "\n",
        "        # Concatenate the two representations\n",
        "        concatenated_representation = torch.cat([document_representation, token_representation], dim=1)\n",
        "\n",
        "        # Pass through the regression layer\n",
        "        output_scores = self.regression_layer(concatenated_representation)\n",
        "\n",
        "        return output_scores\n",
        "\n",
        "# Example usage\n",
        "model = EssayBERTModel(regression_output_size=1)\n",
        "\n",
        "# Input essay text\n",
        "input_text = \"Your essay text goes here.\"\n",
        "\n",
        "# Obtain output scores\n",
        "output_scores = model(input_text)\n",
        "\n",
        "# Print the output scores\n",
        "print(\"Output Scores:\", output_scores)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuTH9na7ZRvT"
      },
      "source": [
        "#### SEGEMENT SCALE REPRESENTATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rN6UDtw3ZRvT"
      },
      "outputs": [],
      "source": [
        "class SegmentScaleEssayModel(nn.Module):\n",
        "    def __init__(self, bert_model, lstm_hidden_size, segment_scales):\n",
        "        super(SegmentScaleEssayModel, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(bert_model)\n",
        "        self.lstm = nn.LSTM(input_size=768, hidden_size=lstm_hidden_size, batch_first=True, dropout=0.1)\n",
        "        self.attention_pooling = nn.Linear(lstm_hidden_size, 1)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        self.segment_scales = segment_scales\n",
        "\n",
        "        # Create dense regression layers for each segment-scale with dropout\n",
        "        self.regression_layers = nn.ModuleList([nn.Sequential(\n",
        "            nn.Linear(lstm_hidden_size, 512),  # Adjust the size as needed\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(512, 1)\n",
        "        ) for _ in segment_scales])\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # Step 1: BERT Processing\n",
        "        print(input_ids.shape)\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        sequence_outputs = outputs.last_hidden_state\n",
        "\n",
        "        print(sequence_outputs.shape)\n",
        "        sequence_outputs = sequence_outputs.view(1, -1, 768)\n",
        "\n",
        "        # Step 2: LSTM Processing\n",
        "        lstm_outputs, _ = self.lstm(sequence_outputs)\n",
        "\n",
        "        # Step 3: Attention Pooling\n",
        "        attention_scores = self.tanh(self.attention_pooling(lstm_outputs))\n",
        "        attention_weights = self.softmax(attention_scores)\n",
        "        segment_scale_representation = torch.sum(attention_weights * lstm_outputs, dim=1)\n",
        "\n",
        "        return segment_scale_representation\n",
        "\n",
        "    def segment_scale_representation(self, input_text, max_tokens):\n",
        "        # Tokenize and obtain input_ids, attention_mask\n",
        "        tokenized_input = tokenizer(input_text, return_tensors='pt', max_length=max_tokens, truncation=True, padding='max_length')\n",
        "\n",
        "        input_ids = tokenized_input['input_ids']\n",
        "        attention_mask = tokenized_input['attention_mask']\n",
        "\n",
        "        # Initialize a list to store segment representations and scores\n",
        "        segment_representations = []\n",
        "        segment_scores = []\n",
        "\n",
        "        for scale in self.segment_scales:\n",
        "            # Calculate the number of segments for each scale\n",
        "            num_segments = (input_ids.size(1) + scale - 1) // scale\n",
        "\n",
        "            # Pad the input_ids and attention_mask to fit the segments\n",
        "            pad_tokens = num_segments * scale - input_ids.size(1)\n",
        "            input_ids_padded = F.pad(input_ids, (0, pad_tokens), value=tokenizer.pad_token_id)\n",
        "            attention_mask_padded = F.pad(attention_mask, (0, pad_tokens), value=0)\n",
        "\n",
        "            # Reshape input_ids and attention_mask into segments\n",
        "            segment_input_ids = input_ids_padded.view(-1, scale)\n",
        "            segment_attention_mask = attention_mask_padded.view(-1, scale)\n",
        "\n",
        "            # Forward pass through the model for each segment-scale\n",
        "            segment_output = self.forward(segment_input_ids, segment_attention_mask)\n",
        "\n",
        "            # print(segment_output.shape)\n",
        "            segment_representations.append(segment_output)\n",
        "\n",
        "            # Apply dense regression layer for each segment-scale\n",
        "            segment_score = self.regression_layers[self.segment_scales.index(scale)](segment_output)\n",
        "            # print(segment_score)\n",
        "            segment_scores.append(segment_score)\n",
        "\n",
        "        # Concatenate segment scores\n",
        "        final_scores = torch.cat(segment_scores, dim=1)\n",
        "\n",
        "        # Sum scores across segment-scales to get the final score\n",
        "        final_score = torch.sum(final_scores, dim=1)\n",
        "\n",
        "        return final_score\n",
        "\n",
        "# Example usage:\n",
        "model = SegmentScaleEssayModel(bert_model='bert-base-uncased', lstm_hidden_size=256, segment_scales=[5, 10, 25])\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Example essay\n",
        "essay = \"Your essay text goes here.\"\n",
        "\n",
        "# Set the maximum number of tokens\n",
        "max_tokens = 50\n",
        "\n",
        "# Get the segment-scale essay representation\n",
        "final_score = model.segment_scale_representation(essay, max_tokens)\n",
        "\n",
        "print(\"Final essay score:\", final_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MVIffLRZRvU"
      },
      "source": [
        "#### Combined Representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7idcSRlqZRvU"
      },
      "outputs": [],
      "source": [
        "class CombinedEssayModel(nn.Module):\n",
        "    def __init__(self, bert_model, lstm_hidden_size, segment_scales, regression_output_size=1):\n",
        "        super(CombinedEssayModel, self).__init__()\n",
        "\n",
        "        # Segment-scale model\n",
        "        self.segment_scale_model = SegmentScaleEssayModel(bert_model, lstm_hidden_size, segment_scales)\n",
        "\n",
        "        # Document-scale and Token-scale model\n",
        "        self.essay_bert_model = EssayBERTModel(bert_model, regression_output_size)\n",
        "\n",
        "    def forward(self, input_text, max_tokens):\n",
        "        # Get segment-scale representation\n",
        "        segment_scale_representation_score = self.segment_scale_model.segment_scale_representation(input_text, max_tokens)\n",
        "\n",
        "        # Get document-scale and token-scale representation\n",
        "        essay_representation_score = self.essay_bert_model(input_text)\n",
        "\n",
        "        score=essay_representation_score+segment_scale_representation_score\n",
        "        # Combine the representations (you can use any operation that suits your task)\n",
        "\n",
        "        return score\n",
        "\n",
        "# Example usage:\n",
        "combined_model = CombinedEssayModel(bert_model='bert-base-uncased', lstm_hidden_size=256, segment_scales=[5, 10, 25], regression_output_size=1)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Example essay\n",
        "essay = \"Your essay text goes here.\"\n",
        "\n",
        "# Set the maximum number of tokens\n",
        "max_tokens = 50\n",
        "\n",
        "# Get the final combined essay representation\n",
        "final_representation = combined_model(essay, max_tokens)\n",
        "\n",
        "print(\"Final combined essay score:\", final_representation)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6ABgDhXZRvV"
      },
      "source": [
        "#### LOSS FUNCTION CONSISTING OF MSE,SIM,MRR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "J3vI93ZkZRvV"
      },
      "outputs": [],
      "source": [
        "class CustomLoss(nn.Module):\n",
        "    def __init__(self, alpha, beta, gamma):\n",
        "        super(CustomLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, predicted_scores, labels):\n",
        "        # Convert predicted_scores and labels to 1D tensors\n",
        "        predicted_scores = predicted_scores.view(-1)\n",
        "        labels = labels.view(-1)\n",
        "\n",
        "        # SIM loss\n",
        "        sim_loss = 1 - F.cosine_similarity(predicted_scores, labels, dim=0)\n",
        "\n",
        "        # MR loss\n",
        "        mr_loss = F.mse_loss(predicted_scores, labels)\n",
        "\n",
        "        # Coherence loss\n",
        "        coherence_loss = torch.mean(torch.abs(predicted_scores - labels))\n",
        "\n",
        "        # Combine losses\n",
        "        loss = self.alpha * sim_loss + self.beta * mr_loss + self.gamma * coherence_loss\n",
        "\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Xn-0cLrhZRvV"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xc-57TETZRvW"
      },
      "outputs": [],
      "source": [
        "# model_combined = CombinedEssayModel(bert_model='bert-base-uncased', lstm_hidden_size=256, segment_scales=[20,50,100], regression_output_size=1)\n",
        "# criterion = CustomLoss(0.5, 0.5, 0.2)\n",
        "\n",
        "# max_tokens = 120\n",
        "\n",
        "# learning_rate = 6e-5\n",
        "# beta1 = 0.9\n",
        "# beta2 = 0.999\n",
        "# weight_decay = 0.005\n",
        "\n",
        "# # Set up the optimizer\n",
        "# optimizer_model = optim.Adam(model_combined.parameters(), lr=learning_rate, betas=(beta1, beta2), weight_decay=weight_decay)\n",
        "\n",
        "# for epoch in range(1):\n",
        "#     out_loss = 0\n",
        "\n",
        "#     num_samples_processed_1=0\n",
        "\n",
        "#     for batch_idx, (essay_id, essay_set, essays, prompt, normalized_score) in tqdm(enumerate(dataloader)):\n",
        "\n",
        "#         # if torch.cuda.is_available():\n",
        "#         #     essay_id, essay_set, essays, prompt, normalized_score = essay_id.cuda(), essay_set.cuda(), essays.cuda(), prompt.cuda(), normalized_score.cuda()\n",
        "#         # normalized_score = normalized_score.to(device)\n",
        "\n",
        "\n",
        "\n",
        "#         num_samples_processed_1 += essay_id.size(0)\n",
        "\n",
        "#         if num_samples_processed_1 >= 1000:\n",
        "#           break\n",
        "\n",
        "#         optimizer_model.zero_grad()\n",
        "\n",
        "#         # essays, lengths_batch = preprocess_essay(essays)\n",
        "#         # essays = essays.to(device)\n",
        "#         normalized_score = normalized_score.to(device)\n",
        "#         normalized_score = normalized_score.view(1, -1)\n",
        "\n",
        "#         # print(lengths_batch.dtype)\n",
        "#         # print(essays.dtype)\n",
        "#         # print(essays)\n",
        "\n",
        "#         out = model_combined(essays, max_tokens)\n",
        "\n",
        "#         # print(out)\n",
        "\n",
        "\n",
        "#         out = out.float()\n",
        "#         out = out.view(1, -1)\n",
        "\n",
        "#         normalized_score = normalized_score.float()\n",
        "\n",
        "#         loss = criterion(out, normalized_score)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         out_loss += loss.item()\n",
        "\n",
        "\n",
        "#         print(f\"Epoch [{epoch + 1}/5], Batch [{batch_idx + 1}/{len(dataloader)}], Batch Loss: {loss.item():.4f}\")\n",
        "\n",
        "\n",
        "#     # train_loss.append(out_loss/len(dataloader))\n",
        "\n",
        "\n",
        "# # Save the best model\n",
        "# # torch.save(model.state_dict(), 'best_model.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rUsZvu5ZRvW",
        "outputId": "c43c2a39-3d80-442a-b7fc-10fd916dd04d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pchhl\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final essay scores (batch): tensor([[-0.0013],\n",
            "        [-0.0023]], grad_fn=<MeanBackward1>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "class SegmentScaleEssayModelo(nn.Module):\n",
        "    def __init__(self, bert_model, lstm_hidden_size, segment_scales):\n",
        "        super(SegmentScaleEssayModelo, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(bert_model)\n",
        "        self.lstm = nn.LSTM(input_size=768, hidden_size=lstm_hidden_size, batch_first=True, dropout=0.1)\n",
        "        self.attention_pooling = nn.Linear(lstm_hidden_size, 1)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        self.segment_scales = segment_scales\n",
        "        self.lstm_hidden=lstm_hidden_size\n",
        "\n",
        "        for param in self.bert.parameters():\n",
        "             param.requires_grad = False\n",
        "        # Create dense regression layers for each segment-scale with dropout\n",
        "        self.regression_layers = nn.ModuleList([nn.Sequential(\n",
        "            nn.Linear(lstm_hidden_size, 512),  # Adjust the size as needed\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(512, 1)\n",
        "        ) for _ in segment_scales])\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "\n",
        "        batch_size, num_segments, max_tokens = input_ids.size()\n",
        "\n",
        "        # Reshape input_ids and attention_mask for BERT processing\n",
        "        input_ids_flat = input_ids.view(batch_size * num_segments, max_tokens)\n",
        "        attention_mask_flat = attention_mask.view(batch_size * num_segments, max_tokens)\n",
        "\n",
        "        # Step 1: BERT Processing\n",
        "        outputs = self.bert(input_ids_flat, attention_mask=attention_mask_flat)\n",
        "        sequence_outputs = outputs.last_hidden_state\n",
        "\n",
        "        # Reshape sequence_outputs back to 3D\n",
        "        sequence_outputs = sequence_outputs.view(batch_size, num_segments, max_tokens, -1)\n",
        "\n",
        "        # Initialize a list to store segment outputs\n",
        "        segment_outputs = []\n",
        "\n",
        "        for segment_index in range(num_segments):\n",
        "            # Select the current segment from the 3D tensor\n",
        "            current_segment = sequence_outputs[:, segment_index, :, :]\n",
        "\n",
        "            # Step 2: LSTM Processing for the current segment\n",
        "            lstm_outputs, _ = self.lstm(current_segment)\n",
        "\n",
        "            # Step 3: Attention Pooling for the current segment\n",
        "            attention_scores = self.tanh(self.attention_pooling(lstm_outputs))\n",
        "            attention_weights = self.softmax(attention_scores)\n",
        "            segment_scale_representation = torch.sum(attention_weights * lstm_outputs, dim=1)\n",
        "\n",
        "            # Append the segment representation to the list\n",
        "            segment_outputs.append(segment_scale_representation)\n",
        "\n",
        "        # Concatenate segment outputs to get the final representation\n",
        "\n",
        "        final_representation = torch.cat(segment_outputs, dim=1)\n",
        "\n",
        "        final_representation=final_representation.reshape(batch_size,num_segments,self.lstm_hidden)\n",
        "\n",
        "        # print(final_representation.shape)\n",
        "\n",
        "        return final_representation\n",
        "\n",
        "    def segment_scale_representation(self, input_ids, attention_mask):\n",
        "        # Forward pass through the model for each segment-scale\n",
        "\n",
        "        segment_outputs = []\n",
        "        for scale in self.segment_scales:\n",
        "            # Calculate the number of segments for each scale\n",
        "            num_segments = (input_ids.size(1) + scale - 1) // scale\n",
        "\n",
        "            # Pad the input_ids and attention_mask to fit the segments\n",
        "            pad_tokens = num_segments * scale - input_ids.size(1)\n",
        "            input_ids_padded = F.pad(input_ids, (0, pad_tokens), value=tokenizer.pad_token_id)\n",
        "            attention_mask_padded = F.pad(attention_mask, (0, pad_tokens), value=0)\n",
        "\n",
        "            # Reshape input_ids and attention_mask into segments\n",
        "            segment_input_ids = input_ids_padded.view(-1, num_segments, scale)  # Updated this line\n",
        "            # print(scale)\n",
        "            # print(segment_input_ids.shape)\n",
        "            segment_attention_mask = attention_mask_padded.view(-1, num_segments, scale)  # Updated this line\n",
        "\n",
        "\n",
        "            # Forward pass through the model for each segment-scale\n",
        "            segment_output = self.forward(segment_input_ids, segment_attention_mask)\n",
        "            segment_outputs.append(segment_output)\n",
        "\n",
        "        # Concatenate segment outputs along the sequence dimension\n",
        "        final_representation = torch.cat(segment_outputs, dim=1)\n",
        "\n",
        "        # Apply dense regression layer for each segment-scale\n",
        "        segment_scores = [layer(final_representation) for layer in self.regression_layers]\n",
        "\n",
        "        # Concatenate segment scores\n",
        "        final_scores = torch.cat(segment_scores, dim=1)\n",
        "\n",
        "        # Sum scores across segment-scales to get the final score\n",
        "        final_score = torch.mean(final_scores, dim=1)\n",
        "\n",
        "\n",
        "        return final_score\n",
        "\n",
        "# Example usage with batched input:\n",
        "model = SegmentScaleEssayModelo(bert_model='bert-base-uncased', lstm_hidden_size=256, segment_scales=[5, 10, 25])\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Example essays\n",
        "essays = [\"Your essay text goes here.\", \"Another essay text.\"]\n",
        "\n",
        "# Tokenize and obtain input_ids, attention_mask\n",
        "tokenized_input = tokenizer(essays, return_tensors='pt', max_length=50, truncation=True, padding='max_length')\n",
        "\n",
        "input_ids = tokenized_input['input_ids']\n",
        "attention_mask = tokenized_input['attention_mask']\n",
        "\n",
        "# Get the segment-scale essay representation for the batch\n",
        "final_scores_batch = model.segment_scale_representation(input_ids, attention_mask)\n",
        "\n",
        "print(\"Final essay scores (batch):\", final_scores_batch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EA7_6B0CZRvX",
        "outputId": "a42bd640-c935-4d36-b4fb-52931758f7ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output Scores (Batch): tensor([[-0.2355],\n",
            "        [-0.2300]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "class EssayBERTModel_(nn.Module):\n",
        "    def __init__(self, bert_model_name='bert-base-uncased', regression_output_size=1):\n",
        "        super(EssayBERTModel_, self).__init__()\n",
        "\n",
        "        # BERT model and tokenizer\n",
        "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
        "\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Regression layer with dropout\n",
        "        self.regression_layer = nn.Sequential(\n",
        "            nn.Linear(2 * self.bert.config.hidden_size, 512),\n",
        "            nn.ReLU(),\n",
        "            # nn.Dropout(0.1),\n",
        "            nn.Linear(512, regression_output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self,essays):\n",
        "        # Tokenize input essay\n",
        "\n",
        "        tokenized_input = tokenizer(essays, return_tensors='pt', max_length=512, truncation=True, padding='max_length')\n",
        "\n",
        "        input_ids = tokenized_input['input_ids']\n",
        "        attention_mask = tokenized_input['attention_mask']\n",
        "\n",
        "        batch_size, max_tokens = input_ids.size()\n",
        "\n",
        "        # Add an extra dimension for num_segments\n",
        "        input_ids = input_ids.unsqueeze(1)\n",
        "        attention_mask = attention_mask.unsqueeze(1)\n",
        "\n",
        "        # Reshape input_ids and attention_mask for BERT processing\n",
        "        input_ids_flat = input_ids.view(batch_size * 1, max_tokens)\n",
        "        attention_mask_flat = attention_mask.view(batch_size * 1, max_tokens)\n",
        "\n",
        "        # Step 1: BERT Processing\n",
        "        outputs = self.bert(input_ids_flat, attention_mask=attention_mask_flat)\n",
        "\n",
        "        # Max pooling over the sequence outputs for token-scale representation\n",
        "        token_representation, _ = torch.max(outputs.last_hidden_state, dim=1)\n",
        "\n",
        "        # Document-scale representation (pooler output)\n",
        "        document_representation = outputs.pooler_output\n",
        "\n",
        "        # Concatenate the two representations\n",
        "        concatenated_representation = torch.cat([document_representation, token_representation], dim=1)\n",
        "\n",
        "        # Pass through the regression layer\n",
        "        output_scores = self.regression_layer(concatenated_representation)\n",
        "\n",
        "        return output_scores\n",
        "\n",
        "\n",
        "model_essay = EssayBERTModel_(regression_output_size=1)\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Example essays in a batch\n",
        "essays = [\"Your essay text goes here.\", \"Another essay text.\"]\n",
        "\n",
        "\n",
        "# Get the model predictions for the batch\n",
        "output_scores_batch = model_essay.forward(essays)\n",
        "\n",
        "print(\"Output Scores (Batch):\", output_scores_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "yTDwO3t7ZRvY"
      },
      "outputs": [],
      "source": [
        "class CombinedEssayModel_(nn.Module):\n",
        "    def __init__(self, bert_model, lstm_hidden_size, segment_scales, regression_output_size=1):\n",
        "        super(CombinedEssayModel_, self).__init__()\n",
        "\n",
        "        self.tokenizer=BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # Segment-scale model\n",
        "        self.segment_scale_model = SegmentScaleEssayModelo(bert_model, lstm_hidden_size, segment_scales)\n",
        "\n",
        "        # Document-scale and Token-scale model\n",
        "        self.essay_bert_model = EssayBERTModel_(bert_model, regression_output_size)\n",
        "\n",
        "    def forward(self, input_text, max_tokens):\n",
        "\n",
        "        tokenized_input = tokenizer(input_text, return_tensors='pt', max_length=max_tokens, truncation=True, padding='max_length')\n",
        "\n",
        "        input_ids = tokenized_input['input_ids']\n",
        "        attention_mask = tokenized_input['attention_mask']\n",
        "        # Get segment-scale representation\n",
        "        segment_scale_representation_score = self.segment_scale_model.segment_scale_representation(input_ids, attention_mask)\n",
        "\n",
        "        # print(segment_scale_representation_score)\n",
        "        # Get document-scale and token-scale representation\n",
        "        essay_representation_score = self.essay_bert_model(input_text)\n",
        "\n",
        "        # print(essay_representation_score)\n",
        "        score=essay_representation_score+segment_scale_representation_score\n",
        "\n",
        "        return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuf21VPUZRvY",
        "outputId": "fb027fb9-76e0-43d5-b9f1-e88f0074dc27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final combined essay score: tensor([[-0.1233],\n",
            "        [-0.0914]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "combined_model = CombinedEssayModel_(bert_model='bert-base-uncased', lstm_hidden_size=256, segment_scales=[5, 10, 25], regression_output_size=1)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Example essay\n",
        "essays = [\"Your essay text goes here.\", \"Another essay text.\"]\n",
        "\n",
        "# Set the maximum number of tokens\n",
        "max_tokens = 50\n",
        "\n",
        "# Get the final combined essay representation\n",
        "final_representation = combined_model(essays, max_tokens)\n",
        "\n",
        "print(\"Final combined essay score:\", final_representation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "7wy2NIcFusEs"
      },
      "outputs": [],
      "source": [
        "# Initialize the model, criterion, and optimizer\n",
        "model_combined = CombinedEssayModel_(bert_model='bert-base-uncased', lstm_hidden_size=256, segment_scales=[90,130], regression_output_size=1)\n",
        "criterion = CustomLoss(0.33, 0.33, 0.34)\n",
        "\n",
        "learning_rate = 6e-5\n",
        "beta1 = 0.9\n",
        "beta2 = 0.999\n",
        "weight_decay = 0.005\n",
        "\n",
        "\n",
        "train_loss_combine=[]\n",
        "# Set up the optimizer\n",
        "optimizer_model = optim.Adam(model_combined.parameters(), lr=learning_rate, betas=(beta1, beta2), weight_decay=weight_decay)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bz5t5lXYZRvZ",
        "outputId": "22777bca-1315-4c6e-b0ac-b72fb917e7f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pchhl\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "1it [00:32, 32.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [1/1498], Batch Loss: 0.3040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2it [01:04, 32.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [2/1498], Batch Loss: 0.0173\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "3it [01:36, 32.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [3/1498], Batch Loss: 0.1252\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "4it [02:09, 32.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [4/1498], Batch Loss: 0.1413\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5it [02:42, 32.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [5/1498], Batch Loss: 0.1367\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "6it [03:14, 32.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [6/1498], Batch Loss: 0.0748\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7it [03:46, 32.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [7/1498], Batch Loss: 0.1808\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "8it [04:18, 32.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [8/1498], Batch Loss: 0.1078\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "9it [04:50, 32.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [9/1498], Batch Loss: 0.1009\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10it [05:22, 32.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [10/1498], Batch Loss: 0.1247\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "11it [05:54, 31.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [11/1498], Batch Loss: 0.1244\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12it [06:26, 31.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [12/1498], Batch Loss: 0.0495\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "13it [06:57, 31.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [13/1498], Batch Loss: 0.1278\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "14it [07:29, 31.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [14/1498], Batch Loss: 0.0773\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15it [08:00, 31.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [15/1498], Batch Loss: 0.0829\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "16it [08:32, 31.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [16/1498], Batch Loss: 0.1630\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "17it [09:03, 31.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [17/1498], Batch Loss: 0.1147\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "18it [09:35, 31.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [18/1498], Batch Loss: 0.1208\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "19it [10:07, 31.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [19/1498], Batch Loss: 0.1146\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "20it [10:38, 31.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [20/1498], Batch Loss: 0.1225\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "21it [11:11, 31.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [21/1498], Batch Loss: 0.1856\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [11:42, 31.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [22/1498], Batch Loss: 0.1108\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23it [12:12, 31.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [23/1498], Batch Loss: 0.1352\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24it [12:43, 31.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [24/1498], Batch Loss: 0.0810\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25it [13:14, 30.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [25/1498], Batch Loss: 0.0892\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "26it [13:44, 30.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [26/1498], Batch Loss: 0.1068\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "27it [14:15, 30.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [27/1498], Batch Loss: 0.1496\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "28it [14:45, 30.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [28/1498], Batch Loss: 0.1202\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "29it [15:16, 30.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [29/1498], Batch Loss: 0.0937\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "30it [15:47, 30.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [30/1498], Batch Loss: 0.1145\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "31it [16:20, 31.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [31/1498], Batch Loss: 0.0647\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "32it [16:53, 31.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [32/1498], Batch Loss: 0.1488\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [17:25, 31.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [33/1498], Batch Loss: 0.1652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "34it [17:56, 31.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [34/1498], Batch Loss: 0.1080\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "35it [18:26, 31.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [35/1498], Batch Loss: 0.0528\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "36it [18:56, 30.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [36/1498], Batch Loss: 0.0632\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "37it [19:28, 31.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [37/1498], Batch Loss: 0.0966\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "38it [19:57, 30.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [38/1498], Batch Loss: 0.0492\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "39it [20:26, 30.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [39/1498], Batch Loss: 0.1255\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "40it [20:56, 29.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [40/1498], Batch Loss: 0.0826\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "41it [21:25, 29.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [41/1498], Batch Loss: 0.0777\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "42it [21:54, 29.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [42/1498], Batch Loss: 0.0715\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "43it [22:24, 29.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [43/1498], Batch Loss: 0.0960\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [22:53, 29.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [44/1498], Batch Loss: 0.0627\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "45it [23:22, 29.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [45/1498], Batch Loss: 0.1113\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "46it [23:51, 29.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [46/1498], Batch Loss: 0.0880\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "47it [24:20, 29.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [47/1498], Batch Loss: 0.0863\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "48it [24:49, 29.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [48/1498], Batch Loss: 0.0482\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "49it [25:19, 29.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [49/1498], Batch Loss: 0.0651\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "50it [25:49, 29.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [50/1498], Batch Loss: 0.1251\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "51it [26:19, 29.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [51/1498], Batch Loss: 0.1471\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [26:49, 29.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [52/1498], Batch Loss: 0.1049\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "53it [27:19, 29.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [53/1498], Batch Loss: 0.0886\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "54it [27:48, 29.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [54/1498], Batch Loss: 0.0440\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [28:18, 29.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [55/1498], Batch Loss: 0.0784\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "56it [28:52, 30.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [56/1498], Batch Loss: 0.0420\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "57it [29:40, 36.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [57/1498], Batch Loss: 0.0913\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "58it [30:27, 39.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [58/1498], Batch Loss: 0.1132\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "59it [31:15, 41.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [59/1498], Batch Loss: 0.0926\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "60it [31:48, 39.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [60/1498], Batch Loss: 0.1142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "61it [32:17, 36.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [61/1498], Batch Loss: 0.0802\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "62it [32:44, 31.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch [62/1498], Batch Loss: 0.0667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "1it [00:27, 27.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [1/1498], Batch Loss: 0.1028\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2it [00:58, 29.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [2/1498], Batch Loss: 0.0985\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "3it [01:31, 31.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [3/1498], Batch Loss: 0.0897\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "4it [02:04, 32.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [4/1498], Batch Loss: 0.0788\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5it [02:35, 31.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [5/1498], Batch Loss: 0.0639\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "6it [03:06, 31.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [6/1498], Batch Loss: 0.0767\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7it [03:39, 31.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [7/1498], Batch Loss: 0.0844\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "8it [04:11, 32.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [8/1498], Batch Loss: 0.1010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "9it [04:42, 31.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [9/1498], Batch Loss: 0.1144\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10it [05:13, 31.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [10/1498], Batch Loss: 0.0720\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "11it [05:45, 31.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [11/1498], Batch Loss: 0.0721\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12it [06:18, 32.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [12/1498], Batch Loss: 0.1064\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "13it [06:51, 32.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [13/1498], Batch Loss: 0.1264\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "14it [07:22, 31.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [14/1498], Batch Loss: 0.0658\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15it [07:55, 32.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [15/1498], Batch Loss: 0.0898\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "16it [08:26, 31.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [16/1498], Batch Loss: 0.0741\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "17it [08:58, 31.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [17/1498], Batch Loss: 0.1216\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "18it [09:31, 32.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [18/1498], Batch Loss: 0.1106\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "19it [10:02, 32.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [19/1498], Batch Loss: 0.1033\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "20it [10:33, 31.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [20/1498], Batch Loss: 0.1278\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "21it [11:05, 31.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [21/1498], Batch Loss: 0.1168\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [11:36, 31.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [22/1498], Batch Loss: 0.1037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23it [12:08, 31.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [23/1498], Batch Loss: 0.0623\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24it [12:41, 32.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [24/1498], Batch Loss: 0.0701\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25it [13:12, 31.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [25/1498], Batch Loss: 0.1507\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "26it [13:42, 31.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [26/1498], Batch Loss: 0.0782\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "27it [14:15, 31.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [27/1498], Batch Loss: 0.0742\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "28it [14:48, 32.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [28/1498], Batch Loss: 0.1148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "29it [15:20, 32.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [29/1498], Batch Loss: 0.0627\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "30it [15:52, 31.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [30/1498], Batch Loss: 0.0807\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "31it [16:22, 31.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [31/1498], Batch Loss: 0.0983\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "32it [16:55, 31.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [32/1498], Batch Loss: 0.1148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [17:28, 32.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [33/1498], Batch Loss: 0.1648\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "34it [18:01, 32.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [34/1498], Batch Loss: 0.0997\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "35it [18:32, 32.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [35/1498], Batch Loss: 0.0556\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "36it [19:03, 31.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [36/1498], Batch Loss: 0.0672\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "37it [19:36, 31.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [37/1498], Batch Loss: 0.0682\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "38it [20:08, 32.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [38/1498], Batch Loss: 0.1274\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "39it [20:39, 31.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [39/1498], Batch Loss: 0.0727\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "40it [21:10, 31.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [40/1498], Batch Loss: 0.1002\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "41it [21:42, 31.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [41/1498], Batch Loss: 0.2113\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "42it [22:15, 31.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [42/1498], Batch Loss: 0.0637\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "43it [22:46, 31.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [43/1498], Batch Loss: 0.0944\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [23:17, 31.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [44/1498], Batch Loss: 0.1283\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "45it [23:49, 31.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [45/1498], Batch Loss: 0.1066\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "46it [24:22, 32.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [46/1498], Batch Loss: 0.0898\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "47it [24:55, 32.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [47/1498], Batch Loss: 0.1133\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "48it [25:27, 32.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [48/1498], Batch Loss: 0.0961\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "49it [25:58, 31.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [49/1498], Batch Loss: 0.0792\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "50it [26:29, 31.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [50/1498], Batch Loss: 0.0732\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "51it [27:02, 32.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [51/1498], Batch Loss: 0.0790\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [27:34, 32.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [52/1498], Batch Loss: 0.1197\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "53it [28:06, 31.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [53/1498], Batch Loss: 0.1095\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "54it [28:37, 31.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [54/1498], Batch Loss: 0.0990\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [29:09, 31.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [55/1498], Batch Loss: 0.0590\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "56it [29:43, 32.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [56/1498], Batch Loss: 0.0980\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "57it [30:14, 31.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [57/1498], Batch Loss: 0.0412\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "58it [30:44, 31.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [58/1498], Batch Loss: 0.0546\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "59it [31:17, 31.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [59/1498], Batch Loss: 0.1122\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "60it [31:50, 32.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [60/1498], Batch Loss: 0.0633\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "61it [32:22, 32.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [61/1498], Batch Loss: 0.0841\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "62it [32:54, 31.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch [62/1498], Batch Loss: 0.0829\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "1it [00:30, 30.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [1/1498], Batch Loss: 0.0652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2it [01:03, 31.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [2/1498], Batch Loss: 0.1342\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "3it [01:36, 32.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [3/1498], Batch Loss: 0.0882\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "4it [02:07, 32.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [4/1498], Batch Loss: 0.0901\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5it [02:38, 31.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [5/1498], Batch Loss: 0.0786\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "6it [03:10, 31.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [6/1498], Batch Loss: 0.0713\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7it [03:44, 32.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [7/1498], Batch Loss: 0.1156\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "8it [04:16, 32.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [8/1498], Batch Loss: 0.1022\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "9it [04:48, 32.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [9/1498], Batch Loss: 0.1396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10it [05:18, 31.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [10/1498], Batch Loss: 0.0599\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "11it [05:50, 31.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [11/1498], Batch Loss: 0.0507\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12it [06:24, 32.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [12/1498], Batch Loss: 0.1202\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "13it [06:56, 32.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [13/1498], Batch Loss: 0.1252\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "14it [07:28, 32.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [14/1498], Batch Loss: 0.0796\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15it [07:59, 31.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [15/1498], Batch Loss: 0.0731\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "16it [08:31, 31.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [16/1498], Batch Loss: 0.0917\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "17it [09:04, 32.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [17/1498], Batch Loss: 0.0717\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "18it [09:36, 32.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [18/1498], Batch Loss: 0.0901\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "19it [10:08, 32.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [19/1498], Batch Loss: 0.0652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "20it [10:38, 31.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [20/1498], Batch Loss: 0.1004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "21it [11:11, 32.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [21/1498], Batch Loss: 0.1008\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [11:43, 31.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [22/1498], Batch Loss: 0.1848\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23it [12:16, 32.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [23/1498], Batch Loss: 0.0829\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24it [12:48, 32.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [24/1498], Batch Loss: 0.0718\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25it [13:19, 31.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [25/1498], Batch Loss: 0.1064\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "26it [13:50, 31.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [26/1498], Batch Loss: 0.0977\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "27it [14:20, 31.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [27/1498], Batch Loss: 0.0794\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "28it [14:45, 29.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [28/1498], Batch Loss: 0.0821\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "29it [15:10, 28.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [29/1498], Batch Loss: 0.0852\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "30it [15:37, 27.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [30/1498], Batch Loss: 0.0499\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "31it [16:03, 27.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [31/1498], Batch Loss: 0.1050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "32it [16:28, 26.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [32/1498], Batch Loss: 0.0928\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [16:53, 26.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [33/1498], Batch Loss: 0.0807\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "34it [17:19, 26.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [34/1498], Batch Loss: 0.1013\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "35it [17:44, 25.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [35/1498], Batch Loss: 0.1521\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "36it [18:10, 25.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [36/1498], Batch Loss: 0.0814\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "37it [18:36, 25.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [37/1498], Batch Loss: 0.0757\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "38it [19:06, 27.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [38/1498], Batch Loss: 0.0683\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "39it [19:32, 26.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [39/1498], Batch Loss: 0.1099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "40it [20:03, 27.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [40/1498], Batch Loss: 0.1358\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "41it [20:33, 28.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [41/1498], Batch Loss: 0.0754\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "42it [21:04, 29.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [42/1498], Batch Loss: 0.0838\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "43it [21:34, 29.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [43/1498], Batch Loss: 0.1008\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [22:04, 29.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [44/1498], Batch Loss: 0.1107\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "45it [22:34, 29.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [45/1498], Batch Loss: 0.1163\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "46it [23:00, 28.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [46/1498], Batch Loss: 0.0699\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "47it [23:26, 27.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [47/1498], Batch Loss: 0.0831\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "48it [23:51, 27.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [48/1498], Batch Loss: 0.1295\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "49it [24:16, 26.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [49/1498], Batch Loss: 0.1429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "50it [24:41, 26.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [50/1498], Batch Loss: 0.0865\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "51it [25:06, 25.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [51/1498], Batch Loss: 0.0439\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [25:32, 25.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [52/1498], Batch Loss: 0.0360\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "53it [25:57, 25.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [53/1498], Batch Loss: 0.0593\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "54it [26:21, 25.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [54/1498], Batch Loss: 0.0433\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [26:46, 25.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [55/1498], Batch Loss: 0.1153\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "56it [27:12, 25.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [56/1498], Batch Loss: 0.0730\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "57it [27:36, 25.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [57/1498], Batch Loss: 0.0395\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "58it [28:01, 25.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [58/1498], Batch Loss: 0.0675\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "59it [28:26, 24.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [59/1498], Batch Loss: 0.0565\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "60it [28:51, 24.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [60/1498], Batch Loss: 0.0799\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "61it [29:16, 25.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [61/1498], Batch Loss: 0.1338\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "62it [29:42, 28.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch [62/1498], Batch Loss: 0.0913\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "1it [00:27, 27.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [1/1498], Batch Loss: 0.0944\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2it [00:53, 26.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [2/1498], Batch Loss: 0.0938\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "3it [01:19, 26.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [3/1498], Batch Loss: 0.1013\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "4it [01:48, 27.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [4/1498], Batch Loss: 0.0989\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5it [02:16, 27.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [5/1498], Batch Loss: 0.0922\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "6it [02:41, 26.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [6/1498], Batch Loss: 0.0711\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7it [03:08, 26.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [7/1498], Batch Loss: 0.0708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "8it [03:41, 28.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [8/1498], Batch Loss: 0.1307\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "9it [04:14, 30.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [9/1498], Batch Loss: 0.0868\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10it [04:44, 29.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [10/1498], Batch Loss: 0.0790\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "11it [05:16, 30.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [11/1498], Batch Loss: 0.1979\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12it [05:49, 31.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [12/1498], Batch Loss: 0.1224\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "13it [06:22, 31.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [13/1498], Batch Loss: 0.0836\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "14it [06:53, 31.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [14/1498], Batch Loss: 0.0593\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15it [07:24, 31.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [15/1498], Batch Loss: 0.1408\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "16it [07:58, 32.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [16/1498], Batch Loss: 0.1581\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "17it [08:29, 31.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [17/1498], Batch Loss: 0.0754\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "18it [09:02, 32.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [18/1498], Batch Loss: 0.0802\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "19it [09:33, 31.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [19/1498], Batch Loss: 0.1587\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "20it [10:07, 32.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [20/1498], Batch Loss: 0.0815\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "21it [10:39, 32.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [21/1498], Batch Loss: 0.0734\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [11:12, 32.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [22/1498], Batch Loss: 0.1083\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23it [11:45, 32.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [23/1498], Batch Loss: 0.0744\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24it [12:17, 32.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [24/1498], Batch Loss: 0.0812\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25it [12:49, 32.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [25/1498], Batch Loss: 0.0585\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "26it [13:20, 31.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [26/1498], Batch Loss: 0.1016\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "27it [13:54, 32.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [27/1498], Batch Loss: 0.1097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "28it [14:26, 32.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [28/1498], Batch Loss: 0.0624\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "29it [14:59, 32.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [29/1498], Batch Loss: 0.2167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "30it [15:31, 32.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [30/1498], Batch Loss: 0.0527\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "31it [16:02, 32.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [31/1498], Batch Loss: 0.0985\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "32it [16:34, 32.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [32/1498], Batch Loss: 0.0482\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [17:07, 32.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [33/1498], Batch Loss: 0.0870\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "34it [17:40, 32.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [34/1498], Batch Loss: 0.1031\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "35it [18:13, 32.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [35/1498], Batch Loss: 0.1076\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "36it [18:45, 32.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [36/1498], Batch Loss: 0.1110\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "37it [19:17, 32.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [37/1498], Batch Loss: 0.0977\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "38it [19:48, 32.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [38/1498], Batch Loss: 0.0585\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "39it [20:22, 32.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [39/1498], Batch Loss: 0.0549\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "40it [20:55, 32.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [40/1498], Batch Loss: 0.0942\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "41it [21:28, 32.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [41/1498], Batch Loss: 0.0441\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "42it [21:58, 32.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [42/1498], Batch Loss: 0.0388\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "43it [22:31, 32.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [43/1498], Batch Loss: 0.0697\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [23:03, 32.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [44/1498], Batch Loss: 0.1427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "45it [23:35, 32.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [45/1498], Batch Loss: 0.0443\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "46it [24:08, 32.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [46/1498], Batch Loss: 0.0757\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "47it [24:40, 32.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [47/1498], Batch Loss: 0.1096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "48it [25:13, 32.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [48/1498], Batch Loss: 0.1447\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "49it [25:39, 30.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [49/1498], Batch Loss: 0.0327\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "50it [26:04, 28.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [50/1498], Batch Loss: 0.0623\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "51it [26:30, 28.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [51/1498], Batch Loss: 0.0586\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [26:56, 27.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [52/1498], Batch Loss: 0.0526\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "53it [27:25, 27.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [53/1498], Batch Loss: 0.0488\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "54it [27:53, 28.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [54/1498], Batch Loss: 0.0853\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [28:21, 28.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [55/1498], Batch Loss: 0.0436\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "56it [28:46, 27.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [56/1498], Batch Loss: 0.0956\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "57it [29:14, 27.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [57/1498], Batch Loss: 0.0362\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "58it [29:40, 26.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [58/1498], Batch Loss: 0.1004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "59it [30:10, 27.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [59/1498], Batch Loss: 0.0878\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "60it [30:40, 28.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [60/1498], Batch Loss: 0.1114\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "61it [31:09, 28.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [61/1498], Batch Loss: 0.0485\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "62it [31:37, 30.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch [62/1498], Batch Loss: 0.0606\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "1it [00:28, 28.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [1/1498], Batch Loss: 0.0995\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2it [00:53, 26.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [2/1498], Batch Loss: 0.0934\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "3it [01:25, 28.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [3/1498], Batch Loss: 0.0912\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "4it [01:52, 28.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [4/1498], Batch Loss: 0.0583\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5it [02:19, 27.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [5/1498], Batch Loss: 0.0984\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "6it [02:45, 27.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [6/1498], Batch Loss: 0.0723\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7it [03:12, 27.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [7/1498], Batch Loss: 0.0550\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "8it [03:38, 26.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [8/1498], Batch Loss: 0.0460\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "9it [04:05, 26.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [9/1498], Batch Loss: 0.0460\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10it [04:29, 26.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [10/1498], Batch Loss: 0.0498\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "11it [04:58, 26.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [11/1498], Batch Loss: 0.0605\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12it [05:25, 26.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [12/1498], Batch Loss: 0.0403\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "13it [05:49, 26.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [13/1498], Batch Loss: 0.0932\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "14it [06:17, 26.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [14/1498], Batch Loss: 0.0730\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15it [06:45, 26.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [15/1498], Batch Loss: 0.1060\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "16it [07:09, 26.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [16/1498], Batch Loss: 0.1005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "17it [07:37, 26.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [17/1498], Batch Loss: 0.0914\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "18it [08:07, 27.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [18/1498], Batch Loss: 0.0702\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "19it [08:37, 28.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [19/1498], Batch Loss: 0.1136\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "20it [09:10, 29.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [20/1498], Batch Loss: 0.1304\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "21it [09:44, 31.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [21/1498], Batch Loss: 0.1604\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [10:16, 31.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [22/1498], Batch Loss: 0.0627\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23it [10:46, 30.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [23/1498], Batch Loss: 0.0584\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24it [11:19, 31.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [24/1498], Batch Loss: 0.0697\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25it [11:49, 31.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [25/1498], Batch Loss: 0.0764\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "26it [12:17, 30.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [26/1498], Batch Loss: 0.0883\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "27it [12:44, 29.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [27/1498], Batch Loss: 0.0576\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "28it [13:12, 28.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [28/1498], Batch Loss: 0.0716\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "29it [13:41, 29.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [29/1498], Batch Loss: 0.0505\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "30it [14:10, 28.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [30/1498], Batch Loss: 0.0550\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "31it [14:41, 29.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [31/1498], Batch Loss: 0.0434\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "32it [15:12, 30.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [32/1498], Batch Loss: 0.1340\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [15:40, 29.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [33/1498], Batch Loss: 0.0753\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "34it [16:07, 28.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [34/1498], Batch Loss: 0.0880\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "35it [16:34, 28.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [35/1498], Batch Loss: 0.1265\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "36it [17:00, 27.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [36/1498], Batch Loss: 0.1134\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "37it [17:25, 26.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [37/1498], Batch Loss: 0.0662\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "38it [17:51, 26.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [38/1498], Batch Loss: 0.0653\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "39it [18:21, 27.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [39/1498], Batch Loss: 0.1347\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "40it [18:53, 28.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [40/1498], Batch Loss: 0.0905\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "41it [19:24, 29.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [41/1498], Batch Loss: 0.1677\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "42it [19:57, 30.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [42/1498], Batch Loss: 0.0909\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "43it [20:30, 31.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [43/1498], Batch Loss: 0.1311\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [21:02, 31.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [44/1498], Batch Loss: 0.0765\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "45it [21:32, 30.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [45/1498], Batch Loss: 0.0577\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "46it [21:59, 29.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [46/1498], Batch Loss: 0.1067\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "47it [22:29, 29.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [47/1498], Batch Loss: 0.0513\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "48it [23:00, 30.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [48/1498], Batch Loss: 0.0589\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "49it [23:27, 29.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [49/1498], Batch Loss: 0.0935\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "50it [23:58, 29.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [50/1498], Batch Loss: 0.1332\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "51it [24:30, 30.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [51/1498], Batch Loss: 0.0566\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "52it [24:57, 29.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [52/1498], Batch Loss: 0.0629\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "53it [25:28, 29.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [53/1498], Batch Loss: 0.0323\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "54it [25:56, 29.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [54/1498], Batch Loss: 0.0967\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [26:21, 28.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [55/1498], Batch Loss: 0.1040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "56it [26:49, 27.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [56/1498], Batch Loss: 0.0991\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "57it [27:20, 28.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [57/1498], Batch Loss: 0.0718\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "58it [27:50, 29.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [58/1498], Batch Loss: 0.0605\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "59it [28:16, 28.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [59/1498], Batch Loss: 0.0747\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "60it [28:44, 28.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [60/1498], Batch Loss: 0.0971\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "61it [29:13, 28.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [61/1498], Batch Loss: 0.1003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "62it [29:43, 28.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch [62/1498], Batch Loss: 0.0667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Training loop\n",
        "for epoch in range(5):\n",
        "\n",
        "    out_loss = 0\n",
        "    num_samples_processed_1 = 0\n",
        "\n",
        "    for batch_idx, (essay_id, essay_set, essays, prompt, normalized_score) in tqdm(enumerate(dataloader)):\n",
        "\n",
        "        num_samples_processed_1 += essay_id.size(0)\n",
        "\n",
        "        if num_samples_processed_1 >= 500:\n",
        "            break\n",
        "\n",
        "        optimizer_model.zero_grad()\n",
        "\n",
        "        # normalized_score = normalized_score.to(device)\n",
        "        # normalized_score = normalized_score.view(1, -1)\n",
        "\n",
        "        out = model_combined(essays, 800)\n",
        "\n",
        "        out=out.squeeze()\n",
        "\n",
        "        # print(out)\n",
        "        # print(normalized_score)\n",
        "        out = out.float()\n",
        "        # out = out.view(1, -1)\n",
        "\n",
        "        normalized_score = normalized_score.float()\n",
        "\n",
        "        loss = criterion(out, normalized_score)\n",
        "        loss.backward()\n",
        "        optimizer_model.step()\n",
        "\n",
        "        out_loss += loss.item()\n",
        "\n",
        "        # break\n",
        "        print(f\"Epoch [{epoch + 1}/5], Batch [{batch_idx + 1}/{len(dataloader)}], Batch Loss: {loss.item():.4f}\")\n",
        "\n",
        "    train_loss_combine.append(out_loss)\n",
        "    # Save the model after every iteration\n",
        "    torch.save(model_combined.state_dict(), f'model_epoch_{epoch + 10}.pt')\n",
        "\n",
        "    # Save the final model after training\n",
        "    if epoch == 4:  # Assuming you want to save the model after the last epoch\n",
        "        torch.save(model_combined.state_dict(), 'final_model.pt')\n",
        "\n",
        "# Save the entire model (including optimizer and other state)\n",
        "torch.save({\n",
        "    'epoch': 5,  # Assuming you trained for 5 epochs\n",
        "    'model_state_dict': model_combined.state_dict(),\n",
        "    'optimizer_state_dict': optimizer_model.state_dict(),\n",
        "    'loss': out_loss / len(dataloader),\n",
        "}, 'entire_model.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47rZbZkkZRvZ",
        "outputId": "e18f29b2-008d-414f-89bb-8c0d67f864f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x212595e4340>]"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot([1,2,3,4,5],train_loss_combine)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duekbhCPZRva",
        "outputId": "dcea0d1d-ec22-4f2f-9b86-4fc14a1393dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x19f54553430>]"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot([1,2,3,4],train_loss_combine)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtvMhBe8uHQi",
        "outputId": "9ec783b5-9172-487f-8dbc-992551f0e542"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# model_combined.load_state_dict(torch.load(\"/content/drive/MyDrive/ire_v2t/entire_model.pt\"))\n",
        "\n",
        "# model_combined.eval()\n",
        "\n",
        "loaded_model_checkpoint = torch.load('entire_model.pt', map_location=torch.device('cpu'))\n",
        "\n",
        "# Assuming 'model_state_dict' is the key for your model\n",
        "loaded_model_state_dict = loaded_model_checkpoint['model_state_dict']\n",
        "\n",
        "# Now, you need to create an instance of your model and load the state dictionary\n",
        "# Replace 'YourModelClass' with the actual class of your model\n",
        "model_combined.load_state_dict(loaded_model_state_dict)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRCsI4ZqwL0t",
        "outputId": "3d8438f8-1ecc-4855-f0ec-c1e3d86e5dec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [02:55, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "for batch_idx, (essay_id, essay_set, essays, prompt, normalized_score) in tqdm(enumerate(dataloader)):\n",
        "    x = model_combined(essays,800)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHBQHhsLxlK9",
        "outputId": "ac584d6e-b8be-46ad-f0e2-b8061e286ec9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "for batch_idx, (essay_id, essay_set, essays, prompt, normalized_score) in tqdm(enumerate(dataloader)):\n",
        "    y = normalized_score\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVBx1OMSw50R",
        "outputId": "ecc076fe-1416-4a18-9ead-711edd87d057"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.4576],\n",
              "        [0.5561],\n",
              "        [0.2083],\n",
              "        [0.6316],\n",
              "        [0.0641],\n",
              "        [0.3843],\n",
              "        [0.7712],\n",
              "        [0.6273],\n",
              "        [0.3556],\n",
              "        [0.6836],\n",
              "        [0.5091],\n",
              "        [0.6014],\n",
              "        [0.6097],\n",
              "        [0.6902],\n",
              "        [0.5522],\n",
              "        [0.3617],\n",
              "        [0.5664],\n",
              "        [0.5959],\n",
              "        [0.3753],\n",
              "        [0.7696],\n",
              "        [0.4606],\n",
              "        [0.7146],\n",
              "        [0.3165],\n",
              "        [0.6356],\n",
              "        [0.6674],\n",
              "        [0.8357],\n",
              "        [0.6473],\n",
              "        [0.7392],\n",
              "        [0.6404],\n",
              "        [0.6453],\n",
              "        [0.6600],\n",
              "        [0.6721]], grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kRn3-TJx4bV",
        "outputId": "a6ed28ba-452e-4ccc-d96d-fd6b7867c117"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Real :  tensor(1., dtype=torch.float64) pred :  tensor([0.4576], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(1., dtype=torch.float64) pred :  tensor([0.5561], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(0.6000, dtype=torch.float64) pred :  tensor([0.2083], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(0.6667, dtype=torch.float64) pred :  tensor([0.6316], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(0.7000, dtype=torch.float64) pred :  tensor([0.0641], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(0.6667, dtype=torch.float64) pred :  tensor([0.3843], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(1., dtype=torch.float64) pred :  tensor([0.7712], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(0.5000, dtype=torch.float64) pred :  tensor([0.6273], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(0.2000, dtype=torch.float64) pred :  tensor([0.3556], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(0.5000, dtype=torch.float64) pred :  tensor([0.6836], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(0.5000, dtype=torch.float64) pred :  tensor([0.5091], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(0., dtype=torch.float64) pred :  tensor([0.6014], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(1., dtype=torch.float64) pred :  tensor([0.6097], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(0.8000, dtype=torch.float64) pred :  tensor([0.6902], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(0.3333, dtype=torch.float64) pred :  tensor([0.5522], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(0.6667, dtype=torch.float64) pred :  tensor([0.3617], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(0.7778, dtype=torch.float64) pred :  tensor([0.5664], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(0.5000, dtype=torch.float64) pred :  tensor([0.5959], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(1., dtype=torch.float64) pred :  tensor([0.3753], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(0.5000, dtype=torch.float64) pred :  tensor([0.7696], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(1., dtype=torch.float64) pred :  tensor([0.4606], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(1., dtype=torch.float64) pred :  tensor([0.7146], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(0.2500, dtype=torch.float64) pred :  tensor([0.3165], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(0.6667, dtype=torch.float64) pred :  tensor([0.6356], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(0.4000, dtype=torch.float64) pred :  tensor([0.6674], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(0.3333, dtype=torch.float64) pred :  tensor([0.8357], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(0.2000, dtype=torch.float64) pred :  tensor([0.6473], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(0.6000, dtype=torch.float64) pred :  tensor([0.7392], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(0.9444, dtype=torch.float64) pred :  tensor([0.6404], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(0., dtype=torch.float64) pred :  tensor([0.6453], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(0.4000, dtype=torch.float64) pred :  tensor([0.6600], grad_fn=<UnbindBackward0>)\n",
            "Real :  tensor(0.8000, dtype=torch.float64) pred :  tensor([0.6721], grad_fn=<UnbindBackward0>)\n"
          ]
        }
      ],
      "source": [
        "for v1, v2 in zip(x, y):\n",
        "    print(\"Real : \", v2, \"pred : \", v1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh3pO7IrZRvc"
      },
      "source": [
        "Coherence NLI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dceaYrP4ZRvd",
        "outputId": "242315f8-30e5-4610-b06e-c935a76499d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "101 102 0 100\n"
          ]
        }
      ],
      "source": [
        "bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "# bert_tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "cls = bert_tokenizer.cls_token\n",
        "sep = bert_tokenizer.sep_token\n",
        "pad = bert_tokenizer.pad_token\n",
        "unk = bert_tokenizer.unk_token\n",
        "\n",
        "cls_id = bert_tokenizer.cls_token_id\n",
        "sep_id = bert_tokenizer.sep_token_id\n",
        "pad_id = bert_tokenizer.pad_token_id\n",
        "unk_id = bert_tokenizer.unk_token_id\n",
        "print(cls_id,sep_id,pad_id,unk_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "QRb5pkkrZRve"
      },
      "outputs": [],
      "source": [
        "#Helper functions for pre-processing\n",
        "def limit_sentence_length(sentence):\n",
        "  sentence = sentence.split()\n",
        "  sentence = sentence[:128]\n",
        "  return \" \".join(sentence)\n",
        "\n",
        "def get_token_type(sentence,num):\n",
        "  return [num]*len(sentence)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "1wTwui0AZRve"
      },
      "outputs": [],
      "source": [
        "#Model\n",
        "class Bert_Model(nn.Module):\n",
        "  def __init__(self,output_dim):\n",
        "    super().__init__()\n",
        "    self.bert = bert\n",
        "    embedding_dim = bert.config.to_dict()['hidden_size']\n",
        "    self.out = nn.Linear(embedding_dim, output_dim)\n",
        "  def forward(self, seq, attention_mask, token_type):\n",
        "    embeddings = self.bert(input_ids = seq, attention_mask = attention_mask, token_type_ids= token_type)[1]\n",
        "    return self.out(embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7UvaBcoZRve",
        "outputId": "3d6ae339-5c71-46ee-af4c-432a145132b5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pchhl\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "bert_model_snli = Bert_Model(3).to(device)\n",
        "bert_model_snli.load_state_dict(torch.load(r\"bert_model_snli.pth\",map_location=torch.device('cpu')))\n",
        "optimizer_snli = AdamW(bert_model_snli.parameters(),lr=2e-5,eps=1e-6,correct_bias=False)\n",
        "criterion_snli = nn.CrossEntropyLoss().to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "77-8Vo40ZRvf"
      },
      "outputs": [],
      "source": [
        "def predict_inference(premise, hypothesis, bert_model):\n",
        "    torch.cuda.empty_cache()\n",
        "    bert_model.eval()\n",
        "    premise = cls + ' ' + premise + ' ' + sep\n",
        "    hypothesis = hypothesis + ' ' + sep\n",
        "\n",
        "    premise_tokens = bert_tokenizer.tokenize(premise)\n",
        "    hypothesis_tokens = bert_tokenizer.tokenize(hypothesis)\n",
        "\n",
        "    premise_token_type = get_token_type(premise_tokens,0)\n",
        "    hypothesis_token_type = get_token_type(hypothesis_tokens,1)\n",
        "    # print(premise_token_type, hypothesis_token_type)\n",
        "    seq = premise_tokens + hypothesis_tokens\n",
        "    seq = bert_tokenizer.convert_tokens_to_ids(seq)\n",
        "    # print(seq)\n",
        "    tokens_type = premise_token_type + hypothesis_token_type\n",
        "    attention_mask = get_token_type(seq,1)\n",
        "\n",
        "    seq = torch.LongTensor(seq).unsqueeze(0).to(device)\n",
        "    tokens_type = torch.LongTensor(tokens_type).unsqueeze(0).to(device)\n",
        "    attention_mask = torch.LongTensor(attention_mask).unsqueeze(0).to(device)\n",
        "\n",
        "    prediction = bert_model(seq, attention_mask, tokens_type)\n",
        "    prediction = F.softmax(prediction, dim=-1)\n",
        "\n",
        "    return prediction[0, 0].item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuVDwW0vZRvf",
        "outputId": "50dfbfa1-8720-4f46-bb1c-5bfaddb2b340"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9508330821990967\n"
          ]
        }
      ],
      "source": [
        "premise = 'A soccer game with multiple males playing.'\n",
        "hypothesis = 'Some men are playing a sport.'\n",
        "\n",
        "print(predict_inference(premise, hypothesis,bert_model_snli))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nbGnCY2ZRvg",
        "outputId": "99f5488b-f423-4b68-f6da-99fa20322b59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.17029417385088486\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def coherence_score_snli(essay):\n",
        "    paragraphs = essay.split('\\n\\n')\n",
        "    final_sum = 0\n",
        "    for paragraph in paragraphs:\n",
        "        sentences = sent_tokenize(paragraph)\n",
        "        # print(sentences)\n",
        "        size = len(sentences)-1\n",
        "        # print(size)\n",
        "        sum = 0\n",
        "        for i in range(size):\n",
        "            x = predict_inference(sentences[i], sentences[i+1], bert_model_snli)\n",
        "            # print(sentences[i], sentences[i+1], x)\n",
        "            sum += x\n",
        "        # print(sum, size, \"score :\",sum / size)\n",
        "        final_sum += sum / max(1, size)\n",
        "\n",
        "    # print(\"final_sum :\", final_sum/len(paragraphs))\n",
        "    return final_sum/len(paragraphs)\n",
        "\n",
        "\n",
        "# essay = \"\"\"In the rapidly evolving landscape of technology, Artificial Intelligence (AI) stands out as a revolutionary force with the potential to reshape every aspect of human life. From intelligent virtual assistants and autonomous vehicles to sophisticated medical diagnostics, AI has transcended the realm of science fiction, becoming an integral part of our daily existence. This essay explores the impact of artificial intelligence on various domains and discusses both its promises and challenges. At its core, AI refers to the development of computer systems that can perform tasks that typically require human intelligence. These tasks include learning from experience (machine learning), understanding natural language, recognizing patterns, and solving complex problems. The power of AI lies in its ability to process vast amounts of data, learn from it, and make informed decisions without explicit programming. One of the most visible manifestations of AI in our lives is through virtual assistants like Siri, Alexa, and Google Assistant. These systems use natural language processing and machine learning algorithms to understand and respond to user queries, making our interactions with technology more intuitive and user-friendly. Similarly, AI has transformed industries such as healthcare, finance, and manufacturing, enhancing efficiency and productivity. In healthcare, AI plays a crucial role in medical imaging analysis, disease diagnosis, and drug discovery. Machine learning algorithms can analyze medical images, detect anomalies, and assist healthcare professionals in making more accurate and timely decisions. In finance, AI algorithms are employed for fraud detection, risk assessment, and algorithmic trading, contributing to the stability and security of financial systems. However, the widespread adoption of AI also raises ethical and societal concerns. The deployment of AI in decision-making processes, such as hiring, lending, and law enforcement, has raised questions about bias and fairness. Ensuring transparency, accountability, and ethical considerations in AI systems is crucial to avoid reinforcing existing societal inequalities. Moreover, there are concerns about job displacement as automation and AI technologies continue to advance. While AI has the potential to create new job opportunities, it is essential to address the skills gap and provide education and training to empower the workforce for the jobs of the future. The development of AI also poses challenges related to privacy and security. As AI systems rely on massive datasets for training, protecting sensitive information from misuse and ensuring robust cybersecurity measures become paramount. In conclusion, artificial intelligence is a transformative force that holds immense potential for positive impact across various domains. Its ability to process data, learn from experience, and make intelligent decisions opens up new possibilities for innovation and efficiency. However, ethical considerations, societal impacts, and the need for responsible development and deployment are critical aspects that must be carefully navigated to harness the full benefits of AI while addressing its challenges. As we move forward into an AI-driven future, it is imperative to strike a balance that maximizes the positive contributions of AI while safeguarding the well-being of individuals and society as a whole\"\"\"\n",
        "# print(coherence_score_snli(essay))\n",
        "\n",
        "\n",
        "# essay = \"Dear local newspaper, I think effects computers have on people are great learning skills/affects because they give us time to chat with friends/new people, helps us learn about the globe(astronomy) and keeps us out of troble! Thing about! Dont you think so? How would you feel if your teenager is always on the phone with friends! Do you ever time to chat with your friends or buisness partner about things. Well now - there's a new way to chat the computer, theirs plenty of sites on the internet to do so: @ORGANIZATION1, @ORGANIZATION2, @CAPS1, facebook, myspace ect. Just think now while your setting up meeting with your boss on the computer, your teenager is having fun on the phone not rushing to get off cause you want to use it. How did you learn about other countrys/states outside of yours? Well I have by computer/internet, it's a new way to learn about what going on in our time! You might think your child spends a lot of time on the computer, but ask them so question about the economy, sea floor spreading or even about the @DATE1's you'll be surprise at how much he/she knows. Believe it or not the computer is much interesting then in class all day reading out of books. If your child is home on your computer or at a local library, it's better than being out with friends being fresh, or being perpressured to doing something they know isnt right. You might not know where your child is, @CAPS2 forbidde in a hospital bed because of a drive-by. Rather than your child on the computer learning, chatting or just playing games, safe and sound in your home or community place. Now I hope you have reached a point to understand and agree with me, because computers can have great effects on you or child because it gives us time to chat with friends/new people, helps us learn about the globe and believe or not keeps us out of troble. Thank you for listening.\"\n",
        "# print(coherence_score_snli(essay))\n",
        "\n",
        "essay = 'the mood created by the author in the memoir was a mood of admiration. i think it was a mood of admiration because narciso admires the fact that his mother and father both left their families friends and careers in the country they loved. caps1 mood that the memoir sets is the mood of family and friends. i think the memoir sets the mood family and friend because it talks alot about the meaning of family for example in paragraph num1 the author says growing up in this environment instilled in me a great sense that family had nothing to do with being blood relative. that means that even though someone is not blood related to you can love them just as much as if they were. caps1 thing the memoir said was i learned the real definition of family. and for this i will never forget that house or its gracious neighbor hood or the many things i learned there about how to love. i will never forget how my parents turned this simple house into a home. this means that his parents turned a small house into a welcoming. loving place that holds so many memories.'\n",
        "print(coherence_score_snli(essay))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizer'.\n",
            "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-multiset-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
            "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n",
        "\n",
        "context_encoder_model_name = 'facebook/dpr-ctx_encoder-multiset-base'\n",
        "context_encoder_tokenizer = DPRContextEncoderTokenizer.from_pretrained(context_encoder_model_name)\n",
        "context_encoder_model = DPRContextEncoder.from_pretrained(context_encoder_model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "RANKED MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import random as scale\n",
        "\n",
        "# file type contains {'bert-base-uncased', 'roberta-base', 'xlnet-base-cased'}\n",
        "file = 'bert-base-uncased'\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(file, sep_token='[SEP]')\n",
        "url_replacer = '<url>'\n",
        "num_regex = re.compile('^[+-]?[0-9]+\\.?[0-9]*$')\n",
        "ref_scores_dtype = 'int32'\n",
        "\n",
        "MAX_SENTLEN = 50\n",
        "MAX_SENTNUM = 100\n",
        "\n",
        "asap_ranges = {\n",
        "    0: (-60, 60),\n",
        "    1: (-10, 10),\n",
        "    2: (-5, 5),\n",
        "    3: (-3, 3),\n",
        "    4: (-3, 3),\n",
        "    5: (-4, 4),\n",
        "    6: (-4, 4),\n",
        "    7: (-30, 30),\n",
        "    8: (-60, 60)\n",
        "}\n",
        "def get_ref_dtype():\n",
        "    return ref_scores_dtype\n",
        "\n",
        "\n",
        "def tokenize(string):\n",
        "    tokens = nltk.word_tokenize(string)\n",
        "    for index, token in enumerate(tokens):\n",
        "        if token == '@' and (index+1) < len(tokens):\n",
        "            tokens[index+1] = '@' + re.sub('[0-9]+.*', '', tokens[index+1])\n",
        "            tokens.pop(index)\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def get_score_range(prompt_id):\n",
        "    return asap_ranges[prompt_id]\n",
        "\n",
        "def scaled_value(low, high):\n",
        "    return scale.uniform(low, high)\n",
        "\n",
        "import re\n",
        "# import nltk\n",
        "\n",
        "# Download the necessary resource if not already downloaded\n",
        "# nltk.download('punkt')\n",
        "\n",
        "def text_tokenizer(text, replace_url_flag=True, tokenize_sent_flag=True, create_vocab_flag=True):\n",
        "    text = replace_url(text)\n",
        "    text = text.replace(u'\"', u'')\n",
        "\n",
        "    if \"...\" in text:\n",
        "        text = re.sub(r'\\.{3,}(\\s+\\.{3,})*', '...', text)\n",
        "    if \"??\" in text:\n",
        "        text = re.sub(r'\\?{2,}(\\s+\\?{2,})*', '?', text)\n",
        "    if \"!!\" in text:\n",
        "        text = re.sub(r'\\!{2,}(\\s+\\!{2,})*', '!', text)\n",
        "\n",
        "    # Use nltk word tokenizer\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "\n",
        "    if tokenize_sent_flag:\n",
        "        punctuation = '.!,;:?\"\\'、，；'\n",
        "        text = \" \".join(tokens)\n",
        "        text_nopun = re.sub(r'[{}]+'.format(punctuation), '', text)\n",
        "        sent_tokens = text_nopun\n",
        "\n",
        "\n",
        "        return sent_tokens\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "\n",
        "def read_input_essay(input):\n",
        "    \n",
        "\n",
        "    data_id = []\n",
        "\n",
        "    # tokenize text into sentences\n",
        "    sent_tokens = text_tokenizer(input, replace_url_flag=True, tokenize_sent_flag=True)\n",
        "    tokenized_text = bert_tokenizer.tokenize(sent_tokens)\n",
        "    max_num = 512\n",
        "    indexed_tokens = bert_tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "\n",
        "    data_id.append(indexed_tokens)\n",
        "\n",
        "\n",
        "    return data_id\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "def padding_sentence_sequences_input(index_sequences, maxnum, post_padding=True):\n",
        "\n",
        "\n",
        "    index_sequences = np.array(index_sequences)\n",
        "    num_seq = math.ceil((index_sequences.size) / maxnum)\n",
        "    index_sequences = index_sequences.flatten()\n",
        "\n",
        "    X = np.empty([num_seq, maxnum], dtype=np.int32)\n",
        "    mask = np.zeros([num_seq, maxnum], dtype=np.float32)\n",
        "\n",
        "    j = 0\n",
        "\n",
        "    for i in range(0, len(index_sequences), maxnum):\n",
        "        # Get a slice of elements for the current row\n",
        "        row = index_sequences[i:i + maxnum]\n",
        "\n",
        "        # If the row is shorter than maxnum, set values and mask for padding\n",
        "        X[j, :len(row)] = row\n",
        "        X[j, len(row):] = 1\n",
        "        mask[j, :len(row)] = 1\n",
        "        mask[j, len(row):] = 0\n",
        "\n",
        "        j += 1\n",
        "\n",
        "    return X, mask\n",
        "\n",
        "def prepare_sentence_data(input):\n",
        "    \n",
        "    data = read_input_essay(input)\n",
        "\n",
        "    X_data,mask = padding_sentence_sequences_input(data, max_num, post_padding=True)\n",
        "\n",
        "\n",
        "    return X_data,mask\n",
        "\n",
        "# from transformers import BertModel\n",
        "\n",
        "file = 'bert-base-uncased'\n",
        "bert_model = BertModel.from_pretrained(file)\n",
        "\n",
        "\n",
        "\n",
        "class mlp(nn.Module):\n",
        "    def __init__(self, in_f, out_f):\n",
        "        super(mlp, self).__init__()\n",
        "        self.layer1 = nn.Linear(in_f, 768)\n",
        "        self.active = nn.Tanh()\n",
        "        self.layer2 = nn.Linear(768, out_f)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class npcr_model(nn.Module):\n",
        "    def __init__(self, maxSq=512):\n",
        "        super(npcr_model, self).__init__()\n",
        "\n",
        "        self.embedding = bert_model\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "        self.nn1 = nn.Linear(768, 768)\n",
        "        self.output = nn.Linear(768, 1, bias=False)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        \"\"\"\n",
        "        Here we reproduce Keras default initialization weights for consistency with Keras version\n",
        "        \"\"\"\n",
        "        ih = (param.data for name, param in self.named_parameters() if 'weight_ih' in name)\n",
        "        hh = (param.data for name, param in self.named_parameters() if 'weight_hh' in name)\n",
        "        b = (param.data for name, param in self.named_parameters() if 'bias_ih' in name or 'bias_hh' in name)\n",
        "        # nn.init.uniform(self.embed.weight.data, a=-0.5, b=0.5)\n",
        "        for t in ih:\n",
        "            nn.init.xavier_uniform_(t)\n",
        "        for t in hh:\n",
        "            nn.init.orthogonal_(t)\n",
        "        for t in b:\n",
        "            nn.init.constant_(t, 0)\n",
        "\n",
        "    def forward(self, x0, x1):\n",
        "        x0_embed = self.embedding(x0)[1]\n",
        "        x1_embed = self.embedding(x1)[1]\n",
        "\n",
        "        # the linear layer nn1 can be replaced by MLP(the above or overwite by yourself)\n",
        "        x0_nn1 = self.nn1(x0_embed)\n",
        "        x1_nn1 = self.nn1(x1_embed)\n",
        "\n",
        "        x0_nn1_d = self.dropout(x0_nn1)\n",
        "        x1_nn1_d = self.dropout(x1_nn1)\n",
        "\n",
        "        diff_x = (x0_nn1_d - x1_nn1_d)\n",
        "        y = self.output(diff_x)\n",
        "\n",
        "        y = torch.sigmoid(y)\n",
        "\n",
        "        return y\n",
        "\n",
        "model = npcr_model(512)\n",
        "\n",
        "def replace_url(text):\n",
        "    replaced_text = re.sub('(http[s]?://)?((www)\\.)?([a-zA-Z0-9]+)\\.{1}((com)(\\.(cn))?|(org))', url_replacer, text)\n",
        "    return replaced_text\n",
        "max_num = 512\n",
        "def is_number(token):\n",
        "    return bool(num_regex.match(token))\n",
        "# .cuda()\n",
        "# For PyTorch model\n",
        "import torch\n",
        "\n",
        "\n",
        "model = torch.load('testrank_core_bert.prompt1.pt', map_location=torch.device('cpu'))\n",
        "# model = torch.load('testrank_core_bert.prompt1.pt')\n",
        "# model = model.to(device)\n",
        "\n",
        "# Function to convert model prediction to a score\n",
        "def convert_prediction_to_score(prediction):\n",
        "\n",
        "    scaled_factor = scaled_value(0, 10)\n",
        "    final_score = scaled_factor*prediction*2\n",
        "    return final_score\n",
        "\n",
        "def predict_score(essay_text, reference_text, model):\n",
        "    # Prepare input data\n",
        "    tensor_input,mask_input = prepare_sentence_data(essay_text)\n",
        "    tensor_reference,mask_reference = prepare_sentence_data(reference_text)\n",
        "\n",
        "    # Extract only the first sequence\n",
        "    tensor_input = torch.tensor(tensor_input)\n",
        "    mask_input = torch.tensor(mask_input)\n",
        "    tensor_reference = torch.tensor(tensor_reference)\n",
        "    mask_reference = torch.tensor(mask_reference)\n",
        "\n",
        "    # Move tensors to the specified device\n",
        "    tensor_input = tensor_input.to(device)\n",
        "    mask_input = mask_input.to(device)\n",
        "    tensor_reference = tensor_reference.to(device)\n",
        "    mask_reference = mask_reference.to(device)\n",
        "\n",
        "    size = tensor_input.size()\n",
        "\n",
        "    # Use the loaded model to make predictions\n",
        "    with torch.no_grad():\n",
        "        prediction = model(tensor_input, tensor_reference)\n",
        "\n",
        "\n",
        "    # Convert the model's prediction to a score\n",
        "    predicted_score = convert_prediction_to_score(prediction[0].item())\n",
        "\n",
        "    return predicted_score\n",
        "\n",
        "\n",
        "# from Reference import list\n",
        "lst =[\"the world. This is why chatting is the best setting. Computer helps the world in many ways. It helps kids if they need to research something. It helps the cops catch the bad people. The computer helps parents get from their children by vaction ads. This is has the computer helps the world. The computer does benifit our society. It has change the world. You can do many things on it. On the computer, you can chat with people from anywhere. The computer helps the world everyday. This is how the computer benifits our society.\",\"Dear Newspaper, I think computers are great. There really helpful. They can teach us about things. Also they have fun games and websites which is always a plus. Computers are helpful in lots of things, like if you need to look something up for school you can just easily go on the computer and find it also some teachers have websites now where insted of bringing a big social studies book home, you can go on the internet and use the online book. Did you know that @PERCENT1 of @CAPS1 students rather use the internet book then taking the actual one home. Also if you forgot to write down your homework theres a website to lookup all the homework you have. Also computers can teach us things. There are websites that have math games and school related things. Also you can easilly go on google and look up things and they can give you thousands of information. Lastly the internet is a good source for fun they have millions of games on the internet and also fun websites like facebook. Did you know @PERCENT2 of @CAPS1 students use the computer for the games and online talking. This also gives kids lots of things to do on a rainy day. So weither your using the internet for it's helpfulness its resources, or just for the fun games and websites. Computers are really helpful.\",\"Although some people believe that computers turn us children into zombies, I believe that they effect us in a posotive way. Computers can help us explore far away places that we @MONTH1 never go to. Maybe help us connect with an old friend or just a little help on homeworks. One reason why I think computers are only helping us is they help us explore othe places. I know for a fact that every kid dreams of a place that they would love to visit. But not at all of us can afford to travel far away. Most families however, do have computers. With these computers, kids with a parents permission, can use the internet to learn tons of cool facts about their place. \"\"I have always wanted to go to @LOCATION1 but my parents just don't have the proper incomg\"\" said @PERSON1 of @CAPS1-@CAPS2 @CAPS3 school @CAPS4 I used my @CAPS6 and the internet to discover. HUNDREDS of amazing facts on it.\"\" @CAPS4 as you can see computers can help people realize their dreams. Another reason why I\",\"said @PERSON1 of @CAPS1-@CAPS2 @CAPS3 school @CAPS4 I used my @CAPS6 and the internet to discover. HUNDREDS of amazing facts on it.\"\" @CAPS4 as you can see computers can help people realize their dreams. Another reason why I think computers are good is they help you connect with friends. If you are like me, you like to talk to your friends. A @CAPS5! But sometimes they are too far away to call if you don't want to pay for it. A solution a new wonderful machine called. The @CAPS6! You can chat long distances without being for it. This is especially good for me because not too long ago, one of my best friends moved away to @LOCATION2. I thoughy I would never talk to him again. Then I learned about @CAPS7 @CAPS8. It allows you to talk whenever you want, whenever you want! Now, me and my friend can stay in touch and @CAPS4 can you! My finale reason as to why I think computers are good is they can help you on homework too. Even have a tricky math problem you couldn't figure out? How about the capital of a state that visit, slipped your mined? Well the @CAPS6 can solve both of those problems and more! @PERCENT1 of computers these days come with soft wear in them that comes with a calculator. For the other @PERCENT1 you can download and install softwear onto your @CAPS6 for a low price. And every @CAPS6 made in this world has internet capabilities. All's you need to do is it on and get ready for a ride! @CAPS4 don'y worry about too much @CAPS6 use, because computers can only help us not hurt us. @CAPS4 remember, computers help us live our dreams to the full extent. they also help us connect with no another, and help us excel in school. @CAPS4 get on, and get goin. Have you used your @CAPS6 today?\",\"Dear local newspaper, @CAPS1 you know how long you go on the computer for? Well get up and go outside. Thats one of my reasons why I think people spend to much time on it my other reason is your eyesit can go bad. Its a nice sunny day dont wast your time on the computer! Go outside! All, kids @CAPS1 is sit on the computer all day not getting exercis. Did you know @NUM1 out of @NUM2 kids that sit on the computers all day gain at least @NUM3? @PERSON1 told me that. I mean I believe him because its true kids dont get up.There missing a nice day out would you wanna miss a nice sunny day? My finall reason is kids eyesight can go bad. I mean having them stare at a screen all day, thats bad. @PERSON1 told me if your on the computer for @NUM4 hours on the computer for @NUM4 hours straight your eyes can get worst. I remember a tiny when I was on the computer for @NUM4 1/@NUM4 hours my eyes were killing me everything I blink. I know the computer is fun playing games, talking to friends but you should take a break and @CAPS1 something ples. In conclusion just go outside and have fun! @CAPS1 you want to wast a nice sunny day by staying in doors hurting your eyes? I know I @CAPS1!\"]\n",
        "\n",
        "# Move the model to GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "loaded_model = model.to(device)\n",
        "\n",
        "\n",
        "def vaibhav(input):\n",
        "    score = []\n",
        "    for i,reference_essay in enumerate(lst):\n",
        "            predicted_score = predict_score(input, reference_essay, loaded_model)\n",
        "            score.append(predicted_score)\n",
        "\n",
        "    final =  ((sum(score)/len(score)))/10\n",
        "    # print(\"Score of the essay is : \",final)\n",
        "    return final\n",
        "\n",
        "\n",
        "def get_final_score_vaibhav(essays):\n",
        "    main_data = pd.DataFrame()\n",
        "    essays = [essays]\n",
        "    prompt = [prompt]\n",
        "\n",
        "\n",
        "    main_data = pd.DataFrame()\n",
        "    temp_df = pd.DataFrame({\n",
        "        'score_vaibhav' : vaibhav(essays[0]),\n",
        "        # 'normalized_score': normalized_score\n",
        "      }, index=[0])\n",
        "\n",
        "    main_data = pd.concat([main_data, temp_df], ignore_index=True)\n",
        "    return main_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VxSRpmWZRvh"
      },
      "source": [
        "#### LOADING MODELS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVQFmDlPZRvi",
        "outputId": "3a400a75-71cb-4e20-9411-176498a87da6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/375 [03:30<21:49:18, 210.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.5041676  0.5058102  0.502608   0.50287455 0.50404686 0.50277233\n",
            " 0.50056565 0.5020878  0.5010128  0.503953   0.5014078  0.50247675\n",
            " 0.5045078  0.50253713 0.5027312  0.5011677  0.5047954  0.5013811\n",
            " 0.50262076 0.5020898  0.5041601  0.5029414  0.5050386  0.5051391\n",
            " 0.5047843  0.50509703 0.50239867 0.50468963 0.50275725 0.5047855\n",
            " 0.50498825 0.5026075 ]\n",
            "out_coher: [0.20128092 0.25307566 0.3057093  0.25506708 0.486871   0.28607333\n",
            " 0.49314734 0.2623561  0.49528807 0.48553845 0.29493693 0.4938039\n",
            " 0.25549588 0.28205845 0.26798272 0.21793818 0.49968788 0.22260246\n",
            " 0.49619412 0.3018118  0.24301194 0.48705998 0.21740443 0.35942394\n",
            " 0.23218921 0.520518   0.5018147  0.50791806 0.24308681 0.47924337\n",
            " 0.4979789  0.33004555]\n",
            "out_prompt: [3.7481838e-01 3.3711219e-01 3.5261744e-01 1.6347622e-03 5.9876265e-04\n",
            " 8.8455759e-02 4.3537896e-04 3.0506713e-02 2.2002889e-04 9.7791723e-04\n",
            " 1.2113331e-03 4.9347960e-04 2.3321380e-01 3.9572718e-05 5.6572873e-03\n",
            " 3.7320857e-03 4.4233733e-04 2.8152380e-03 1.6973396e-04 3.7582588e-01\n",
            " 3.9074264e-02 4.6374579e-04 3.2306598e-03 2.1565683e-02 1.6522548e-03\n",
            " 2.5506249e-01 9.4520850e-03 1.2802638e-03 6.7851756e-04 3.5630512e-01\n",
            " 3.6590710e-01 1.7061766e-03]\n",
            "combined_score: [0.8089645504951477, 0.7509770393371582, 0.3830060660839081, 0.49134451150894165, 0.6217251420021057, 0.5068507194519043, 0.7659192085266113, 0.6684898734092712, 0.7423932552337646, 0.5384134650230408, 0.6579111218452454, 0.6989704370498657, 0.677025556564331, 0.34712791442871094, 0.6346402764320374, 0.5627251863479614, 0.6145594716072083, 0.3555423617362976, 0.6352373957633972, 0.584093451499939, 0.8007922172546387, 0.4646506905555725, 0.49567145109176636, 0.6813594102859497, 0.5353637933731079, 0.7754020690917969, 0.6241016387939453, 0.6088380813598633, 0.553592324256897, 0.4940599203109741, 0.14477774500846863, 0.4937933683395386]\n",
            "coherence_score_nli: [0.02900255666463636, 0.08082141308113933, 0.0, 0.053883322436983384, 0.17676403987570666, 0.2098458447597093, 0.08000460561985771, 0.05735557805746794, 0.12906764950603247, 0.18209633845835924, 0.13587885916543505, 0.1939341001303142, 0.041417800795493856, 0.12279111643632253, 0.13840732040504614, 0.37103900127112865, 0.1303337442688644, 0.2228147517889738, 0.09305790144329269, 0.10016601847989175, 0.061411408125422895, 0.1721137210726738, 0.08919080059664945, 0.2873355846174739, 0.050341054797172546, 0.09980345714332846, 0.1746746662001197, 0.15211123673038351, 0.2830615702162807, 0.05360168315625439, 0.8491758108139038, 0.18197965979292666]\n",
            "normalized_score: [1.         1.         0.61111111 0.5        0.7        0.6\n",
            " 1.         0.4        1.         0.5        0.33333333 0.75\n",
            " 0.66666667 0.5        0.66666667 0.4        0.5        0.33333333\n",
            " 0.75       0.77777778 0.88888889 0.5        0.66666667 0.6\n",
            " 0.66666667 1.         0.7        1.         0.66666667 0.5\n",
            " 0.         0.4       ]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 2/375 [07:00<21:45:27, 209.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.50195634 0.50283825 0.50206286 0.5018214  0.5044791  0.5060237\n",
            " 0.5060105  0.505131   0.5045028  0.5009789  0.5004945  0.500899\n",
            " 0.506553   0.5048256  0.5014836  0.5006048  0.50181043 0.5057422\n",
            " 0.5049106  0.5001196  0.5025507  0.5001426  0.504355   0.5025994\n",
            " 0.5026567  0.50396544 0.50178224 0.50338495 0.5062427  0.5015843\n",
            " 0.50428295 0.5044761 ]\n",
            "out_coher: [0.27353266 0.28895065 0.51333785 0.4977665  0.47825173 0.1866511\n",
            " 0.3003453  0.4805716  0.21293339 0.50281715 0.5044949  0.48646092\n",
            " 0.23832285 0.49989364 0.48328513 0.20883188 0.2128558  0.27511472\n",
            " 0.506421   0.24195035 0.50893205 0.24842139 0.49660793 0.50077254\n",
            " 0.20818193 0.15969677 0.35215387 0.5213442  0.27518004 0.48956728\n",
            " 0.24001464 0.28714016]\n",
            "out_prompt: [3.8168782e-01 3.6919311e-01 5.4765709e-02 2.1706663e-04 8.2059741e-02\n",
            " 4.3425080e-03 6.4740749e-04 3.1072509e-01 9.4798929e-04 5.1836896e-04\n",
            " 1.0416515e-01 2.3699630e-04 3.4353736e-01 3.6868864e-01 1.5264735e-01\n",
            " 3.8073480e-01 2.9232284e-01 2.3547320e-02 5.3276500e-04 3.4964573e-01\n",
            " 3.6495197e-01 3.2785782e-01 1.4162502e-03 5.9197984e-05 5.6318408e-03\n",
            " 3.7227249e-01 7.5432353e-02 1.0407150e-03 9.1658876e-04 8.0360910e-03\n",
            " 3.7557986e-01 1.4734869e-03]\n",
            "combined_score: [0.7249132394790649, 0.1265864074230194, 0.6490401029586792, 0.7190290689468384, 0.5344785451889038, 0.564810574054718, 0.39449217915534973, 0.6711390614509583, 0.6786651015281677, 0.8351670503616333, 0.5973444581031799, 0.7798693776130676, 0.1622929722070694, 0.5700590014457703, 0.4408003091812134, 0.5468209981918335, 0.43502506613731384, 0.6619346141815186, 0.7181810140609741, 0.7458395957946777, 0.674817681312561, 0.630161702632904, 0.7709407806396484, 0.7184325456619263, 0.5964237451553345, 0.296063095331192, 0.6178517937660217, 0.48388129472732544, 0.7330528497695923, 0.7019711136817932, 0.562433660030365, 0.7127934098243713]\n",
            "coherence_score_nli: [0.02759631509737422, 0.0, 0.13585799955762923, 0.15774220597813837, 0.15875471368457916, 0.06334932870231569, 0.08385717961937189, 0.13224999204447324, 0.08427210591201272, 0.1893921459268313, 0.1787415085360408, 0.1464326542669109, 0.5203396081924438, 0.16666666213423015, 0.2406002159363457, 0.020806366531178355, 0.2144745032665714, 0.2030217434144824, 0.11656474531628191, 0.15067045514115307, 0.15637872533552583, 0.01931080999202095, 0.12320550647564232, 0.1238113811791495, 0.14345858680705229, 0.007288975175470114, 0.15115328377578408, 0.16250136730377562, 0.09525011647825263, 0.1380429288433136, 0.07058924529701471, 0.0924797919831927]\n",
            "normalized_score: [0.83333333 0.         0.6        0.75       0.6        0.66666667\n",
            " 0.33333333 0.7        0.66666667 0.9        0.6        0.75\n",
            " 0.33333333 0.5        0.4        0.72222222 0.2        0.6\n",
            " 0.5        0.77777778 0.5        0.66666667 1.         0.8\n",
            " 0.66666667 0.33333333 0.6        0.5        1.         0.6\n",
            " 1.         0.8       ]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 3/375 [10:13<20:55:45, 202.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.5038754  0.5047081  0.50483525 0.501616   0.5023313  0.50302935\n",
            " 0.50651187 0.50722605 0.5003463  0.50342387 0.5004033  0.5086954\n",
            " 0.4996521  0.5041163  0.5030865  0.504545   0.49995363 0.49388197\n",
            " 0.50634474 0.50375015 0.5037394  0.5037652  0.49822786 0.5018451\n",
            " 0.50365996 0.5028655  0.50623566 0.50372934 0.5034286  0.49971393\n",
            " 0.5043417  0.505206  ]\n",
            "out_coher: [0.49701285 0.30287424 0.24867696 0.4939459  0.24378747 0.2007252\n",
            " 0.50329244 0.5090041  0.29975808 0.22154742 0.5157145  0.50380087\n",
            " 0.42291284 0.25354356 0.49590722 0.5023525  0.52209383 0.46966738\n",
            " 0.27739727 0.26849863 0.49192095 0.49476674 0.27433544 0.4979245\n",
            " 0.23336434 0.48385927 0.2155025  0.21329747 0.37895668 0.51243526\n",
            " 0.23130523 0.4853448 ]\n",
            "out_prompt: [3.1208005e-03 6.9638086e-03 3.6201063e-01 2.9628402e-01 1.0678002e-01\n",
            " 7.2220587e-03 1.1940798e-03 9.6981442e-03 3.6162813e-03 3.7402523e-01\n",
            " 3.5537845e-01 4.8658168e-03 2.6868465e-05 4.1036230e-01 1.0981938e-03\n",
            " 4.3216324e-04 3.6307752e-01 1.2860911e-03 2.3133755e-03 1.0370266e-02\n",
            " 1.9426577e-04 3.5895878e-01 3.5672984e-01 5.2219321e-04 3.8183409e-01\n",
            " 3.4831809e-03 3.6635411e-01 3.5876858e-01 3.8382089e-01 3.8909140e-01\n",
            " 3.6047643e-01 3.6364883e-01]\n",
            "combined_score: [0.5183544158935547, 0.6715822219848633, 0.26325109601020813, 0.7897017002105713, 0.3767870366573334, 0.756368100643158, 0.7373272776603699, 0.7257134914398193, 0.6455768346786499, 0.2638842463493347, 0.7066478729248047, 0.6442165374755859, 0.7104535102844238, 0.36742591857910156, 0.5450201630592346, 0.677943766117096, 0.7834855914115906, 0.7522525787353516, 0.6089065670967102, 0.5297753214836121, 0.4713486433029175, 0.6546770930290222, 0.6555535793304443, 0.5754648447036743, 0.5958672165870667, 0.6431176662445068, 0.795494019985199, 0.32311105728149414, 0.3513900637626648, 0.6639143824577332, 0.6440798044204712, 0.807515561580658]\n",
            "coherence_score_nli: [0.22264443103922532, 0.16566330582524338, 0.0, 0.09432171616936103, 0.1138550393017275, 0.13460927905345504, 0.11446846835315228, 0.2938765953294933, 0.22697637043893337, 0.0, 0.1070469099296523, 0.18410632868900018, 0.19367128691488975, 0.0017898834776133299, 0.28088880019883317, 0.20067501581568076, 0.09222455220879056, 0.16794630069246827, 0.09592815291834995, 0.22811982857392116, 0.026822763407835737, 0.058484858533899696, 0.10092115487592916, 0.24729813926893732, 0.17051197066903115, 0.28952392869229826, 0.3284302060492337, 0.0005821510567329824, 0.02261311002075672, 0.14332845502067357, 0.09463067824253812, 0.12682147251649034]\n",
            "normalized_score: [0.4        0.6        0.         1.         0.4        0.66666667\n",
            " 0.75       0.7        1.         0.         1.         0.4\n",
            " 0.6        0.33333333 0.5        0.6        0.75       0.8\n",
            " 0.4        0.4        0.5        0.75       0.66666667 0.6\n",
            " 0.94444444 0.75       0.94444444 0.         0.33333333 0.75\n",
            " 0.66666667 1.        ]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 4/375 [13:42<21:08:40, 205.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.50306916 0.50068057 0.5058496  0.504758   0.5038954  0.50461924\n",
            " 0.5019042  0.50255346 0.5034965  0.49885985 0.50266594 0.5020915\n",
            " 0.5009798  0.50136834 0.50069535 0.504953   0.5028172  0.5044715\n",
            " 0.50051075 0.5049442  0.5028525  0.49328253 0.5020175  0.50448674\n",
            " 0.5013468  0.5019502  0.5043612  0.50113434 0.50142175 0.50650305\n",
            " 0.50372595 0.50295   ]\n",
            "out_coher: [0.49605027 0.20978342 0.22859216 0.23277217 0.27950144 0.28386027\n",
            " 0.2105453  0.20300959 0.5059921  0.49642256 0.27083147 0.26943952\n",
            " 0.5143301  0.25643036 0.20159145 0.2259805  0.49104574 0.30640435\n",
            " 0.24104436 0.24861515 0.24861382 0.41727608 0.24322708 0.25241113\n",
            " 0.48595354 0.18963791 0.48485252 0.19018894 0.17918631 0.49456298\n",
            " 0.48975822 0.501661  ]\n",
            "out_prompt: [3.3486354e-01 4.3410607e-04 1.4388168e-03 3.4933361e-01 3.6769563e-01\n",
            " 3.6407551e-01 3.6710027e-01 1.3395338e-01 1.3142708e-03 3.4096646e-01\n",
            " 1.1128543e-03 1.4391498e-03 1.6292739e-01 3.7149999e-01 9.8700970e-03\n",
            " 9.4682706e-04 1.0127433e-03 5.8171414e-02 3.7132183e-01 9.4823958e-04\n",
            " 1.2985275e-03 9.6925913e-04 3.5712537e-01 3.6567909e-01 1.6100240e-03\n",
            " 1.0578325e-03 2.8987715e-01 3.7046621e-04 3.9263061e-01 3.5249028e-01\n",
            " 3.3905262e-01 8.2836404e-02]\n",
            "combined_score: [0.42408546805381775, 0.2688134014606476, 0.7415646314620972, 0.5178167819976807, 0.41078394651412964, 0.6694475412368774, 0.599298357963562, 0.6817396283149719, 0.5891706943511963, 0.6920348405838013, 0.44461941719055176, 0.7658313512802124, 0.623840868473053, 0.5282071828842163, 0.6820632815361023, 0.5383668541908264, 0.5205683708190918, 0.6040201783180237, 0.5264955759048462, 0.37336885929107666, 0.531451940536499, 0.5910364389419556, 0.6489666104316711, 0.21284353733062744, 0.7390409708023071, 0.49129781126976013, 0.5885449051856995, 0.7555071115493774, 0.36226364970207214, 0.528328001499176, 0.6915877461433411, 0.6031054258346558]\n",
            "coherence_score_nli: [0.16279953430322083, 0.059765081852674484, 0.10698316413133095, 0.015649895028521616, 0.34131919199393856, 0.051895004347898066, 0.058838644597147195, 0.28904595569922376, 0.24124513193964958, 0.05733419582247734, 0.11857605755794794, 0.018776502925902605, 0.12621344421916691, 0.21308599793701433, 0.15085813278953233, 0.09318163928886254, 0.015942061960231513, 0.3191203892997959, 0.09309991728514433, 0.02205154113471508, 0.09348975587636232, 0.14872487259117406, 0.3146878699106829, 0.052840158343315125, 0.1743450307339016, 0.08457697400202353, 0.10057869229543333, 0.13208075451664628, 0.046606700867414474, 0.15395046334015206, 0.04404492462232996, 0.14635634356980315]\n",
            "normalized_score: [0.4        0.33333333 1.         0.55555556 0.4        0.66666667\n",
            " 0.77777778 0.7        1.         0.75       0.66666667 1.\n",
            " 0.77777778 0.         1.         0.33333333 0.75       0.6\n",
            " 0.66666667 0.25       1.         0.6        0.6        0.\n",
            " 1.         0.66666667 0.6        0.8        0.33333333 0.4\n",
            " 0.77777778 0.4       ]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|▏         | 5/375 [17:13<21:18:26, 207.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.50055844 0.49944332 0.50032234 0.5021193  0.5032242  0.50050396\n",
            " 0.50569177 0.4920254  0.5024821  0.5038018  0.50326246 0.5032311\n",
            " 0.5065999  0.5050708  0.5073802  0.5014173  0.5030377  0.50268984\n",
            " 0.50373846 0.5028733  0.5010309  0.50401014 0.50526786 0.5035871\n",
            " 0.50481313 0.50015014 0.50570637 0.50615484 0.50107026 0.50301987\n",
            " 0.50221115 0.5051882 ]\n",
            "out_coher: [0.50253296 0.25059667 0.17756182 0.4997006  0.21937269 0.2198983\n",
            " 0.50231296 0.3293674  0.24464247 0.32947046 0.50181353 0.24653304\n",
            " 0.24194016 0.51400983 0.1973884  0.47816497 0.51499885 0.47962573\n",
            " 0.5103975  0.21027973 0.28378758 0.245397   0.2401445  0.24917229\n",
            " 0.47861448 0.40361148 0.21163084 0.5033299  0.4841402  0.25602087\n",
            " 0.27358583 0.50025225]\n",
            "out_prompt: [3.4572239e-04 1.5862143e-01 9.6345879e-04 3.8491634e-01 3.4966657e-01\n",
            " 3.5046434e-01 5.9543923e-02 1.1910956e-03 8.1805832e-04 3.7117296e-01\n",
            " 3.5243246e-01 1.3120086e-01 3.6868286e-01 3.6522627e-03 1.4164593e-03\n",
            " 3.5653171e-01 3.6968297e-01 4.0547969e-04 3.6227819e-01 8.7401160e-04\n",
            " 3.6510354e-01 1.1111064e-01 3.7418246e-01 1.0610885e-03 4.7352612e-03\n",
            " 2.5279386e-04 3.7867931e-01 1.7959550e-03 3.6214826e-01 3.6085075e-01\n",
            " 2.7065277e-03 3.6102828e-01]\n",
            "combined_score: [0.43428272008895874, 0.5115365982055664, 0.6815442442893982, 0.7789926528930664, 0.6640511155128479, 0.6465895175933838, 0.823276162147522, 0.8785363435745239, 0.3587896227836609, 0.7097679376602173, 0.4564625918865204, 0.6052548885345459, 0.42068395018577576, 0.5299623608589172, 0.47988536953926086, 0.6244540214538574, 0.47684744000434875, 0.5747385025024414, 0.5526586771011353, 0.7978845834732056, 0.5875755548477173, 0.564217746257782, 0.29158663749694824, 0.5636425018310547, 0.7345653176307678, 0.8542595505714417, 0.5825821161270142, 0.6187446117401123, 0.8058859705924988, 0.673839271068573, 0.674614667892456, 0.8708095550537109]\n",
            "coherence_score_nli: [0.40920156333595514, 0.15287308442251135, 0.005133969090820756, 0.07974665869648258, 0.1458395984955132, 0.013419669052382233, 0.05691088332591958, 0.1097170474477025, 0.13916947692632675, 0.09793729679659009, 0.20249931948880354, 0.142449693993994, 0.18338040681555867, 0.16529384503761926, 0.3085675872862339, 0.2864969196832842, 0.13397906293076547, 0.12718052277341485, 0.12080016848631203, 0.1881748703867197, 0.18377091316506267, 0.22827885049628094, 0.2553364485502243, 0.0667170052183792, 0.20143002203743285, 0.16607943239311376, 0.26122161839157343, 0.24135867149743717, 0.05801727661552528, 0.03517629023796568, 0.3461364184816678, 0.08522709391804205]\n",
            "normalized_score: [0.25       0.4        0.66666667 0.88888889 0.66666667 0.77777778\n",
            " 0.83333333 0.9        0.5        0.66666667 0.4        0.4\n",
            " 0.72222222 0.33333333 0.33333333 0.25       0.6        0.75\n",
            " 0.4        0.6        0.77777778 0.6        0.4        0.33333333\n",
            " 0.8        0.8        0.75       0.5        1.         1.\n",
            " 1.         0.75      ]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 6/375 [20:16<20:23:33, 198.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.50324804 0.50947803 0.5044832  0.5042509  0.50504315 0.50138474\n",
            " 0.50550455 0.5062647  0.50404215 0.50234187 0.4990321  0.5030232\n",
            " 0.5017519  0.50337267 0.498706   0.5028516  0.50081444 0.5064656\n",
            " 0.50477976 0.5045509  0.5027393  0.5061717  0.50439054 0.5065653\n",
            " 0.5058003  0.50478166 0.502493   0.50166374 0.49902165 0.50486755\n",
            " 0.505068   0.5042761 ]\n",
            "out_coher: [0.48433462 0.20711361 0.20885387 0.50712407 0.22889476 0.51094574\n",
            " 0.285769   0.21630403 0.5076762  0.4925852  0.2839048  0.29609662\n",
            " 0.48242754 0.48804477 0.25972337 0.50081617 0.2757927  0.27194345\n",
            " 0.28526786 0.4966437  0.28098372 0.4777677  0.495429   0.27992323\n",
            " 0.21733926 0.51426387 0.22133923 0.22166325 0.49315175 0.21119143\n",
            " 0.5050091  0.48671213]\n",
            "out_prompt: [3.7373704e-01 3.7495074e-01 7.7302760e-04 1.5599023e-01 2.3894746e-02\n",
            " 3.7713712e-01 3.7073958e-01 3.7275773e-01 1.8476482e-04 3.6119402e-04\n",
            " 4.0983484e-04 3.9452240e-01 3.5346285e-01 1.3493121e-02 2.6431354e-02\n",
            " 2.3167094e-03 1.0302180e-01 2.8197342e-03 1.0555178e-03 2.1716849e-04\n",
            " 3.4244624e-01 2.3226321e-03 1.0196811e-01 2.8852304e-03 3.5276508e-01\n",
            " 3.3831033e-01 3.7572950e-01 8.9792610e-04 3.7013900e-01 3.7293503e-01\n",
            " 1.0886214e-02 3.6925948e-01]\n",
            "combined_score: [0.4542286694049835, 0.24073262512683868, 0.41382551193237305, 0.503722071647644, 0.6132082343101501, 0.4865895211696625, 0.6689902544021606, 0.37889641523361206, 0.4911794066429138, 0.7039095759391785, 0.7734251022338867, 0.42366209626197815, 0.5031243562698364, 0.6154847145080566, 0.7129917144775391, 0.8197794556617737, 0.8073370456695557, 0.5387773513793945, 0.25557392835617065, 0.6016054749488831, 0.47212061285972595, 0.696320116519928, 0.8088721036911011, 0.6168814301490784, 0.7996466755867004, 0.7128095030784607, 0.3494834303855896, 0.47483083605766296, 0.26082003116607666, 0.4831831157207489, 0.5729673504829407, 0.646276593208313]\n",
            "coherence_score_nli: [0.04102438264453667, 0.0, 0.0, 0.16346341832540928, 0.1528763025708031, 0.17918437564124665, 0.08058814462274314, 0.10513649135828018, 0.2155646285771028, 0.1940540895642092, 0.1414425166190735, 0.18115555122494698, 0.29587807366624475, 0.16172929995638483, 0.16340606172161642, 0.07159732913391458, 0.09864211820497397, 0.1688905154587701, 0.0, 0.2272322266140864, 0.06578253820242191, 0.13129583920817822, 0.13790350424139486, 0.16201957955490798, 0.030122139533473688, 0.2894628846940274, 0.0, 0.02331404418994983, 0.5329584032297134, 0.1294335308484733, 0.21408666585768132, 0.15118648843573673]\n",
            "normalized_score: [0.5        0.25       0.25       0.4        0.6        0.33333333\n",
            " 1.         0.         0.4        0.5        0.8        0.33333333\n",
            " 0.5        0.7        0.6        0.75       1.         0.66666667\n",
            " 0.33333333 0.7        0.77777778 0.75       0.83333333 0.66666667\n",
            " 0.66666667 0.5        0.33333333 0.33333333 0.         0.25\n",
            " 0.6        0.75      ]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 7/375 [23:30<20:09:05, 197.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.4981102  0.50395054 0.50510234 0.5062168  0.5044323  0.5017649\n",
            " 0.50412256 0.50298727 0.50177294 0.5005379  0.5025836  0.5042765\n",
            " 0.50281054 0.5000427  0.50382835 0.5030029  0.5043332  0.5046169\n",
            " 0.5049817  0.49814686 0.50238425 0.5007963  0.5004261  0.50509804\n",
            " 0.50452137 0.50048083 0.50422966 0.50190777 0.50456375 0.5034171\n",
            " 0.5002416  0.5047075 ]\n",
            "out_coher: [0.21006149 0.41474247 0.25210774 0.48805913 0.22219439 0.2381349\n",
            " 0.30278045 0.49887726 0.5037335  0.48760986 0.5060668  0.25025982\n",
            " 0.48287818 0.26372358 0.49140346 0.22680572 0.22293374 0.4981465\n",
            " 0.24430175 0.2733209  0.21936406 0.50343096 0.4972926  0.23243879\n",
            " 0.50197613 0.48419094 0.50262916 0.4955593  0.4893228  0.47380605\n",
            " 0.29623154 0.20918964]\n",
            "out_prompt: [9.2006335e-03 9.9827834e-05 2.1461423e-03 3.5625613e-01 3.3004364e-01\n",
            " 3.5126069e-01 1.2503625e-03 3.5568607e-01 3.5528424e-01 4.7444501e-03\n",
            " 4.8729384e-04 3.5137492e-01 7.0664245e-03 3.8067216e-01 1.4433084e-03\n",
            " 2.4464990e-03 1.6304346e-03 7.6417840e-04 3.6278760e-01 3.6293849e-01\n",
            " 3.6867595e-01 3.4632769e-01 3.6213884e-01 9.7070478e-02 1.3715514e-03\n",
            " 3.9859799e-01 6.6935502e-02 5.5735498e-03 3.6669293e-01 3.6050332e-01\n",
            " 1.1564465e-03 3.5725915e-01]\n",
            "combined_score: [0.424555242061615, 0.8193635940551758, 0.3485032618045807, 0.8120318651199341, 0.6616647839546204, 0.2915918827056885, 0.6519461870193481, 0.7371422648429871, 0.645552396774292, 0.8804504871368408, 0.5288141369819641, 0.5406090021133423, 0.6454092860221863, 0.45488879084587097, 0.7118863463401794, 0.4538175165653229, 0.6303644180297852, 0.6049014329910278, 0.5660684704780579, 0.42267829179763794, 0.38225698471069336, 0.6844302415847778, 0.8004943132400513, 0.5095055103302002, 0.7853372097015381, 0.6505295038223267, 0.3749864101409912, 0.6238833069801331, 0.6955757737159729, 0.7818686366081238, 0.5258470773696899, 0.6266601085662842]\n",
            "coherence_score_nli: [0.31351619213819504, 0.19054901439812966, 0.10266236832831055, 0.06515967364733417, 0.03616591835660594, 0.0, 0.30918372073210776, 0.1335300779069907, 0.36400112378246646, 0.10791455998939152, 0.2931801344923399, 0.2553310438990593, 0.16770342934787982, 0.36479300260543823, 0.11809061239990923, 0.4653321676887572, 0.14988858341239392, 0.1444972252772589, 0.05252728424966335, 0.3186380583756545, 0.0, 0.3103745127251993, 0.018113275431096552, 0.26132858369517353, 0.17002763925120234, 0.11799835221609101, 0.18450083641024928, 0.31977818030420513, 0.07864964324980975, 0.09709548333194107, 0.23152256752971723, 0.053980515202662595]\n",
            "normalized_score: [0.         0.8        0.33333333 1.         0.4        0.33333333\n",
            " 1.         1.         0.5        1.         0.6        0.5\n",
            " 0.6        0.33333333 0.75       0.33333333 0.66666667 0.5\n",
            " 0.61111111 0.83333333 0.25       0.5        0.5        0.4\n",
            " 1.         0.75       0.4        0.6        0.75       1.\n",
            " 0.6        0.66666667]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 8/375 [26:56<20:24:13, 200.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.50231683 0.50589174 0.50118303 0.5031869  0.5019471  0.505782\n",
            " 0.50428474 0.5054589  0.49978462 0.50403094 0.5075097  0.50384575\n",
            " 0.49840817 0.5043646  0.50317794 0.5019296  0.50163764 0.50007385\n",
            " 0.50502306 0.50324684 0.5002696  0.5045333  0.5035324  0.5021492\n",
            " 0.50246066 0.50483865 0.4994061  0.50424725 0.5038579  0.5004523\n",
            " 0.501888   0.50123155]\n",
            "out_coher: [0.5085158  0.2479236  0.260184   0.21995826 0.49136275 0.50122726\n",
            " 0.2009056  0.50618076 0.29743102 0.3089583  0.4870553  0.21759799\n",
            " 0.4962032  0.51291806 0.23486307 0.48359907 0.5110454  0.20727879\n",
            " 0.29316542 0.49619165 0.5154281  0.22478072 0.24430475 0.51368076\n",
            " 0.49418917 0.50223464 0.30540255 0.31970227 0.2884814  0.24548163\n",
            " 0.33599094 0.22921658]\n",
            "out_prompt: [1.5223774e-03 3.0670220e-01 3.8489074e-01 3.7937275e-01 1.9109958e-04\n",
            " 2.1391321e-02 7.7213137e-03 3.5965586e-01 1.4183730e-02 1.3278226e-03\n",
            " 1.2886796e-02 3.5206714e-01 1.1706623e-02 5.0549641e-02 9.0443790e-02\n",
            " 4.7859509e-04 4.0085196e-01 4.4462220e-03 1.1131613e-03 3.7868693e-01\n",
            " 1.6212107e-04 1.3061620e-03 3.6733103e-01 3.6945334e-01 3.6399093e-01\n",
            " 3.8020998e-01 3.7017903e-01 1.6707431e-03 3.3574176e-03 4.2417743e-03\n",
            " 1.3400773e-03 3.3672816e-01]\n",
            "combined_score: [0.7911475300788879, 0.5513442754745483, 0.5997871160507202, 0.7015222907066345, 0.7277156114578247, 0.5840564370155334, 0.7883241176605225, 0.7512066960334778, 0.7758816480636597, 0.51435786485672, 0.6661731004714966, 0.6069066524505615, 0.6259343028068542, 0.5207193493843079, 0.49374809861183167, 0.47449764609336853, 0.5279034376144409, 0.4837682843208313, 0.6069909334182739, 0.4949055314064026, 0.8548682332038879, 0.7319377064704895, 0.5593125820159912, 0.7228314876556396, 0.6432414054870605, 0.6502978801727295, 0.6568223834037781, 0.5588688254356384, 0.5006570816040039, 0.5182604789733887, 0.7075346112251282, 0.4827595353126526]\n",
            "coherence_score_nli: [0.11924043430813722, 0.2303391255151767, 0.06083419488277286, 0.045335821947082876, 0.15634997259599692, 0.21411617178147516, 0.1444382032337175, 0.11876439879415557, 0.173229171934983, 0.07708935174159706, 0.1313825530587169, 0.6487274169921875, 0.18304359969624784, 0.32748468284262344, 0.18010024520481238, 0.05769126329687424, 0.13354339384074723, 0.056732057283322014, 0.052955401285241045, 0.07217173177438478, 0.06978860936270884, 0.28671639746365446, 0.10567322216229513, 0.06541987143767376, 0.12302256813272834, 0.14489666345928395, 0.005721444962546229, 0.13288387036300264, 0.0353397784444193, 0.01872253728409608, 0.06907909525034484, 0.022043696604669094]\n",
            "normalized_score: [1.         0.4        0.88888889 0.         0.7        0.6\n",
            " 0.7        1.         0.6        0.75       0.7        0.33333333\n",
            " 0.6        0.6        0.6        0.5        0.94444444 0.66666667\n",
            " 0.66666667 0.5        0.7        0.66666667 0.66666667 1.\n",
            " 0.5        0.83333333 0.77777778 0.66666667 0.33333333 0.33333333\n",
            " 1.         0.44444444]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 9/375 [30:19<20:25:03, 200.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.5018625  0.50550115 0.50203454 0.50617903 0.5037906  0.5026193\n",
            " 0.50397074 0.5044152  0.49818668 0.501886   0.50440556 0.5037108\n",
            " 0.50479656 0.50240004 0.5027331  0.5042888  0.50611067 0.50119567\n",
            " 0.50143695 0.5026636  0.5017979  0.5043445  0.4999746  0.503511\n",
            " 0.500204   0.5045779  0.5016654  0.5047843  0.5045473  0.50471604\n",
            " 0.50174093 0.49991715]\n",
            "out_coher: [0.50656635 0.51894796 0.48525667 0.5052192  0.49720186 0.47561455\n",
            " 0.21561319 0.20928545 0.4525625  0.29054794 0.49013874 0.48041308\n",
            " 0.25894558 0.49824616 0.52416015 0.50487256 0.49233034 0.49868554\n",
            " 0.507329   0.49370077 0.49861816 0.49656114 0.5207955  0.23165433\n",
            " 0.31727928 0.49876484 0.2941964  0.23073383 0.26167467 0.27463564\n",
            " 0.49170792 0.5062575 ]\n",
            "out_prompt: [1.74950121e-03 1.67261076e-03 3.64520936e-03 1.62373134e-03\n",
            " 1.53397977e-01 8.33479688e-03 1.82315484e-01 3.74921918e-01\n",
            " 1.71761676e-05 6.60721511e-02 1.11567148e-03 1.66586608e-01\n",
            " 4.16502468e-02 3.56847495e-01 1.38161168e-01 4.44988022e-04\n",
            " 3.62576485e-01 3.58131319e-01 3.92905384e-01 6.16657510e-02\n",
            " 1.33326394e-03 3.82302493e-01 9.77122225e-03 2.46859831e-03\n",
            " 3.35030586e-01 3.87847155e-01 3.58782530e-01 3.55333596e-01\n",
            " 3.53213310e-01 1.83233507e-02 1.17798254e-01 3.80001783e-01]\n",
            "combined_score: [0.6511938571929932, 0.3349531888961792, 0.44356822967529297, 0.5279377102851868, 0.5378800630569458, 0.5811463594436646, 0.3248492181301117, 0.41588419675827026, 0.5656259655952454, 0.5280890464782715, 0.6726062297821045, 0.5116556286811829, 0.4275856018066406, 0.6544349193572998, 0.6618770956993103, 0.6716638803482056, 0.7819579839706421, 0.6385872960090637, 0.6832255721092224, 0.5689685344696045, 0.7471293210983276, 0.6525701284408569, 0.5603658556938171, 0.4714984595775604, 0.7440592646598816, 0.7060335278511047, 0.43563899397850037, 0.7790241837501526, 0.15221494436264038, 0.6393940448760986, 0.594569742679596, 0.5043736100196838]\n",
            "coherence_score_nli: [0.17286042751844174, 0.11526451616858442, 0.051913252705708145, 0.24685752764344215, 0.10483892812626436, 0.16968300845474005, 0.3807157297311018, 0.17432272775913588, 0.1376844910784822, 0.2350652819389806, 0.282458549624102, 0.19603361734189093, 0.21932490938343108, 0.01883414546318818, 0.17924246456823312, 0.12664334422775678, 0.19087497694417835, 0.024128734300445234, 0.13753608707338572, 0.1265628439346876, 0.18632518073233464, 0.03743745774651567, 0.2107977778747833, 0.0482713533565402, 0.05213085305083289, 0.19205795997404493, 0.40231478214263916, 0.07965418235010778, 0.9583368301391602, 0.1431616996292417, 0.18109900898450768, 0.24715410580392927]\n",
            "normalized_score: [0.9        0.25       0.5        0.33333333 0.6        0.6\n",
            " 0.2        0.77777778 0.6        0.6        0.6        0.4\n",
            " 0.4        0.77777778 0.6        0.75       0.75       0.5\n",
            " 1.         0.8        1.         0.75       0.4        0.33333333\n",
            " 1.         0.6        0.66666667 0.94444444 0.         0.6\n",
            " 0.6        0.4       ]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 10/375 [33:35<20:13:55, 199.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.50258267 0.50521976 0.502338   0.5000316  0.50691247 0.5029654\n",
            " 0.5032367  0.50228876 0.5049792  0.50149864 0.5021549  0.5019183\n",
            " 0.5035301  0.50275046 0.5006272  0.50180686 0.5019928  0.500003\n",
            " 0.50262684 0.49671793 0.5030164  0.50338876 0.50180334 0.500743\n",
            " 0.5012648  0.49785253 0.50232506 0.4999907  0.50302255 0.50129694\n",
            " 0.501369   0.5022761 ]\n",
            "out_coher: [0.22621417 0.29860282 0.18744975 0.22676903 0.22391924 0.24984568\n",
            " 0.22111808 0.50087774 0.48968387 0.49805441 0.23923326 0.33074117\n",
            " 0.49900487 0.2730146  0.28381655 0.49810374 0.18005016 0.50926477\n",
            " 0.22411987 0.45546332 0.33877295 0.48908523 0.2777849  0.27986854\n",
            " 0.49229378 0.49326536 0.22391014 0.23219594 0.2678133  0.4955852\n",
            " 0.49711448 0.3203557 ]\n",
            "out_prompt: [2.8949194e-03 2.9172949e-03 1.0685103e-03 3.5064816e-01 3.6450997e-01\n",
            " 3.8151407e-01 3.7278804e-01 1.5295533e-03 5.3815143e-03 3.4662017e-01\n",
            " 3.5154521e-01 3.6148456e-01 3.3369783e-01 1.6217668e-03 3.1059053e-02\n",
            " 3.6944300e-01 3.4957007e-01 3.5239878e-01 3.4889594e-01 1.0011402e-04\n",
            " 4.8407745e-03 3.6926547e-01 5.8522861e-04 3.7181881e-01 3.5931700e-01\n",
            " 1.2608874e-03 1.4662531e-03 8.1834763e-02 3.6187595e-01 1.0564261e-03\n",
            " 1.3740568e-02 3.4896496e-01]\n",
            "combined_score: [0.6491768956184387, 0.7607584595680237, 0.27996835112571716, 0.6220810413360596, 0.6206624507904053, 0.5896674990653992, 0.7419003248214722, 0.8497584462165833, 0.8081504106521606, 0.5305168032646179, 0.47003424167633057, 0.5168559551239014, 0.8179010152816772, 0.6375268697738647, 0.6184775233268738, 0.7779958248138428, 0.6413394808769226, 0.4943692684173584, 0.6975427269935608, 0.7709829211235046, 0.638365626335144, 0.8723188042640686, 0.46702665090560913, 0.2892330586910248, 0.8013210296630859, 0.691248893737793, 0.3673838675022125, 0.47366154193878174, 0.5463690161705017, 0.5534657835960388, 0.7360168695449829, 0.4009976387023926]\n",
            "coherence_score_nli: [0.04248748421669006, 0.22379163528482118, 0.04246842861175537, 0.17382606382016091, 0.07050390294753014, 0.201639916941834, 0.019893993018195034, 0.1596277991322697, 0.12435193879914899, 0.17902636341750622, 0.269216206989118, 0.023462142795324326, 0.09805458605804138, 0.0308806949906284, 0.13542767751496285, 0.17002461535028285, 0.01869659766089171, 0.06250686748119604, 0.06892447848804295, 0.1279700090755906, 0.10356207060006757, 0.09892081236466765, 0.03454858809709549, 0.0, 0.07405841946601868, 0.12354132435575593, 0.10435777474776842, 0.20105916834162438, 0.07682733684778213, 0.25739885252658967, 0.16004947808952155, 0.08561557531356812]\n",
            "normalized_score: [1.         1.         0.33333333 0.61111111 0.25       0.66666667\n",
            " 0.66666667 1.         0.6        0.4        0.6        0.66666667\n",
            " 1.         1.         0.6        0.75       0.66666667 0.25\n",
            " 0.83333333 0.6        0.66666667 0.75       0.25       0.33333333\n",
            " 1.         0.9        0.33333333 0.6        0.66666667 0.4\n",
            " 0.7        0.        ]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 11/375 [36:50<20:02:22, 198.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.5044783  0.50406003 0.5021276  0.5032503  0.5032067  0.5045532\n",
            " 0.5024672  0.50422364 0.5007823  0.5014801  0.50618327 0.5015655\n",
            " 0.50394136 0.4929577  0.5028419  0.4989763  0.5057106  0.5016847\n",
            " 0.50375545 0.50108564 0.5030851  0.5034282  0.5053034  0.50192845\n",
            " 0.49805796 0.50591594 0.50601774 0.50581855 0.50709426 0.5003737\n",
            " 0.50670385 0.503857  ]\n",
            "out_coher: [0.21958616 0.3176106  0.29812318 0.25589916 0.2659053  0.26223657\n",
            " 0.48166144 0.25789487 0.28317842 0.47214776 0.49742684 0.48366553\n",
            " 0.20818377 0.4932988  0.28228647 0.5156321  0.48427066 0.49968952\n",
            " 0.22334924 0.30369264 0.31492686 0.25922757 0.2429658  0.2408038\n",
            " 0.1969537  0.266142   0.51506287 0.3397854  0.49398825 0.25694475\n",
            " 0.48067427 0.26981813]\n",
            "out_prompt: [3.0401018e-03 2.9187459e-03 5.4208864e-02 4.7077560e-03 3.6060995e-01\n",
            " 3.5461074e-01 5.4482516e-04 9.3217718e-04 1.8947282e-04 1.6652431e-01\n",
            " 1.8986908e-04 3.6886823e-01 3.6406806e-01 1.8026156e-03 3.8052809e-01\n",
            " 1.8636215e-02 1.4899941e-03 7.8598270e-05 3.4109029e-01 3.5361627e-01\n",
            " 1.2261513e-02 2.7499273e-01 3.5769546e-01 1.9441916e-03 3.8491515e-03\n",
            " 3.3106074e-01 6.2146364e-03 3.5544696e-01 2.4565766e-03 3.5604626e-01\n",
            " 1.4120426e-04 2.6961559e-01]\n",
            "combined_score: [0.2702693045139313, 0.7591719627380371, 0.459805428981781, 0.3291196823120117, 0.26544618606567383, 0.5753358602523804, 0.8035280704498291, 0.6982775926589966, 0.7357351183891296, 0.7260767221450806, 0.8205687999725342, 0.7841170430183411, 0.6609325408935547, 0.5193396210670471, 0.45834875106811523, 0.6449494361877441, 0.6088050603866577, 0.437542200088501, 0.4352760910987854, 0.2037932574748993, 0.5540366768836975, 0.3384956121444702, 0.8059608340263367, 0.5595624446868896, 0.7681531310081482, 0.5718016028404236, 0.49204021692276, 0.32155895233154297, 0.39937958121299744, 0.35087859630584717, 0.6221261620521545, 0.5391641855239868]\n",
            "coherence_score_nli: [0.9582810401916504, 0.08848092504777014, 0.08433191571384668, 0.07582959920788805, 0.07541538091997306, 0.29918378591537476, 0.2448438743206983, 0.08448415071082611, 0.24843593914588186, 0.05279903198019243, 0.08508969470858574, 0.17524289842694998, 0.11643198553550367, 0.18648086972266006, 0.18421469402632543, 0.16190550028113648, 0.27233281717635693, 0.14158793874958064, 0.10108965029940009, 0.0, 0.005329808540409431, 0.17075944688570285, 0.12747828289866447, 0.31753311213105917, 0.10506589817149299, 0.027828585356473923, 0.23748017979475358, 0.13980260491371155, 0.17473972775042057, 0.016480990995963413, 0.2361628515413031, 0.2882077880203724]\n",
            "normalized_score: [0.33333333 1.         0.4        0.33333333 0.44444444 0.88888889\n",
            " 0.75       1.         0.6        0.66666667 1.         0.5\n",
            " 0.61111111 0.6        0.66666667 0.6        0.33333333 0.5\n",
            " 0.2        0.         0.33333333 0.2        0.75       0.66666667\n",
            " 1.         0.66666667 0.4        0.         0.5        0.61111111\n",
            " 0.6        0.4       ]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 12/375 [40:01<19:45:08, 195.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.5058807  0.5045242  0.500466   0.5064343  0.50408614 0.50410444\n",
            " 0.5026066  0.49989745 0.49747244 0.5026473  0.50272304 0.49985126\n",
            " 0.501221   0.5059108  0.50434214 0.5022532  0.5039096  0.49381608\n",
            " 0.50457644 0.50284433 0.5004862  0.5018046  0.5023606  0.50569487\n",
            " 0.5058801  0.5020712  0.50095844 0.5037749  0.50339234 0.5003043\n",
            " 0.502797   0.5047165 ]\n",
            "out_coher: [0.22602703 0.26982033 0.49127764 0.19358931 0.27572763 0.2699618\n",
            " 0.49725464 0.4959583  0.21987185 0.25771457 0.49714193 0.21443616\n",
            " 0.4887475  0.49975157 0.2836566  0.49845874 0.30137488 0.48713675\n",
            " 0.23688953 0.36578855 0.49296442 0.49865407 0.5049536  0.48630416\n",
            " 0.49169964 0.25069505 0.2029411  0.19006199 0.49672675 0.49695563\n",
            " 0.22900853 0.22444887]\n",
            "out_prompt: [3.5611421e-01 5.2963677e-03 3.7739107e-01 3.6987683e-01 3.6948088e-01\n",
            " 5.5566714e-03 1.2214885e-03 1.9508241e-03 2.6847634e-03 6.0600862e-02\n",
            " 3.6183128e-01 2.9695482e-04 3.6351237e-01 3.6629659e-01 3.6550751e-01\n",
            " 3.5681590e-01 1.1920547e-03 2.6074768e-04 1.4340183e-03 3.9091349e-01\n",
            " 4.6598396e-04 1.6585403e-03 3.5625225e-01 3.5705060e-01 3.5409856e-01\n",
            " 3.5132375e-03 2.8654523e-03 1.7187684e-03 3.6302477e-01 9.5407380e-04\n",
            " 3.4152833e-01 3.7105846e-01]\n",
            "combined_score: [0.5990283489227295, 0.29488277435302734, 0.7316844463348389, 0.4437330663204193, 0.05906011164188385, 0.5328922271728516, 0.5588374137878418, 0.6543450355529785, 0.6185254454612732, 0.6739740371704102, 0.703725278377533, 0.379193514585495, 0.8866506218910217, 0.5775564908981323, 0.7470408082008362, 0.5286350250244141, 0.6955267786979675, 0.7382887005805969, 0.45638421177864075, 0.10126805305480957, 0.8177247047424316, 0.5462707281112671, 0.528577983379364, 0.4655694365501404, 0.7272010445594788, 0.6552733778953552, 0.12212379276752472, 0.48592549562454224, 0.7489482164382935, 0.7324888110160828, 0.6581931114196777, 0.5497603416442871]\n",
            "coherence_score_nli: [0.30708372965455055, 0.3286588490009308, 0.13606389984488487, 0.07482244369263451, 0.0, 0.07106190058402717, 0.250964601803571, 0.049038629712803025, 0.02930949507281184, 0.12187972768237267, 0.11535462620668113, 0.037458328530192375, 0.0726728459703736, 0.02473381080199033, 0.11441861093044281, 0.1797126788749463, 0.14513040247506329, 0.20486586665113768, 0.17575761396437883, 0.0, 0.21299810953099618, 0.11063951067626476, 0.19760423845478467, 0.15979762190383756, 0.17016739817336202, 0.1608083342667669, 0.06443065591156483, 0.29609283059835434, 0.10381105176306196, 0.1656852657924901, 0.09367528268194292, 0.3726736009120941]\n",
            "normalized_score: [0.4        0.         0.75       0.5        0.         0.5\n",
            " 0.5        0.75       0.66666667 0.6        0.75       0.25\n",
            " 0.75       0.75       1.         0.4        0.75       0.8\n",
            " 0.5        0.33333333 1.         0.66666667 0.2        0.25\n",
            " 0.75       0.66666667 0.         0.33333333 0.75       0.9\n",
            " 0.         0.4       ]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 13/375 [43:12<19:33:42, 194.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.50180846 0.499012   0.5005315  0.5031914  0.50564617 0.5091898\n",
            " 0.50489926 0.50324744 0.50019187 0.50623554 0.5000247  0.5077564\n",
            " 0.50276506 0.50163954 0.5025069  0.5030624  0.503891   0.50417596\n",
            " 0.50369436 0.50348514 0.5026028  0.50517386 0.501477   0.5083819\n",
            " 0.50093305 0.49976826 0.5038923  0.5023505  0.50490844 0.5033444\n",
            " 0.50489676 0.50203466]\n",
            "out_coher: [0.50416887 0.4965349  0.24985665 0.47612375 0.17923214 0.49608552\n",
            " 0.2599534  0.49572963 0.50318617 0.2100008  0.23282997 0.5004165\n",
            " 0.4993193  0.4955771  0.2778042  0.4934933  0.49081755 0.32540667\n",
            " 0.25752756 0.26296192 0.49202222 0.25056705 0.2580356  0.26817292\n",
            " 0.4935459  0.20278078 0.2816224  0.21188195 0.49016643 0.29084015\n",
            " 0.4942006  0.5157762 ]\n",
            "out_prompt: [1.6563419e-02 3.6173677e-01 3.9311070e-03 3.5685551e-01 2.6084015e-03\n",
            " 1.2539944e-04 1.7745914e-03 5.1677241e-03 3.6749497e-01 3.4029958e-01\n",
            " 3.8026899e-01 3.7875500e-01 2.7751553e-01 1.6701877e-02 3.6570325e-01\n",
            " 3.3760768e-01 3.7427011e-01 4.5555364e-03 5.7129968e-02 9.5425925e-04\n",
            " 5.4582809e-03 3.6067462e-01 3.6391446e-01 1.9276286e-02 3.2182306e-01\n",
            " 2.6903367e-01 3.9298174e-01 3.6173195e-01 4.1125619e-01 3.7427402e-01\n",
            " 3.9267904e-01 3.7873426e-01]\n",
            "combined_score: [0.7357462644577026, 0.7034503817558289, 0.7605372667312622, 0.35514381527900696, 0.7260079383850098, 0.7658450603485107, 0.3157603144645691, 0.5270907282829285, 0.6945196390151978, 0.43859803676605225, 0.46302399039268494, 0.7274290323257446, 0.5998664498329163, 0.5670360922813416, 0.4694223701953888, 0.5901885032653809, 0.6735295653343201, 0.6513692736625671, 0.2210197150707245, 0.33389776945114136, 0.5004615783691406, 0.5126230716705322, 0.5528063774108887, 0.539210319519043, 0.5601896643638611, 0.6013389825820923, 0.48652878403663635, 0.6567050218582153, 0.3253999352455139, 0.1784534901380539, 0.6968050003051758, 0.5606898069381714]\n",
            "coherence_score_nli: [0.0660667100455612, 0.192124714575974, 0.028592101046039414, 0.23397860820405186, 0.025214325170964003, 0.13131583580573977, 0.0, 0.11480197412893176, 0.014291834202595055, 0.1612314786761999, 0.007816100493073463, 0.09508914706141998, 0.16692230899241708, 0.11843627770140301, 0.028046017255595263, 0.1479530099662952, 0.008492945414036512, 0.20904735517170694, 0.005763837601989508, 0.0, 0.43820160379012424, 0.23521851158390442, 0.1470210949992179, 0.17533569905208424, 0.06616853303178989, 0.17686368428191848, 0.1081717309425585, 0.06727002518406759, 0.14115237519145013, 0.06305935978889465, 0.19355405527832253, 0.0011805090859221916]\n",
            "normalized_score: [0.75       0.75       1.         0.4        0.66666667 0.8\n",
            " 0.33333333 0.75       0.75       0.4        0.         0.75\n",
            " 0.6        0.5        0.66666667 0.4        0.5        1.\n",
            " 0.25       0.33333333 0.33333333 0.5        0.2        0.6\n",
            " 0.5        0.6        0.4        0.6        0.33333333 0.33333333\n",
            " 0.75       0.25      ]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▎         | 14/375 [46:20<19:17:20, 192.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.50829375 0.50604576 0.5030597  0.5067113  0.50365055 0.5022154\n",
            " 0.5017775  0.5010622  0.5029102  0.5025347  0.50364    0.5006757\n",
            " 0.5049438  0.50247586 0.5000267  0.50283587 0.5032957  0.50099593\n",
            " 0.5010402  0.5023413  0.5028098  0.5024447  0.50223297 0.48764026\n",
            " 0.5031956  0.5017667  0.5026088  0.49895725 0.5058145  0.50540197\n",
            " 0.49867624 0.5038331 ]\n",
            "out_coher: [0.4904998  0.355604   0.49710315 0.2178143  0.2599214  0.5018909\n",
            " 0.29421744 0.5022805  0.4883902  0.23976834 0.4954819  0.25944015\n",
            " 0.19485848 0.48338616 0.23028019 0.4705422  0.29243213 0.2523409\n",
            " 0.2655893  0.2164173  0.48079905 0.49111202 0.4892823  0.5051634\n",
            " 0.49151155 0.27462578 0.23850489 0.27063793 0.18854041 0.3221288\n",
            " 0.5146522  0.4786297 ]\n",
            "out_prompt: [5.3296058e-04 1.1435242e-01 3.6683488e-01 1.0453286e-02 3.7093970e-01\n",
            " 2.2216540e-04 4.4901641e-03 3.5295856e-01 9.6891570e-04 3.3548307e-01\n",
            " 3.3452582e-01 2.6456648e-03 4.6116137e-03 4.7493340e-03 3.6157441e-01\n",
            " 6.1623671e-04 3.4885651e-01 3.7799382e-01 3.7733737e-01 4.9849418e-03\n",
            " 4.1279042e-04 5.0025649e-04 2.3890004e-01 2.6522347e-04 7.9455395e-04\n",
            " 3.7447202e-01 3.8830924e-01 3.0435860e-01 1.0780879e-01 3.8620964e-01\n",
            " 3.6645430e-01 2.8786892e-01]\n",
            "combined_score: [0.6019883751869202, 0.5080392360687256, 0.7678664922714233, 0.5571668744087219, 0.6219106316566467, 0.7900248169898987, 0.444976806640625, 0.4331797957420349, 0.7864487171173096, 0.5062466859817505, 0.6355396509170532, 0.37469762563705444, 0.5308305621147156, 0.7841981053352356, 0.6257082223892212, 0.6225073337554932, 0.6515563726425171, 0.5938853621482849, 0.5370374321937561, 0.533402681350708, 0.6080138683319092, 0.6168588399887085, 0.6244171857833862, 0.5060904026031494, 0.5319416522979736, 0.565020740032196, 0.5675449371337891, 0.8617926239967346, 0.6729099750518799, 0.20606034994125366, 0.7450602650642395, 0.5800864696502686]\n",
            "coherence_score_nli: [0.05382444150745869, 0.22197866067290306, 0.12796007357537748, 0.0, 0.04944613063707948, 0.20745160841298374, 0.1585241618255774, 0.060378014420469604, 0.21230971269930402, 0.2560615713397662, 0.07239415206842953, 0.1667539986471335, 0.19181090220808983, 0.23820515031761982, 0.3015887310818168, 0.1833484265635806, 0.11966177050701597, 0.19507234543561935, 0.17427910827100276, 0.14573440662781267, 0.21730170386413541, 0.22853828708036378, 0.25292609525578363, 0.19805292386669093, 0.2608300160791259, 0.06045930335919062, 0.20344783707211414, 0.020542051309894303, 0.14890828071576026, 0.0, 0.07525926678707558, 0.27353862843786675]\n",
            "normalized_score: [0.75       0.4        0.5        0.33333333 0.66666667 0.8\n",
            " 0.33333333 0.66666667 1.         0.33333333 0.72222222 0.33333333\n",
            " 0.33333333 0.8        0.72222222 0.4        0.88888889 0.33333333\n",
            " 0.66666667 0.2        0.4        0.6        0.5        0.6\n",
            " 0.4        0.66666667 0.33333333 0.83333333 0.5        0.25\n",
            " 0.75       0.5       ]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 15/375 [49:33<19:15:18, 192.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.5063936  0.5019981  0.50554556 0.5036537  0.50332236 0.5022053\n",
            " 0.5017217  0.50011885 0.5045343  0.50418144 0.5031655  0.5033021\n",
            " 0.5029082  0.5026891  0.50174063 0.5038907  0.50556695 0.50512344\n",
            " 0.5024897  0.5034367  0.50273204 0.49903283 0.5026353  0.5036661\n",
            " 0.50447965 0.5073133  0.5035828  0.50095373 0.5059788  0.5028765\n",
            " 0.50385237 0.49889714]\n",
            "out_coher: [0.49407804 0.31187618 0.49422094 0.48689666 0.21818903 0.23291865\n",
            " 0.22860976 0.3044328  0.4914709  0.21723437 0.22264089 0.30096298\n",
            " 0.5121983  0.3426042  0.22311893 0.22286594 0.48754117 0.20387904\n",
            " 0.25414267 0.3349728  0.49658373 0.3325213  0.4997056  0.24568944\n",
            " 0.49735498 0.5032826  0.29491094 0.24091311 0.50773424 0.4923475\n",
            " 0.25375682 0.23532876]\n",
            "out_prompt: [2.3222029e-04 5.3333357e-04 3.2783241e-03 8.3310843e-02 8.4520597e-04\n",
            " 2.3696512e-04 9.0668537e-04 5.1216024e-04 2.4244425e-04 3.4580150e-01\n",
            " 8.1305165e-04 3.9048907e-01 8.5421040e-04 1.6185587e-04 1.3413114e-03\n",
            " 3.2805112e-01 1.5096922e-04 3.6232233e-01 3.4591720e-01 3.7249425e-01\n",
            " 3.4257650e-01 4.3319771e-03 7.5587147e-04 7.3547370e-04 3.7271208e-01\n",
            " 1.1554789e-02 3.7708968e-01 3.2087830e-01 2.5101801e-04 3.7541729e-01\n",
            " 2.5989997e-01 1.1972517e-05]\n",
            "combined_score: [0.6554273366928101, 0.6703683733940125, 0.5327941179275513, 0.52557373046875, 0.33638596534729004, 0.7015936374664307, 0.2549820840358734, 0.5720352530479431, 0.6777958869934082, 0.5450667142868042, 0.528611421585083, 0.6634054183959961, 0.6605132818222046, 0.44418710470199585, 0.78242027759552, 0.4765740633010864, 0.6070801019668579, 0.2778490483760834, 0.3585547208786011, 0.21002240478992462, 0.3741617202758789, 0.5795192122459412, 0.7711189985275269, 0.2280479371547699, 0.6806029081344604, 0.5554304122924805, 0.31334400177001953, 0.49021536111831665, 0.5155017971992493, 0.6327858567237854, 0.8422510623931885, 0.6809126734733582]\n",
            "coherence_score_nli: [0.19326396343832905, 0.14647894042233625, 0.16192971444171336, 0.2971851587450753, 0.13418657278331617, 0.04424888011999428, 0.0, 0.18547135069966317, 0.452593067322265, 0.13105189823545516, 0.19947115564718843, 0.04746428680502706, 0.07090390578377992, 0.2107398919761181, 0.07393842751237874, 0.14599448777735233, 0.06354193657817733, 0.033408649265766144, 0.0, 0.07452007755637169, 0.09923809883184731, 0.21154693109718592, 0.21477364575611832, 0.05640394985675812, 0.08985510461830667, 0.1401760958135128, 0.006459096446633339, 0.1775718768913066, 0.07677973830141127, 0.102822195738554, 0.07772896071599628, 0.17622400161165458]\n",
            "normalized_score: [0.8        0.66666667 0.6        0.5        0.33333333 1.\n",
            " 0.25       0.25       0.5        0.4        0.33333333 0.77777778\n",
            " 0.75       0.5        0.33333333 0.3        0.5        0.\n",
            " 0.25       0.33333333 0.25       0.6        0.7        0.25\n",
            " 0.75       0.6        0.33333333 0.4        0.5        0.5\n",
            " 0.77777778 0.8       ]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 16/375 [52:56<19:31:52, 195.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.49929425 0.49918333 0.50299317 0.5014509  0.5058923  0.5007369\n",
            " 0.50005645 0.50442857 0.49833283 0.501417   0.5021144  0.5005854\n",
            " 0.5040647  0.503189   0.5046176  0.51177186 0.50148225 0.506306\n",
            " 0.5070398  0.5040992  0.50485224 0.5040805  0.5069239  0.5017709\n",
            " 0.5035082  0.49991608 0.5015258  0.5024203  0.5033041  0.5015035\n",
            " 0.5022328  0.506745  ]\n",
            "out_coher: [0.50983816 0.48787713 0.2044588  0.5161592  0.503963   0.28885266\n",
            " 0.252746   0.29085758 0.49374133 0.19945358 0.48347932 0.2679416\n",
            " 0.5013239  0.2523216  0.48402688 0.49419457 0.3014932  0.47812012\n",
            " 0.26428545 0.3201935  0.48623398 0.292549   0.5190707  0.50678486\n",
            " 0.2937894  0.29155228 0.49252674 0.49878564 0.48513263 0.19195549\n",
            " 0.23912919 0.2647128 ]\n",
            "out_prompt: [3.7334713e-01 9.5797731e-03 3.7383407e-01 3.8111585e-04 3.8014424e-01\n",
            " 3.6505577e-01 2.0529267e-03 3.5720173e-01 5.0535781e-04 3.8689855e-01\n",
            " 4.0650548e-04 2.1869589e-03 2.0656599e-04 9.4569701e-04 5.6252200e-02\n",
            " 1.8410693e-04 2.8403425e-03 4.9941032e-04 3.6291698e-01 8.1769394e-04\n",
            " 1.3982340e-04 3.4609735e-01 8.6952180e-02 2.6417384e-01 3.5623056e-01\n",
            " 4.6538487e-03 1.3446486e-02 3.4573326e-01 3.5048109e-01 3.7157318e-01\n",
            " 3.3928323e-01 3.7161091e-01]\n",
            "combined_score: [0.29137641191482544, 0.6934001445770264, 0.2987757921218872, 0.554672360420227, 0.5619383454322815, 0.4046481251716614, 0.57917320728302, 0.49125367403030396, 0.6873925924301147, 0.7439152002334595, 0.721008837223053, 0.8021773099899292, 0.6602442860603333, 0.46641653776168823, 0.7486293911933899, 0.7818458676338196, 0.5027201771736145, 0.6966613531112671, 0.5439648032188416, 0.22446192800998688, 0.5314493179321289, 0.5652505159378052, 0.5318134427070618, 0.6048328280448914, 0.40080687403678894, 0.19943714141845703, 0.6564719080924988, 0.776165783405304, 0.5368861556053162, 0.32611462473869324, 0.7521675825119019, 0.5780442357063293]\n",
            "coherence_score_nli: [0.05332911185299357, 0.08385983369841526, 0.06073638051748276, 0.23688531541265548, 0.20288796598712602, 0.009265728411264718, 0.46244116127491, 0.14459432987496257, 0.280180084393578, 0.17210049847407, 0.12916471542143193, 0.09240709409849453, 0.19071417428656584, 0.09624833834823221, 0.1719598510923485, 0.1607032448535652, 0.27621260929542285, 0.2999098428990692, 0.17573332600295544, 0.40027639269828796, 0.12619061845665178, 0.14330047395612514, 0.19075839576850595, 0.14349212583329063, 0.05741309653967619, 0.15965203940868378, 0.19686775097701079, 0.31891844514757395, 0.29047063663601874, 0.20141415856778622, 0.06598373338864702, 0.0905641932040453]\n",
            "normalized_score: [0.2        0.8        0.         0.5        0.5        0.33333333\n",
            " 0.66666667 0.77777778 0.8        0.83333333 0.8        1.\n",
            " 0.75       0.33333333 0.7        0.9        0.33333333 1.\n",
            " 0.6        0.         0.5        0.4        0.6        0.6\n",
            " 0.33333333 0.66666667 0.8        0.5        0.33333333 0.\n",
            " 0.72222222 0.75      ]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▍         | 17/375 [56:08<19:21:50, 194.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.5015369  0.5042827  0.5036714  0.5040723  0.5029252  0.50261956\n",
            " 0.50560945 0.50068533 0.50177777 0.502756   0.5039239  0.5005096\n",
            " 0.50223756 0.5045953  0.5011911  0.5027377  0.5015124  0.50394726\n",
            " 0.5040824  0.50207675 0.5025862  0.50350726 0.50333303 0.5015231\n",
            " 0.5047618  0.5058656  0.50226617 0.5020219  0.50370723 0.5003616\n",
            " 0.5057421  0.5001287 ]\n",
            "out_coher: [0.24282649 0.24712521 0.2715522  0.2560396  0.29770175 0.49716833\n",
            " 0.48871583 0.28713435 0.46009406 0.4790941  0.2355041  0.28678554\n",
            " 0.5084246  0.5035665  0.2833904  0.23118967 0.32561687 0.2700177\n",
            " 0.24820311 0.4923442  0.49822947 0.25031263 0.49462298 0.2378438\n",
            " 0.48947936 0.30226576 0.48753852 0.236993   0.22555825 0.4980526\n",
            " 0.3273291  0.2466299 ]\n",
            "out_prompt: [1.2300136e-01 3.5112959e-01 3.3442491e-01 1.0474370e-03 1.9857509e-03\n",
            " 2.8556149e-04 7.4106567e-02 3.8181928e-01 9.2771319e-05 1.0122266e-01\n",
            " 2.1664198e-02 3.6730278e-01 3.9567956e-01 3.5967591e-01 3.5829616e-01\n",
            " 3.6443520e-01 3.6737818e-01 5.8890029e-04 2.3597314e-03 7.1723729e-02\n",
            " 3.6990070e-01 3.7348190e-01 3.4531823e-01 1.2586544e-03 7.4182510e-02\n",
            " 3.4893391e-04 7.0670288e-04 4.9373200e-03 3.6523414e-01 3.6066651e-01\n",
            " 1.3644116e-02 3.8541809e-01]\n",
            "combined_score: [0.4225706160068512, 0.6434832811355591, 0.7430014610290527, 0.5676823258399963, 0.8482478857040405, 0.7432931065559387, 0.5026007294654846, 0.5764046907424927, 0.8780391216278076, 0.4766349196434021, 0.5717310905456543, 0.6182883977890015, 0.6656323671340942, 0.4078945517539978, 0.21159982681274414, 0.7423179149627686, 0.4888591170310974, 0.7754595279693604, 0.4918171763420105, 0.6720228791236877, 0.45642322301864624, 0.7223201394081116, 0.46647152304649353, 0.7119339108467102, 0.5115145444869995, 0.7214924693107605, 0.6824474930763245, 0.5440819263458252, 0.6137177348136902, 0.35161730647087097, 0.657774806022644, 0.5809454917907715]\n",
            "coherence_score_nli: [0.15719479293777391, 0.36088990047574043, 0.18113360876062265, 0.019793804734945297, 0.29344247803092005, 0.23896502695667246, 0.1078326105925953, 0.30294921435415745, 0.11048743440287895, 0.3438903867499903, 0.06790181123797083, 0.224061352511247, 0.11567306495271623, 0.320016723126173, 0.0, 0.09200203514192254, 0.09181562873224418, 0.16126824027014663, 0.054287251085042953, 0.2964360447866576, 0.07494584596133791, 0.1015196005270506, 0.3574161392947038, 0.020945008285343646, 0.20545424208311097, 0.08962764096213505, 0.050325203886521716, 0.029806408216245472, 0.11686956072743568, 0.6463966766993204, 0.14393482130253688, 0.07878639657671253]\n",
            "normalized_score: [0.4        0.25       0.88888889 0.5        0.66666667 0.7\n",
            " 0.6        0.66666667 1.         0.4        0.4        1.\n",
            " 0.66666667 0.         0.         1.         0.66666667 0.75\n",
            " 0.5        0.8        0.5        0.75       0.4        0.66666667\n",
            " 0.4        0.7        0.75       0.33333333 0.66666667 0.27777778\n",
            " 1.         0.33333333]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▍         | 18/375 [59:14<19:02:44, 192.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.5010613  0.5063695  0.5010437  0.50361836 0.50214857 0.5047692\n",
            " 0.5033168  0.50642353 0.50389695 0.5067124  0.50165945 0.5087229\n",
            " 0.50130546 0.5027792  0.49762547 0.5045017  0.50343084 0.50401294\n",
            " 0.5029317  0.50075287 0.50411236 0.5050257  0.5037534  0.5015433\n",
            " 0.5067598  0.5053708  0.5047306  0.4985409  0.5053367  0.50079036\n",
            " 0.5040097  0.5027255 ]\n",
            "out_coher: [0.5003565  0.18214925 0.5071582  0.510842   0.21151686 0.2136145\n",
            " 0.28449368 0.2631962  0.29709497 0.24403873 0.29285344 0.5004888\n",
            " 0.5154223  0.21126147 0.48751828 0.25471017 0.25817704 0.30955723\n",
            " 0.21531928 0.24426968 0.22099216 0.28121674 0.3474404  0.5036003\n",
            " 0.31874603 0.47753298 0.50227463 0.28904104 0.4905006  0.49874318\n",
            " 0.29231733 0.49498045]\n",
            "out_prompt: [3.70167464e-01 2.91817385e-04 3.52634698e-01 3.59345973e-01\n",
            " 2.44264095e-03 3.71807516e-01 1.81624200e-02 1.03832655e-01\n",
            " 1.82598387e-03 3.90813351e-01 2.01916378e-02 1.13124924e-03\n",
            " 8.56009200e-02 1.19808035e-04 1.04520448e-04 3.56353074e-01\n",
            " 3.76123548e-01 1.83954672e-03 3.61943662e-01 3.71653885e-01\n",
            " 1.96354254e-03 3.83981615e-01 3.66582572e-01 3.94824982e-01\n",
            " 5.59054781e-03 3.60070914e-01 1.25164224e-03 2.01209169e-03\n",
            " 3.80027354e-01 3.73134226e-01 3.81785333e-01 3.66717935e-01]\n",
            "combined_score: [0.7846276760101318, 0.7557176947593689, 0.4820292592048645, 0.7645053267478943, 0.34979087114334106, 0.6045259237289429, 0.724164605140686, 0.663796603679657, 0.1396290361881256, 0.5307807922363281, 0.577135443687439, 0.7415583729743958, 0.40853363275527954, 0.3560168743133545, 0.6703140139579773, 0.3168465793132782, 0.6232888698577881, 0.7248553037643433, 0.4748823344707489, 0.6813852787017822, 0.5768071413040161, 0.6296103596687317, 0.8048115372657776, 0.6263540387153625, 0.7713737487792969, 0.6005763411521912, 0.5077231526374817, 0.445973664522171, 0.2072465419769287, 0.7399068474769592, 0.756874144077301, 0.83043372631073]\n",
            "coherence_score_nli: [0.0915648876171973, 0.09778557448104645, 0.19572662162993634, 0.07661802177400594, 0.3434224526087443, 0.008889054879546165, 0.16893020171361664, 0.12073245955010255, 0.05393262207508087, 0.021472690626978874, 0.1222723055165261, 0.08445287612266839, 0.1523864035339405, 0.38943259914716083, 0.15371624052885077, 0.39625438824296, 0.03772006129535536, 0.12351566534489393, 0.21416879321138063, 0.05353153784138461, 0.09083780832588673, 0.1901128612080356, 0.07301633324599467, 0.07516801262972876, 0.03174745062798528, 0.0413639333888164, 0.018320550210773945, 0.0, 0.2718104999512434, 0.06293811928480864, 0.05529526928294217, 0.191305617051613]\n",
            "normalized_score: [1.         1.         0.83333333 0.5        0.66666667 0.66666667\n",
            " 0.7        0.83333333 0.33333333 0.33333333 0.6        1.\n",
            " 0.4        0.25       0.6        0.33333333 0.66666667 0.66666667\n",
            " 0.         0.25       0.66666667 0.61111111 0.66666667 0.77777778\n",
            " 0.66666667 1.         0.5        0.33333333 0.11111111 0.75\n",
            " 0.         1.        ]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 19/375 [1:02:27<19:00:40, 192.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.5021966  0.50337446 0.49977943 0.50437206 0.50172156 0.5048877\n",
            " 0.50393045 0.51105845 0.5019751  0.50071156 0.5045664  0.50487155\n",
            " 0.5025986  0.5046627  0.50475276 0.5025901  0.5021697  0.5000102\n",
            " 0.5056624  0.5015065  0.5018215  0.5050165  0.50500757 0.5039015\n",
            " 0.5037521  0.50264734 0.5041356  0.50226015 0.5064127  0.5013151\n",
            " 0.5036005  0.5031135 ]\n",
            "out_coher: [0.26661536 0.4867895  0.48976737 0.49267715 0.21908626 0.25634316\n",
            " 0.30677256 0.4697142  0.49601033 0.22404619 0.23658085 0.49389946\n",
            " 0.19444904 0.25425625 0.25978988 0.25914872 0.32880503 0.24241152\n",
            " 0.5058063  0.25856003 0.2749936  0.2691346  0.25860676 0.50237775\n",
            " 0.23311844 0.25633666 0.23467928 0.4789012  0.2315746  0.2146298\n",
            " 0.49751145 0.49723092]\n",
            "out_prompt: [3.51139337e-01 3.77476931e-01 1.97546557e-01 3.20112765e-01\n",
            " 3.78985733e-01 2.38146214e-03 3.56038570e-01 3.44593078e-04\n",
            " 6.21853746e-04 1.51830202e-03 3.73121083e-01 1.14830680e-01\n",
            " 3.65323722e-01 1.54327616e-04 1.99585140e-01 1.53737530e-01\n",
            " 3.66036206e-01 3.33108101e-03 1.61147863e-02 3.54654193e-01\n",
            " 1.67004741e-03 3.79170418e-01 3.91872078e-01 1.30925566e-01\n",
            " 3.49987835e-01 3.66547465e-01 3.59788060e-01 3.46558243e-01\n",
            " 3.62078905e-01 9.38985310e-03 1.76936667e-02 1.23421505e-01]\n",
            "combined_score: [0.46523797512054443, 0.6751823425292969, 0.6310153603553772, 0.43902337551116943, 0.04856029152870178, 0.6566659212112427, 0.24077162146568298, 0.8160494565963745, 0.6226683855056763, 0.7435815334320068, 0.665702760219574, 0.8139894604682922, 0.4214376211166382, 0.610401451587677, 0.5199578404426575, 0.43391990661621094, 0.6985054016113281, 0.5892823338508606, 0.6054850220680237, 0.4847111403942108, 0.36074361205101013, 0.6833139657974243, 0.6850576996803284, 0.6471801996231079, 0.6357403993606567, 0.4375683069229126, 0.6288489103317261, 0.5661640167236328, 0.7458898425102234, 0.5017796754837036, 0.6344744563102722, 0.6380705833435059]\n",
            "coherence_score_nli: [0.2027537017905464, 0.24301052875816823, 0.16274715160868844, 0.16549820164218546, 0.0, 0.07868303365207144, 0.0061779203824698925, 0.17259786473894362, 0.08441971933934837, 0.04461014777835873, 0.3574381177313626, 0.03514242091256639, 0.0008668004884384573, 0.314431595033966, 0.21237425826903847, 0.3276324135561784, 0.05606300927077731, 0.028921980665472802, 0.2088155053369701, 0.2548461535945535, 0.24684437178075314, 0.04134105430178655, 0.005592662375420332, 0.24857182434708294, 0.0416666170116514, 0.26324883911625613, 0.15938353250385262, 0.17215925469492122, 0.11559897395116943, 0.0, 0.09837673637957778, 0.22235509864740857]\n",
            "normalized_score: [0.5        1.         0.4        0.4        0.         1.\n",
            " 0.25       0.8        0.75       1.         0.4        1.\n",
            " 0.33333333 0.5        0.4        0.4        0.66666667 0.66666667\n",
            " 0.7        0.66666667 0.5        0.83333333 0.66666667 0.6\n",
            " 0.75       0.4        0.5        0.77777778 0.75       0.5\n",
            " 0.6        0.6       ]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 20/375 [1:05:34<18:47:52, 190.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.49788982 0.5007817  0.50068957 0.50234514 0.50596076 0.5042434\n",
            " 0.5045278  0.503044   0.5016294  0.5040087  0.50234026 0.5049634\n",
            " 0.5017206  0.5035144  0.5012329  0.51165825 0.50735736 0.5073615\n",
            " 0.4995986  0.5036622  0.50071454 0.50275934 0.504786   0.50192785\n",
            " 0.5049615  0.5016003  0.50449044 0.50226206 0.4990802  0.50483567\n",
            " 0.5052626  0.5020049 ]\n",
            "out_coher: [0.22189248 0.4856402  0.23921917 0.48557955 0.47922918 0.5008269\n",
            " 0.28655928 0.48028648 0.4931983  0.47063023 0.23708671 0.5031022\n",
            " 0.5044988  0.29511198 0.23507188 0.5129557  0.23115124 0.49634367\n",
            " 0.48016185 0.51036614 0.5096562  0.25404453 0.5169251  0.2598504\n",
            " 0.16199455 0.2311194  0.5079929  0.48813707 0.26007348 0.29183832\n",
            " 0.24024671 0.2560723 ]\n",
            "out_prompt: [3.8937941e-01 2.7810148e-04 3.6691996e-01 3.6430657e-01 1.1290356e-01\n",
            " 4.4927295e-02 3.7520489e-01 3.6770064e-01 3.6014131e-01 6.8584521e-04\n",
            " 3.7861714e-01 3.5757846e-01 5.0283042e-03 3.9228759e-04 3.6453208e-01\n",
            " 9.4844145e-05 7.1104232e-04 3.5158062e-01 3.7398472e-01 3.4251797e-01\n",
            " 3.5247353e-01 4.1118293e-04 1.7429831e-02 3.5858914e-01 3.5034910e-01\n",
            " 3.7861100e-01 9.7359404e-02 3.7659255e-01 2.4979417e-01 5.0361105e-04\n",
            " 3.8431704e-01 3.7715665e-01]\n",
            "combined_score: [0.2734948694705963, 0.541422963142395, 0.6551902294158936, 0.7770155072212219, 0.7631760239601135, 0.8313611149787903, 0.35657304525375366, 0.6168456673622131, 0.4714481830596924, 0.7886375188827515, 0.5585808753967285, 0.40748536586761475, 0.8044223785400391, 0.5730974674224854, 0.27162131667137146, 0.8025325536727905, 0.6353890895843506, 0.5758746266365051, 0.7461804151535034, 0.11655498296022415, 0.5325711369514465, 0.6849738955497742, 0.666981041431427, 0.7206802368164062, 0.5672984719276428, 0.5032257437705994, 0.46074438095092773, 0.5711555480957031, 0.6263926029205322, 0.5281193256378174, 0.5520042777061462, 0.6025189757347107]\n",
            "coherence_score_nli: [0.06121882330626249, 0.23022882582154125, 0.17041792823001742, 0.08083359621066068, 0.21378754652840526, 0.1341452865634069, 0.4678609839756973, 0.1297059950302355, 0.14500607977000377, 0.12570416345261037, 0.09569816128350794, 0.33995941653847694, 0.11188439519451897, 0.033096631756052375, 0.024026893079280853, 0.22278329978753636, 0.06274155496309201, 0.4003546792747719, 0.09058375740423799, 0.18592517790966667, 0.19076792793348432, 0.16962475081284842, 0.20349239655770363, 0.12310715219549213, 0.08421991889675458, 0.0339003074914217, 0.16917143832357728, 0.052493024132369705, 0.14873831515756641, 0.1477272268384695, 0.1625697761774063, 0.06546101938667041]\n",
            "normalized_score: [0.         0.25       0.77777778 0.75       0.7        0.9\n",
            " 0.33333333 0.66666667 0.4        0.5        0.25       0.33333333\n",
            " 0.6        0.33333333 0.33333333 0.8        0.5        0.66666667\n",
            " 0.75       0.         0.4        0.66666667 0.6        0.77777778\n",
            " 0.25       0.77777778 0.6        0.5        0.4        0.66666667\n",
            " 0.66666667 0.66666667]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 21/375 [1:08:58<19:08:09, 194.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.50098836 0.5024248  0.502895   0.497704   0.50426334 0.5032356\n",
            " 0.5027512  0.50475305 0.4998608  0.50493    0.49991393 0.50047773\n",
            " 0.5033576  0.5024517  0.5031811  0.50497556 0.5030247  0.504132\n",
            " 0.50830513 0.50112474 0.5027008  0.5049577  0.5040089  0.504473\n",
            " 0.50493497 0.50470656 0.50309795 0.50140196 0.5012773  0.50692374\n",
            " 0.503107   0.5003958 ]\n",
            "out_coher: [0.25729123 0.24637184 0.22334601 0.49087805 0.22073501 0.50099146\n",
            " 0.24464116 0.51574606 0.23822637 0.48537815 0.27199107 0.2437412\n",
            " 0.4914011  0.4895266  0.48967943 0.26282504 0.25745934 0.501947\n",
            " 0.49214122 0.23077616 0.1969533  0.29881194 0.31885442 0.22781989\n",
            " 0.25613394 0.23791474 0.48928264 0.29026616 0.2724033  0.5048684\n",
            " 0.48449856 0.2921381 ]\n",
            "out_prompt: [7.8249234e-04 1.8331838e-03 3.6914653e-01 3.7995511e-01 2.2336047e-03\n",
            " 1.4012853e-04 3.8014311e-01 4.6447286e-04 2.7366498e-01 3.0340324e-04\n",
            " 7.9908170e-04 3.8961676e-01 4.0470758e-03 3.5583746e-01 1.1174738e-03\n",
            " 1.5176133e-03 3.3458646e-03 3.6845961e-01 3.6955732e-01 3.0421600e-04\n",
            " 1.3575597e-03 5.8751862e-04 1.4531091e-03 3.7499267e-01 3.6169198e-01\n",
            " 3.8414562e-01 1.8917873e-03 9.5723051e-04 3.6711177e-01 3.5392806e-01\n",
            " 3.8144225e-01 2.8085888e-03]\n",
            "combined_score: [0.46079590916633606, 0.1192653477191925, 0.5652140974998474, 0.6548240184783936, 0.4697139263153076, 0.767327606678009, 0.540898859500885, 0.7182782292366028, 0.7766048908233643, 0.7499373555183411, 0.4532610774040222, 0.5158871412277222, 0.600048303604126, 0.7339226007461548, 0.6663793921470642, 0.7514249086380005, 0.7887094616889954, 0.6308324337005615, 0.8392964601516724, 0.4471355080604553, 0.7021552324295044, 0.5722079277038574, 0.4777582585811615, 0.666585385799408, 0.8101037740707397, 0.6583364009857178, 0.7403582334518433, 0.7404834032058716, 0.5143917202949524, 0.41146624088287354, 0.809883177280426, 0.8205016851425171]\n",
            "coherence_score_nli: [0.18867383431643248, 0.40172094106674194, 0.6003727912902832, 0.06684073515740845, 0.19909127047285438, 0.07915438269264996, 0.1157859687693417, 0.11953167555232842, 0.13679426193185565, 0.16998433869697951, 0.133335642516613, 0.0, 0.27727778363359074, 0.04041368122367809, 0.31172568863257766, 0.06751716838599267, 0.04929110439843498, 0.16574342641979456, 0.09628672821616585, 0.350111852089564, 0.16215460188686848, 0.0393882361240685, 0.12879741999010244, 0.23771977424621582, 0.12596273887902498, 0.2187870701142986, 0.14178641566315725, 0.10067496001720429, 0.11259472474921495, 0.04717289904753367, 0.07874178767881611, 0.14055122762587607]\n",
            "normalized_score: [0.66666667 0.         0.75       1.         0.25       1.\n",
            " 1.         1.         0.8        0.8        0.33333333 0.2\n",
            " 0.6        0.5        0.8        1.         1.         0.66666667\n",
            " 1.         0.25       0.66666667 0.33333333 0.33333333 0.72222222\n",
            " 1.         0.75       0.6        0.25       0.4        0.\n",
            " 1.         1.        ]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 22/375 [1:12:13<19:06:49, 194.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.5038755  0.5022137  0.50575864 0.501677   0.5021843  0.5049349\n",
            " 0.49590254 0.50445914 0.5020949  0.5009735  0.503467   0.50545275\n",
            " 0.5030255  0.5053604  0.5027192  0.5020637  0.5009661  0.5035765\n",
            " 0.5017378  0.50145227 0.50086415 0.5023841  0.5036611  0.504826\n",
            " 0.5024744  0.50030744 0.50516456 0.50563264 0.5016553  0.50414574\n",
            " 0.50184333 0.5048761 ]\n",
            "out_coher: [0.49207506 0.50718796 0.51048696 0.21586187 0.21799287 0.25251204\n",
            " 0.29911304 0.23285554 0.2335872  0.28612548 0.26293766 0.49885517\n",
            " 0.4874971  0.31717736 0.49994582 0.2831932  0.48645568 0.48281246\n",
            " 0.4879299  0.25427204 0.5090946  0.48425165 0.50366217 0.21097812\n",
            " 0.49357423 0.4991696  0.47716928 0.2255474  0.490653   0.48532838\n",
            " 0.51555634 0.24779424]\n",
            "out_prompt: [3.6283875e-01 3.6038259e-01 3.6502606e-01 3.7098476e-01 3.8767341e-01\n",
            " 3.7557873e-01 1.1360272e-03 3.5843855e-01 9.3832304e-04 1.6178915e-02\n",
            " 8.7676637e-02 3.7244767e-01 8.4552637e-05 3.6176038e-01 3.9049423e-01\n",
            " 3.6942410e-01 3.7694541e-01 3.6991343e-01 3.4170938e-01 1.0511045e-01\n",
            " 3.6732417e-01 8.8180689e-04 3.6214200e-01 3.9626813e-01 1.8027352e-02\n",
            " 3.6468378e-01 3.4560588e-01 3.2897612e-01 2.5579091e-02 1.3707976e-01\n",
            " 3.6779761e-01 3.5646677e-01]\n",
            "combined_score: [0.6486721038818359, 0.7752499580383301, 0.732600748538971, 0.06077892333269119, 0.44240981340408325, 0.6327647566795349, 0.7829508185386658, 0.6080912351608276, 0.6778131723403931, 0.5914161205291748, 0.7240848541259766, 0.5996749997138977, 0.713186502456665, 0.6954188942909241, 0.5829461812973022, 0.6274959444999695, 0.7116122245788574, 0.6033446788787842, 0.46809086203575134, 0.5241764187812805, 0.7604020833969116, 0.7512127161026001, 0.7801951169967651, 0.34756869077682495, 0.862481951713562, 0.65718674659729, 0.7241707444190979, 0.5816385746002197, 0.5700466632843018, 0.7297835350036621, 0.8590585589408875, 0.6185956001281738]\n",
            "coherence_score_nli: [0.1283679629365603, 0.13152392164597082, 0.1022101016715169, 0.1428038626909256, 0.0, 0.04469495337818646, 0.26283939233871934, 0.08819139810899894, 0.14238325553014874, 0.2080799280152218, 0.17195034379449983, 0.24954368341166308, 0.24095682132368287, 0.07822504331124946, 0.12315349156657855, 0.20829803224478383, 0.147447606921196, 0.16528737199093615, 0.012882286061843237, 0.19771685684099793, 0.09635489899665117, 0.04682192269247025, 0.07361348047673416, 0.08004341274499893, 0.20852293791540433, 0.06201311506863151, 0.1814124829194043, 0.19142997375733795, 0.10332387713715434, 0.2468702624945973, 0.17321985860222153, 0.15682435096241534]\n",
            "normalized_score: [0.5        0.75       0.75       0.         0.         0.83333333\n",
            " 0.8        0.66666667 1.         0.7        0.7        0.4\n",
            " 0.75       0.75       0.4        0.66666667 1.         1.\n",
            " 0.5        0.6        1.         0.75       0.88888889 0.27777778\n",
            " 0.7        0.75       0.7        0.6        0.75       0.6\n",
            " 1.         0.72222222]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 23/375 [1:15:23<18:55:14, 193.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.5058989  0.50218743 0.5013875  0.5026874  0.5046248  0.49988565\n",
            " 0.50474113 0.5002123  0.50280523 0.5031738  0.50301176 0.4930554\n",
            " 0.5053673  0.50249064 0.5035447  0.50270426 0.49921376 0.5033841\n",
            " 0.4993849  0.50322694 0.5040305  0.50421    0.5030089  0.50079507\n",
            " 0.5021172  0.50200677 0.5040353  0.50293016 0.50609815 0.5012473\n",
            " 0.5059715  0.5025814 ]\n",
            "out_coher: [0.5035321  0.50788504 0.19524264 0.48966628 0.4825272  0.4929479\n",
            " 0.49532032 0.4811818  0.25801212 0.27625525 0.5034558  0.46663594\n",
            " 0.48707283 0.49137795 0.5133412  0.19787073 0.49747714 0.26599255\n",
            " 0.29795513 0.28112188 0.22147605 0.22158265 0.24541964 0.51039636\n",
            " 0.5046177  0.5109407  0.27713987 0.50432676 0.5095418  0.25410143\n",
            " 0.33635858 0.2576868 ]\n",
            "out_prompt: [3.9753271e-03 2.8180424e-03 5.6351312e-03 6.7374550e-02 3.4314361e-01\n",
            " 3.6303708e-01 1.6419885e-03 1.8255336e-03 3.6994657e-01 3.8787657e-01\n",
            " 3.6636063e-01 3.2251398e-04 2.3336828e-02 4.0543830e-01 3.6244228e-01\n",
            " 3.9369482e-01 1.7101357e-02 2.6859690e-03 3.4717134e-01 1.4522149e-01\n",
            " 8.0573617e-04 3.2507079e-03 3.6226642e-01 3.6990517e-01 3.7360147e-01\n",
            " 4.5856051e-02 3.5462251e-01 3.5648426e-01 2.8532273e-01 3.3029705e-01\n",
            " 3.7528440e-01 4.1021495e-03]\n",
            "combined_score: [0.8187888264656067, 0.5352950692176819, 0.7602410912513733, 0.48969951272010803, 0.6182841658592224, 0.7441556453704834, 0.6970763802528381, 0.4858053922653198, 0.7550232410430908, 0.4430120587348938, 0.586467444896698, 0.6650829315185547, 0.6738479137420654, 0.4752904772758484, 0.4375874400138855, 0.6440971493721008, 0.6863030195236206, 0.8034502863883972, 0.4733060896396637, 0.6135636568069458, 0.5228527188301086, 0.48071759939193726, 0.3971865773200989, 0.7406440377235413, 0.7055827975273132, 0.6103099584579468, 0.5102491974830627, 0.09379132091999054, 0.705318808555603, 0.4093923568725586, 0.42906373739242554, 0.5041356682777405]\n",
            "coherence_score_nli: [0.027491572379533733, 0.20331137932537655, 0.027627259865403174, 0.2277841871837154, 0.22596715659730965, 0.032443047811587654, 0.10863361434478845, 0.13719479007542962, 0.07918887661459545, 0.22704686286548773, 0.20400908775627613, 0.23537515764914904, 0.1603834884069664, 0.1490545098980268, 0.22563063763082028, 0.212890716874972, 0.1977794803255661, 0.13611865153403155, 0.012791822664439678, 0.11568196341977455, 0.23800885019591078, 0.14405257999897003, 0.08099382929503918, 0.02798466479871422, 0.17080472940579056, 0.21880409261824466, 0.03662547065565983, 0.18008861877024174, 0.11785169600625522, 0.04723978911836942, 0.19914551405236125, 0.2612925859866664]\n",
            "normalized_score: [0.75       0.6        1.         0.4        0.4        0.75\n",
            " 1.         0.33333333 0.77777778 0.77777778 0.66666667 0.6\n",
            " 0.8        0.77777778 0.33333333 0.66666667 0.6        1.\n",
            " 0.66666667 0.4        0.5        0.33333333 0.61111111 0.75\n",
            " 1.         0.6        0.33333333 0.2        0.5        0.33333333\n",
            " 0.2        0.33333333]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▋         | 24/375 [1:18:33<18:45:54, 192.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.5014045  0.50249964 0.50364786 0.50503606 0.49758422 0.5009368\n",
            " 0.50423485 0.50395983 0.5025797  0.5037915  0.50228935 0.5037629\n",
            " 0.50441396 0.5016442  0.5047535  0.50314647 0.50292975 0.49983448\n",
            " 0.5027352  0.5046232  0.5023671  0.5038838  0.5044613  0.5060565\n",
            " 0.49934664 0.50415003 0.50081825 0.5005197  0.50125897 0.5022041\n",
            " 0.50124055 0.50288564]\n",
            "out_coher: [0.49882713 0.4893551  0.24436697 0.20299414 0.47432134 0.49739933\n",
            " 0.49219966 0.23316747 0.24113466 0.5097162  0.276207   0.29761288\n",
            " 0.28972277 0.21761605 0.2403904  0.30730775 0.26632714 0.20718478\n",
            " 0.4930733  0.24835576 0.32461017 0.48716268 0.48308757 0.48050973\n",
            " 0.49188483 0.2556685  0.4975891  0.5013767  0.20405366 0.51675624\n",
            " 0.48514718 0.5104392 ]\n",
            "out_prompt: [3.91609967e-01 2.60550017e-03 3.61826092e-01 1.11906428e-03\n",
            " 2.10060226e-03 2.28041332e-04 3.58721405e-01 3.60557497e-01\n",
            " 1.33160537e-03 3.88921857e-01 3.75652283e-01 9.41053673e-04\n",
            " 9.43778362e-03 2.98738736e-03 3.48123044e-01 3.59421939e-01\n",
            " 1.80555001e-01 1.02828036e-03 1.06540763e-04 3.39752525e-01\n",
            " 1.20842867e-01 1.24571305e-02 3.63234371e-01 1.80060118e-01\n",
            " 3.70331764e-01 3.25179875e-01 6.01620879e-04 1.09798359e-02\n",
            " 3.72462839e-01 3.68351340e-01 1.50771847e-03 3.63010496e-01]\n",
            "combined_score: [0.6267907619476318, 0.6786893606185913, 0.6613810062408447, 0.7456272840499878, 0.5134806036949158, 0.5012249946594238, 0.6927791237831116, 0.6539521217346191, 0.46993550658226013, 0.6070212125778198, 0.6210696697235107, 0.46544355154037476, 0.31950557231903076, 0.5990286469459534, 0.2676399052143097, 0.43991658091545105, 0.6602300405502319, 0.403654009103775, 0.24110960960388184, 0.35110485553741455, 0.9259140491485596, 0.5172882080078125, 0.6418625116348267, 0.6521189212799072, 0.6524222493171692, 0.4817802608013153, 0.5530412793159485, 0.5116509795188904, 0.6591538786888123, 0.6257308721542358, 0.6817291975021362, 0.7028013467788696]\n",
            "coherence_score_nli: [0.16081427425766984, 0.11059961712453514, 0.101958406327123, 0.06468951313290745, 0.10610568406072592, 0.15426757665617125, 0.16711174871306866, 0.21665015692512193, 0.18757282942533493, 0.23360092826187612, 0.11585083790123463, 0.11190006230026484, 0.39476834679953754, 0.03156727117796739, 0.35124891996383667, 0.10397003905382007, 0.22994403923965162, 0.04707694333046675, 0.20530700962990522, 0.03838310856372118, 0.04885856464272365, 0.16392914950847626, 0.09518110234057531, 0.1767373054579366, 0.15633790619904175, 0.06184441555524245, 0.057316051330417395, 0.06952433786581322, 0.018183940866341192, 0.06539085507392883, 0.011845025466755033, 0.15184863736586912]\n",
            "normalized_score: [0.75       1.         0.77777778 1.         0.6        0.5\n",
            " 0.75       1.         0.66666667 0.6        0.25       0.66666667\n",
            " 0.         0.66666667 0.27777778 0.         0.6        0.25\n",
            " 0.25       0.25       0.77777778 0.25       0.75       0.6\n",
            " 0.5        0.4        0.5        0.6        0.5        0.5\n",
            " 0.75       0.75      ]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 25/375 [1:21:36<18:24:52, 189.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.5022333  0.5051001  0.50584596 0.49994147 0.50209445 0.5042052\n",
            " 0.5029627  0.49188468 0.5016565  0.50341874 0.50251186 0.5044161\n",
            " 0.506109   0.50263417 0.50515985 0.5032081  0.5026416  0.5040986\n",
            " 0.50534374 0.50280374 0.5029026  0.5028321  0.5043789  0.5052613\n",
            " 0.49938375 0.5043316  0.49999684 0.4991414  0.49680558 0.5051258\n",
            " 0.50532955 0.5007408 ]\n",
            "out_coher: [0.26638368 0.2568239  0.21690957 0.502578   0.30106798 0.18827851\n",
            " 0.2941165  0.4731554  0.4974646  0.23366484 0.22033353 0.50225013\n",
            " 0.50130355 0.33750895 0.2798113  0.49600726 0.4877475  0.2339511\n",
            " 0.5074992  0.49413398 0.2389697  0.49185959 0.49409986 0.5033213\n",
            " 0.23189808 0.26459935 0.21697061 0.20312175 0.22306326 0.49395525\n",
            " 0.4832811  0.49221087]\n",
            "out_prompt: [3.5629129e-01 1.5778684e-03 3.2028368e-01 3.7917992e-04 3.5144210e-01\n",
            " 1.1662923e-03 3.6565128e-01 1.6058992e-04 3.6714381e-01 2.0897207e-03\n",
            " 3.8391039e-01 5.6648288e-02 3.7394828e-01 3.5056326e-01 3.8385636e-01\n",
            " 3.9940584e-01 3.9093566e-01 3.7668616e-01 3.8413486e-01 5.6651118e-03\n",
            " 4.4059069e-03 2.7726966e-04 3.6717314e-01 2.1485862e-04 3.6618069e-01\n",
            " 2.8658325e-03 3.5782799e-01 3.4234804e-01 3.9643031e-01 3.9434853e-01\n",
            " 3.8159594e-01 3.4631070e-01]\n",
            "combined_score: [0.6265338659286499, 0.7849592566490173, 0.7114511728286743, 0.6878861784934998, 0.6346904039382935, 0.47294989228248596, 0.4716216027736664, 0.7246957421302795, 0.4026971161365509, 0.5472951531410217, 0.7629875540733337, 0.7255816459655762, 0.3667892515659332, 0.2760474979877472, 0.27080023288726807, 0.49663078784942627, 0.5141358971595764, 0.5309851169586182, 0.6844434142112732, 0.5543889999389648, 0.2819540202617645, 0.6881207227706909, 0.6520357728004456, 0.6629347801208496, 0.3349688947200775, 0.5746861696243286, 0.6708353161811829, 0.194060280919075, 0.39711934328079224, 0.6673245429992676, 0.608953058719635, 0.5640367269515991]\n",
            "coherence_score_nli: [0.02828277531079948, 0.16399193488177843, 0.21162720722629905, 0.178822825592237, 0.15973672834225, 0.01929066702723503, 0.25119150223003495, 0.15161882891617198, 0.1758726364509626, 0.9304630160331726, 0.035715566109865905, 0.1638428993478772, 0.07255798857659101, 0.30209880173206327, 0.05165584827773273, 0.28097007870674134, 0.1433070545705656, 0.03775161551311612, 0.04805657956749201, 0.19458981553606433, 0.42131656408309937, 0.04407185888183968, 0.10027361055836082, 0.036371241440065205, 0.0, 0.19685116037726402, 0.04212293348973617, 0.03134674532338977, 0.0014329304685816169, 0.21775007089599968, 0.05140103991808636, 0.14285283181099936]\n",
            "normalized_score: [0.5        1.         0.6        0.9        0.33333333 0.5\n",
            " 0.6        0.6        0.6        0.66666667 0.5        0.7\n",
            " 0.33333333 0.2        0.2        0.66666667 0.66666667 0.66666667\n",
            " 0.75       0.6        0.25       0.5        0.75       0.75\n",
            " 0.         0.66666667 0.33333333 0.33333333 0.         0.66666667\n",
            " 1.         0.4       ]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 26/375 [1:24:58<18:44:05, 193.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.5022605  0.5060153  0.50377584 0.50274897 0.5036847  0.5010822\n",
            " 0.5026792  0.5051304  0.50348884 0.5044244  0.5019787  0.503799\n",
            " 0.503336   0.50346917 0.50585914 0.50389755 0.5042199  0.5046971\n",
            " 0.50295675 0.5017685  0.4993338  0.49948496 0.5021139  0.505108\n",
            " 0.50227815 0.49913302 0.50324744 0.5009176  0.50521135 0.506182\n",
            " 0.50257367 0.5009516 ]\n",
            "out_coher: [0.50385314 0.48534817 0.49097118 0.24236092 0.22623275 0.26565883\n",
            " 0.34002736 0.50253457 0.2356325  0.26673913 0.27361462 0.25087547\n",
            " 0.20796059 0.50958955 0.2215306  0.49286723 0.49866402 0.5154972\n",
            " 0.24438797 0.5064444  0.48653722 0.26996404 0.50093687 0.2778219\n",
            " 0.24797082 0.4983692  0.26826167 0.18191813 0.23514263 0.49589315\n",
            " 0.22487478 0.49620783]\n",
            "out_prompt: [0.3069251  0.09431928 0.02252548 0.00053598 0.37698105 0.3643977\n",
            " 0.36892158 0.35251182 0.37014094 0.37785992 0.3533547  0.36148345\n",
            " 0.3905121  0.37006402 0.21005414 0.00048225 0.04578428 0.00205576\n",
            " 0.38358945 0.24344471 0.00886427 0.38870925 0.10868289 0.29990748\n",
            " 0.37165892 0.00091992 0.3734277  0.3732742  0.13298441 0.11716466\n",
            " 0.35249358 0.2212068 ]\n",
            "combined_score: [0.575819730758667, 0.8105926513671875, 0.7488937377929688, 0.748444676399231, 0.5955218076705933, 0.7829346656799316, 0.5897746086120605, 0.8298177123069763, 0.5385795831680298, 0.42807847261428833, 0.47283387184143066, 0.328685462474823, 0.5306335091590881, 0.8456273078918457, 0.4688397943973541, 0.6247515678405762, 0.6770403385162354, 0.5453701019287109, 0.3248210549354553, 0.5183322429656982, 0.7085769176483154, 0.5698091387748718, 0.6090158820152283, 0.544110894203186, 0.46177858114242554, 0.5826441645622253, 0.7211575508117676, 0.6799510717391968, 0.5839440226554871, 0.625363826751709, 0.6364298462867737, 0.6481092572212219]\n",
            "coherence_score_nli: [0.0809364772738061, 0.13831863628279062, 0.17773687691777013, 0.09524608944775537, 0.31542594521306455, 0.11526865071871063, 0.05792677216231823, 0.18442622951697557, 0.14734598947688937, 0.0158092575147748, 0.1414357942994684, 0.14367827773094177, 0.3213818669319153, 0.055348668654914945, 0.18503395123407246, 0.05129810480866581, 0.22601965065890303, 0.24351309874327853, 0.009260616265237331, 0.262776188342832, 0.18826209979098557, 0.23300798157624042, 0.23056874343786726, 0.20367747834226227, 0.29672043439414764, 0.2608456338206545, 0.09684276426144477, 0.18467157080092214, 0.18963004543620626, 0.09303191772196442, 0.6279267072677612, 0.1120683397472787]\n",
            "normalized_score: [0.6        0.8        0.6        0.75       0.61111111 0.6\n",
            " 0.66666667 1.         0.55555556 0.33333333 0.         0.\n",
            " 0.38888889 1.         0.6        0.66666667 0.6        0.5\n",
            " 0.         0.4        0.7        0.6        0.4        0.6\n",
            " 0.4        0.8        0.38888889 0.7        0.6        0.8\n",
            " 0.55555556 0.7       ]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 27/375 [1:28:23<19:01:21, 196.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.5029799  0.5008951  0.5004028  0.5034254  0.5019708  0.50404376\n",
            " 0.5042142  0.5018428  0.50703806 0.50483143 0.50039524 0.50055224\n",
            " 0.50383306 0.5072963  0.50359756 0.50688654 0.5060814  0.50482285\n",
            " 0.50196964 0.49899513 0.50556034 0.50063866 0.5021313  0.50384206\n",
            " 0.50514555 0.4961144  0.50215256 0.5026863  0.5082749  0.5031103\n",
            " 0.5078617  0.50141245]\n",
            "out_coher: [0.49034944 0.4896984  0.4922007  0.21171339 0.31332886 0.48729986\n",
            " 0.49452734 0.48692232 0.47618195 0.2194721  0.2971199  0.29654613\n",
            " 0.49189362 0.49137026 0.50225353 0.49967113 0.32761234 0.2500313\n",
            " 0.20000637 0.22991869 0.21266544 0.25136384 0.48206922 0.50097287\n",
            " 0.19803272 0.4677927  0.4989109  0.5065964  0.5176238  0.46874815\n",
            " 0.50991935 0.5041255 ]\n",
            "out_prompt: [2.4610346e-02 2.9575065e-04 5.0846180e-03 8.5741159e-04 1.6231022e-03\n",
            " 1.0308057e-02 1.1134092e-02 3.6655888e-01 3.5390884e-01 3.4990239e-01\n",
            " 3.7163535e-01 3.8009408e-01 3.5186866e-01 3.4669319e-01 1.2171025e-03\n",
            " 3.5981527e-01 3.7171236e-01 3.2791453e-03 2.6586256e-03 4.9247347e-02\n",
            " 3.8154575e-01 4.0243682e-01 1.0151995e-03 3.7984332e-01 3.7662366e-01\n",
            " 1.7146930e-03 1.5335742e-01 3.7937962e-02 4.1798100e-02 3.5938638e-01\n",
            " 3.6273646e-01 3.8859412e-01]\n",
            "combined_score: [0.6277384161949158, 0.8051455020904541, 0.45814773440361023, 0.760362446308136, 0.7903273105621338, 0.5940427780151367, 0.7542152404785156, 0.8178166747093201, 0.46181076765060425, 0.7733492851257324, 0.5098061561584473, 0.5207163095474243, 0.6843085289001465, 0.692267656326294, 0.8277565240859985, 0.6713473796844482, 0.49866414070129395, 0.4490169286727905, 0.2674590051174164, 0.45565569400787354, 0.44510963559150696, 0.3671064078807831, 0.7155075669288635, 0.7555139064788818, 0.7332658767700195, 0.7849351763725281, 0.6371977925300598, 0.7162676453590393, 0.8274969458580017, 0.7890794277191162, 0.6803178191184998, 0.8126301765441895]\n",
            "coherence_score_nli: [0.0762719586957246, 0.2143994259902022, 0.09438688540831208, 0.20344952782179462, 0.022644452711877722, 0.15374160474831505, 0.17876474523255903, 0.1483688864391297, 0.18641486477905087, 0.12252379802521318, 0.17855590550849834, 0.24715252074279956, 0.04085352458059788, 0.1763247950002551, 0.1342298310353524, 0.14444508036831394, 0.16305414501888058, 0.04303643406213572, 0.0, 0.10229073464870453, 0.10193795978557318, 0.0, 0.11468956416669804, 0.08998111257096753, 0.10084678336150116, 0.18168193739521402, 0.23273032913915814, 0.1412695807191388, 0.18814485470647924, 0.1271843625211411, 0.15471952706575393, 0.1735849440906589]\n",
            "normalized_score: [0.75       1.         0.5        1.         1.         0.5\n",
            " 0.8        1.         0.6        0.94444444 0.6        0.6\n",
            " 0.25       0.75       1.         0.5        0.25       0.5\n",
            " 0.33333333 0.25       0.33333333 0.38888889 1.         0.75\n",
            " 0.66666667 0.8        0.7        0.9        0.9        1.\n",
            " 0.5        0.8       ]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 28/375 [1:31:58<19:29:31, 202.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.50384015 0.5007822  0.50678116 0.50200427 0.5043936  0.506788\n",
            " 0.5010384  0.49821505 0.5077432  0.50192946 0.50330323 0.5021748\n",
            " 0.49962428 0.5040414  0.5025998  0.5038471  0.50170815 0.5040411\n",
            " 0.5045268  0.5003838  0.5033924  0.5061855  0.5108456  0.5020939\n",
            " 0.50288063 0.5024276  0.50139475 0.50352466 0.49956456 0.50270534\n",
            " 0.5037007  0.50383765]\n",
            "out_coher: [0.17800906 0.2834837  0.21820858 0.2818753  0.49742565 0.51152647\n",
            " 0.25428814 0.28496978 0.5185627  0.4979504  0.5045516  0.48849607\n",
            " 0.21020249 0.2449876  0.18687123 0.4956578  0.4836207  0.4920776\n",
            " 0.21973953 0.26454023 0.48719913 0.475994   0.50434476 0.4948667\n",
            " 0.3084153  0.28824034 0.23860258 0.49350315 0.4867662  0.28700554\n",
            " 0.27304104 0.5135756 ]\n",
            "out_prompt: [3.5033658e-01 1.4170659e-03 3.7666979e-01 9.6551445e-04 5.0729315e-04\n",
            " 4.2526435e-02 3.8104281e-01 3.7741476e-01 8.9306606e-04 1.4326315e-04\n",
            " 2.7914131e-02 3.5928133e-01 5.0879043e-04 1.6944023e-02 1.3602911e-03\n",
            " 3.5961443e-01 2.9433126e-04 1.1997963e-04 3.0470644e-03 3.5926694e-01\n",
            " 3.9121139e-01 9.5949136e-04 1.2352047e-02 6.8215368e-04 3.6665155e-03\n",
            " 3.8661811e-01 3.5006151e-01 1.2806448e-04 8.7764391e-05 3.6424151e-01\n",
            " 3.6965203e-01 9.5302472e-03]\n",
            "combined_score: [0.5507650375366211, 0.6397708058357239, 0.789787769317627, 0.6827762722969055, 0.6646053791046143, 0.6487952470779419, 0.7741742730140686, 0.7571859359741211, 0.6521556377410889, 0.7518017888069153, 0.6219297647476196, 0.7109601497650146, 0.406674325466156, 0.641872763633728, 0.593717634677887, 0.5888915061950684, 0.48906928300857544, 0.6309422850608826, 0.5969582796096802, 0.3549403250217438, 0.6232386231422424, 0.5794541239738464, 0.7620752453804016, 0.608978271484375, 0.6350218057632446, 0.8322572708129883, 0.6520075798034668, 0.8094139695167542, 0.6579406261444092, 0.7115839123725891, 0.6009816527366638, 0.6093397736549377]\n",
            "coherence_score_nli: [0.11784376415889711, 0.14077512241367782, 0.1498224877868779, 0.1230860979296267, 0.21177095045956473, 0.2181035883491859, 0.09739165681613875, 0.07584057956202221, 0.348863285167941, 0.20153053290365885, 0.08829927947815686, 0.13034695163369178, 0.01750505343079567, 0.11556695512540284, 0.081484854221344, 0.18165167211554945, 0.2572815085295588, 0.16336720105541377, 0.23001613091522208, 0.0, 0.08500371139962226, 0.1697203855562423, 0.17402489649612107, 0.1816755727379738, 0.38249722123146057, 0.04274415158267532, 0.1780034786905162, 0.06538454815745354, 0.09691091486352629, 0.12545788629601398, 0.13222019345266744, 0.14917910449905322]\n",
            "normalized_score: [0.         0.66666667 0.75       0.66666667 0.6        0.8\n",
            " 0.75       0.66666667 0.75       0.8        0.6        1.\n",
            " 0.66666667 0.7        0.33333333 0.4        0.5        0.9\n",
            " 0.66666667 0.2        0.66666667 0.5        0.7        0.6\n",
            " 0.66666667 1.         0.66666667 1.         0.8        0.83333333\n",
            " 0.66666667 0.6       ]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 29/375 [1:35:18<19:22:18, 201.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.5053224  0.49552172 0.5030713  0.5010986  0.5076731  0.5044379\n",
            " 0.5011804  0.50515145 0.500204   0.50114524 0.5025707  0.50141287\n",
            " 0.50634766 0.5003293  0.50331163 0.50532544 0.50364953 0.5039402\n",
            " 0.5024997  0.507032   0.50541395 0.50002193 0.5010103  0.502322\n",
            " 0.49834988 0.5010579  0.50166196 0.5015231  0.50416666 0.4992353\n",
            " 0.503457   0.50544   ]\n",
            "out_coher: [0.52417725 0.45817515 0.4951561  0.50588155 0.23117542 0.25153503\n",
            " 0.21576348 0.2818396  0.4880345  0.1882119  0.21160835 0.362921\n",
            " 0.48852277 0.50708103 0.2876585  0.52127737 0.49194565 0.5011318\n",
            " 0.20549044 0.5116725  0.4890633  0.29736093 0.26643836 0.49426767\n",
            " 0.5003954  0.26654884 0.50026935 0.5103642  0.5156141  0.5000658\n",
            " 0.2802826  0.4920575 ]\n",
            "out_prompt: [3.7685817e-01 8.1863807e-04 2.4809060e-01 3.5076037e-01 2.5630922e-03\n",
            " 3.8060132e-01 3.8084811e-01 3.5366172e-01 3.8279900e-01 3.3737117e-01\n",
            " 3.4859961e-01 1.8532287e-03 1.5110059e-01 3.3485913e-01 9.5081534e-03\n",
            " 4.0722728e-01 3.7726745e-01 3.2650629e-01 3.9436042e-01 2.2626978e-01\n",
            " 3.7596920e-01 6.9606380e-04 3.8615304e-01 3.5234764e-01 1.4302090e-03\n",
            " 1.5322365e-04 5.0700329e-02 3.4218094e-01 3.7115389e-01 6.8695989e-04\n",
            " 3.9694265e-01 3.5879400e-03]\n",
            "combined_score: [0.6566740870475769, 0.6362274289131165, 0.6351665258407593, 0.7650381326675415, 0.567886233329773, 0.4974760413169861, 0.7471880316734314, 0.6515570878982544, 0.6746700406074524, 0.6117433309555054, 0.45851993560791016, 0.7791411280632019, 0.6568864583969116, 0.6603927612304688, 0.36360791325569153, 0.3845328092575073, 0.640572190284729, 0.47425898909568787, 0.47094830870628357, 0.4706766903400421, 0.6262548565864563, 0.6205494999885559, 0.5430485010147095, 0.8243428468704224, 0.395565927028656, 0.48822861909866333, 0.6168124675750732, 0.5946128368377686, 0.5661447644233704, 0.7285033464431763, 0.6119512319564819, 0.5266987681388855]\n",
            "coherence_score_nli: [0.09425757643683548, 0.16112297624707794, 0.21586492657661438, 0.07023979898076504, 0.06907761127998431, 0.19176680140662938, 0.2149971217440907, 0.060379277964654775, 0.09971354440785944, 0.10940227527171373, 0.17032460638632377, 0.18932376039447263, 0.300043567915314, 0.08689216007769573, 0.13913205886880556, 0.6649268642067909, 0.094927927612194, 0.09883197388262488, 0.2792976275086403, 0.23261783703377373, 0.2160381999833939, 0.1436272129746309, 0.004317714095426102, 0.09280248140831562, 0.30278311800211666, 0.07588758692145348, 0.05100273846862061, 0.09544669402142365, 0.038815377124895654, 0.17886574869044125, 0.1233600890263915, 0.028186026960611343]\n",
            "normalized_score: [0.66666667 0.8        0.         0.8        0.66666667 0.5\n",
            " 0.25       0.72222222 0.75       0.6        0.6        0.66666667\n",
            " 0.8        0.6        0.5        0.4        1.         0.6\n",
            " 0.33333333 0.4        0.66666667 0.66666667 0.66666667 0.75\n",
            " 0.25       0.33333333 0.7        1.         0.5        0.8\n",
            " 0.66666667 0.5       ]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 30/375 [1:38:30<19:02:50, 198.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.5039781  0.5036723  0.50558895 0.49986425 0.5034545  0.50147516\n",
            " 0.5034588  0.5004367  0.5056315  0.50552464 0.50202537 0.50474226\n",
            " 0.5045134  0.5037374  0.50294685 0.5059867  0.5036397  0.5019913\n",
            " 0.50291884 0.505299   0.500306   0.5012378  0.49865538 0.50213635\n",
            " 0.49735638 0.5019653  0.50337607 0.5003822  0.50257117 0.50473994\n",
            " 0.5012065  0.50166196]\n",
            "out_coher: [0.48575747 0.28101236 0.22452241 0.2013095  0.2677858  0.22302282\n",
            " 0.5090885  0.5106892  0.22661379 0.27425283 0.49527463 0.5074915\n",
            " 0.20416237 0.50145614 0.17781025 0.16611922 0.25751358 0.27639365\n",
            " 0.1982527  0.4872976  0.49198395 0.49694696 0.29739428 0.2279957\n",
            " 0.26484573 0.28648803 0.2452449  0.50092536 0.24390443 0.18364617\n",
            " 0.2396835  0.48269302]\n",
            "out_prompt: [6.1800971e-04 3.6338887e-01 3.6852401e-01 4.5349519e-03 3.5709089e-01\n",
            " 3.7442183e-01 3.0519912e-01 1.4169615e-02 5.5590790e-04 3.6742777e-01\n",
            " 6.7356392e-03 3.7015024e-01 3.4504658e-01 3.9074329e-01 6.0996809e-03\n",
            " 3.1040376e-01 2.2928047e-03 2.6644100e-03 3.6695287e-01 2.0262664e-02\n",
            " 3.7068102e-01 2.8482947e-01 1.9097263e-04 3.7807435e-01 3.6761570e-01\n",
            " 3.6546332e-01 3.7209460e-01 3.7985530e-01 2.6563914e-03 5.6931279e-03\n",
            " 3.9437828e-03 3.6725372e-01]\n",
            "combined_score: [0.7208391427993774, 0.33987441658973694, 0.32094448804855347, 0.4777999520301819, 0.6176176071166992, 0.6056564450263977, 0.5532591342926025, 0.6554533839225769, 0.5878420472145081, 0.45845919847488403, 0.6657028794288635, 0.8475526571273804, 0.2776489555835724, 0.5094378590583801, 0.3635295331478119, 0.6464326977729797, 0.44445016980171204, 0.4775180220603943, 0.5324294567108154, 0.6796214580535889, 0.5881465077400208, 0.580158531665802, 0.7562441229820251, 0.31685730814933777, 0.5912836790084839, 0.3608236014842987, 0.8136144876480103, 0.5751835107803345, 0.6332481503486633, 0.4529731273651123, 0.5139116644859314, 0.46284469962120056]\n",
            "coherence_score_nli: [0.16666697131262886, 0.05800406634807587, 0.06182289868593216, 0.2379302109281222, 0.21388000001509985, 0.9323949217796326, 0.1544239329639822, 0.22425941648042022, 0.03753924393095076, 0.05036522075533867, 0.21960277565813158, 0.18840129367890768, 0.6921152472496033, 0.12806297341982523, 0.010770434979349375, 0.13335104066775078, 0.023502510972321033, 0.016720468488832314, 0.17514825006051418, 0.14059372810671839, 0.07530932473018766, 0.16475736486932469, 0.1499977894297733, 0.03373781684786081, 0.164196774762656, 0.5876161456108093, 0.12615603516460397, 0.042252974957227706, 0.12271149102598429, 0.1083370879253683, 0.38875519286375493, 0.03841028842143714]\n",
            "normalized_score: [1.         0.2        0.33333333 0.33333333 0.66666667 0.5\n",
            " 0.6        0.7        0.66666667 0.33333333 0.7        1.\n",
            " 0.         0.5        0.33333333 0.6        0.33333333 0.33333333\n",
            " 0.6        0.6        0.25       0.6        0.55555556 0.\n",
            " 1.         0.5        0.88888889 0.66666667 0.66666667 0.66666667\n",
            " 0.66666667 0.5       ]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 31/375 [1:41:42<18:48:43, 196.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes before creating DataFrame:\n",
            "out_semantic: [0.5039272  0.5017827  0.5054774  0.5029224  0.50277764 0.50119025\n",
            " 0.50113565 0.503494   0.49915463 0.50127333 0.5042491  0.5029451\n",
            " 0.5076022  0.5025381  0.5062244  0.5014353  0.5071186  0.5028056\n",
            " 0.5033664  0.5027902  0.50123155 0.50039685 0.49911317 0.5055391\n",
            " 0.5044753  0.49960643 0.5061613  0.5025528  0.50218123 0.5039631\n",
            " 0.5043261  0.5020492 ]\n",
            "out_coher: [0.23015764 0.48301375 0.262086   0.5132246  0.51195693 0.50146925\n",
            " 0.22357874 0.48642582 0.50273776 0.24214238 0.23284988 0.5136517\n",
            " 0.28701544 0.28543374 0.24655165 0.4846202  0.26630908 0.2598139\n",
            " 0.25945342 0.4964826  0.49672592 0.49585634 0.50399625 0.22846736\n",
            " 0.29701647 0.2266567  0.17577438 0.33356    0.48921895 0.21096899\n",
            " 0.5227372  0.4958975 ]\n",
            "out_prompt: [3.9137354e-01 7.2959803e-02 3.7596461e-03 2.2785878e-04 3.4567219e-01\n",
            " 7.4621348e-04 3.6845738e-01 2.5185937e-01 2.5370582e-03 3.7854874e-01\n",
            " 2.9451502e-03 3.8272542e-01 9.6521089e-03 1.2139053e-03 3.8470969e-01\n",
            " 1.7516945e-03 2.5460362e-03 3.8231802e-01 3.6765686e-01 1.2839463e-01\n",
            " 2.2361220e-01 3.6889651e-01 9.6020307e-03 3.7935415e-01 3.5869882e-01\n",
            " 3.4121767e-01 2.6280056e-03 3.7696412e-01 6.2348251e-04 3.8267365e-01\n",
            " 6.8500120e-04 3.5665548e-01]\n",
            "combined_score: [0.5014036297798157, 0.5865793228149414, 0.52409827709198, 0.7019040584564209, 0.7308493852615356, 0.5655032992362976, 0.7520900368690491, 0.5049496293067932, 0.6534309983253479, 0.3567937910556793, 0.23195108771324158, 0.713200032711029, 0.6245152950286865, 0.5074722766876221, 0.6010370850563049, 0.5814093351364136, 0.3735949695110321, 0.534893274307251, 0.3205336630344391, 0.4939468204975128, 0.6029704809188843, 0.5571023225784302, 0.5481315851211548, 0.7602894902229309, 0.5364406108856201, 0.6062673330307007, 0.7551952600479126, 0.5333321690559387, 0.5391809940338135, 0.6532013416290283, 0.6777381896972656, 0.661045253276825]\n",
            "coherence_score_nli: [0.22557624313049018, 0.3087038881235963, 0.04704849421977997, 0.1090813020709902, 0.16922109325726828, 0.18642071352780262, 0.06767351599410176, 0.15058987085441394, 0.17597099599411845, 0.06831920907522242, 0.07282193005084991, 0.04414609337358603, 0.15310510732334756, 0.005960940460984905, 0.25012747574510286, 0.10706975013636111, 0.25810159227694385, 0.0582972401753068, 0.26893165458459406, 0.3289630393264815, 0.2807478732739886, 0.1982882217465279, 0.34154014763995433, 0.181008455529809, 0.057848192867822945, 0.057915142090577215, 0.07317705407816295, 0.2115076866466552, 0.28153477869927884, 0.11783475540578366, 0.007839225562444577, 0.12123985106591136]\n",
            "normalized_score: [0.66666667 0.6        0.66666667 0.75       0.75       0.8\n",
            " 1.         0.4        0.6        0.2        0.33333333 0.75\n",
            " 0.6        0.66666667 0.5        0.7        0.33333333 0.5\n",
            " 0.55555556 0.6        0.4        0.75       0.6        0.83333333\n",
            " 0.66666667 0.77777778 1.         0.5        0.5        1.\n",
            " 0.25       0.75      ]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "main_data = pd.DataFrame()\n",
        "\n",
        "total_rows_123=0\n",
        "\n",
        "for essay_id, essay_set, essays, prompt, normalized_score in tqdm(dataloader):\n",
        "    total_rows_123 += essay_id.size(0)\n",
        "\n",
        "    if total_rows_123 >= 1000:\n",
        "          break\n",
        "\n",
        "        \n",
        "    # encoded_prompt = context_encoder_tokenizer(prompt, return_tensors='pt', padding=True, truncation=True)\n",
        "    # prompt_tokens = context_encoder_model(**encoded_prompt).pooler_output\n",
        "\n",
        "    # essays_dpr=list(essays)\n",
        "    # document_embeddings_batch = context_encoder_tokenizer(essays_dpr, return_tensors='pt', padding=True, truncation=True)\n",
        "    # document_embeddings_batch = context_encoder_model(**document_embeddings_batch).pooler_output\n",
        "\n",
        "    # with torch.no_grad():\n",
        "    #     prompt_embedding = model(**prompt_tokens).last_hidden_state.mean(dim=1)\n",
        "    #     essay_embedding = model(**document_embeddings_batch).last_hidden_state.mean(dim=1)\n",
        "\n",
        "    # # Calculate similarity (cosine similarity in this case)\n",
        "    # dpr_score = torch.nn.functional.cosine_similarity(prompt_embedding, essay_embedding).item()\n",
        "    # print(type(essays))\n",
        "    means, variances, grammaticals, word_counts, char_counts, coherence_score_nli, val =[], [], [], [], [], [], []\n",
        "    for index in range(len(essays)):\n",
        "        # print(essays[index])\n",
        "        means.append(get_mean_score(essays[index]))\n",
        "        variances.append(get_variance_score(essays[index]))\n",
        "        grammaticals.append(get_grammatical_score(essays[index]))\n",
        "        word_counts.append(get_word_count(essays[index]))\n",
        "        char_counts.append(get_char_count(essays[index]))\n",
        "        coherence_score_nli.append(coherence_score_snli(essays[index]))\n",
        "        val.append(prompt[index]+\".\"+essays[index])\n",
        "\n",
        "    combined_score = model_combined(essays,800)\n",
        "    combined_score = [item.item() for item in combined_score]\n",
        "\n",
        "    val, lengths_batch = preprocess_essay(val)\n",
        "    # val = val.to(device)\n",
        "    essays, lengths_batch = preprocess_essay(essays)\n",
        "    # essays = essays.to(device)\n",
        "\n",
        "    out_semantic = model_semantic(essays, lengths_batch)\n",
        "    out_coher = model_coher(essays, lengths_batch)\n",
        "    # mittal_sahab_score = mittal_is_a_model(essay)\n",
        "    # normalized_score = normalized_score.to(device)\n",
        "\n",
        "    out_prompt = model_prompt(val, lengths_batch)\n",
        "\n",
        "    out_semantic = out_semantic.cpu().detach().numpy()\n",
        "    out_coher = out_coher.cpu().detach().numpy()\n",
        "    out_prompt = out_prompt.cpu().detach().numpy()\n",
        "    normalized_score = normalized_score.cpu().detach().numpy()\n",
        "\n",
        "\n",
        "    # mittal_sahab = mittal_sahab_score().cpu().detach().numpy()\n",
        "\n",
        "\n",
        "    # print(normalized_score_np.is_cuda, word_counts.is_cuda)\n",
        "\n",
        "    # Print the shapes of arrays before creating the DataFrame\n",
        "    print(\"Shapes before creating DataFrame:\")\n",
        "    print(\"out_semantic:\", out_semantic)\n",
        "    print(\"out_coher:\", out_coher)\n",
        "    print(\"out_prompt:\", out_prompt)\n",
        "    print(\"combined_score:\", combined_score)\n",
        "    print(\"coherence_score_nli:\", coherence_score_nli)\n",
        "    print(\"normalized_score:\", normalized_score)\n",
        "\n",
        "    # Create the DataFrame\n",
        "    temp_df = pd.DataFrame({\n",
        "        'means': means,\n",
        "        'variances': variances,\n",
        "        'grammaticals': grammaticals,\n",
        "        'word_counts': word_counts,\n",
        "        'char_counts': char_counts,\n",
        "        'out_semantic': np.squeeze(out_semantic),\n",
        "        'out_coher': np.squeeze(out_coher),\n",
        "        'out_prompt': np.squeeze(out_prompt),\n",
        "        'combined_score' : np.squeeze(combined_score),\n",
        "        'coherence_score_nli' : np.squeeze(coherence_score_nli),\n",
        "        'normalized_score': np.squeeze(normalized_score)\n",
        "    })\n",
        "    main_data = pd.concat([main_data, temp_df], ignore_index=True)\n",
        "    \n",
        "main_data.to_csv('main_data.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "CO8UfzPwZRvi",
        "outputId": "2e9c580c-01b8-458b-c667-b37dc78e9185"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>means</th>\n",
              "      <th>variances</th>\n",
              "      <th>grammaticals</th>\n",
              "      <th>word_counts</th>\n",
              "      <th>char_counts</th>\n",
              "      <th>out_semantic</th>\n",
              "      <th>out_coher</th>\n",
              "      <th>out_prompt</th>\n",
              "      <th>combined_score</th>\n",
              "      <th>coherence_score_nli</th>\n",
              "      <th>normalized_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.258621</td>\n",
              "      <td>4.726219</td>\n",
              "      <td>0.918103</td>\n",
              "      <td>232</td>\n",
              "      <td>1219</td>\n",
              "      <td>0.504168</td>\n",
              "      <td>0.201281</td>\n",
              "      <td>0.374818</td>\n",
              "      <td>0.808965</td>\n",
              "      <td>0.029003</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.563265</td>\n",
              "      <td>4.841916</td>\n",
              "      <td>0.951020</td>\n",
              "      <td>245</td>\n",
              "      <td>1362</td>\n",
              "      <td>0.505810</td>\n",
              "      <td>0.253076</td>\n",
              "      <td>0.337112</td>\n",
              "      <td>0.750977</td>\n",
              "      <td>0.080821</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.773585</td>\n",
              "      <td>5.043076</td>\n",
              "      <td>0.867925</td>\n",
              "      <td>53</td>\n",
              "      <td>252</td>\n",
              "      <td>0.502608</td>\n",
              "      <td>0.305709</td>\n",
              "      <td>0.352617</td>\n",
              "      <td>0.383006</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.611111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.276786</td>\n",
              "      <td>3.896604</td>\n",
              "      <td>0.848214</td>\n",
              "      <td>112</td>\n",
              "      <td>590</td>\n",
              "      <td>0.502875</td>\n",
              "      <td>0.255067</td>\n",
              "      <td>0.001635</td>\n",
              "      <td>0.491345</td>\n",
              "      <td>0.053883</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.651961</td>\n",
              "      <td>6.192594</td>\n",
              "      <td>0.901961</td>\n",
              "      <td>408</td>\n",
              "      <td>2305</td>\n",
              "      <td>0.504047</td>\n",
              "      <td>0.486871</td>\n",
              "      <td>0.000599</td>\n",
              "      <td>0.621725</td>\n",
              "      <td>0.176764</td>\n",
              "      <td>0.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>987</th>\n",
              "      <td>4.555147</td>\n",
              "      <td>5.835194</td>\n",
              "      <td>0.900735</td>\n",
              "      <td>272</td>\n",
              "      <td>1510</td>\n",
              "      <td>0.502553</td>\n",
              "      <td>0.333560</td>\n",
              "      <td>0.376964</td>\n",
              "      <td>0.533332</td>\n",
              "      <td>0.211508</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>988</th>\n",
              "      <td>4.694444</td>\n",
              "      <td>6.989969</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>72</td>\n",
              "      <td>409</td>\n",
              "      <td>0.502181</td>\n",
              "      <td>0.489219</td>\n",
              "      <td>0.000623</td>\n",
              "      <td>0.539181</td>\n",
              "      <td>0.281535</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>989</th>\n",
              "      <td>4.291209</td>\n",
              "      <td>4.898714</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>182</td>\n",
              "      <td>962</td>\n",
              "      <td>0.503963</td>\n",
              "      <td>0.210969</td>\n",
              "      <td>0.382674</td>\n",
              "      <td>0.653201</td>\n",
              "      <td>0.117835</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>990</th>\n",
              "      <td>4.553191</td>\n",
              "      <td>5.566320</td>\n",
              "      <td>0.819149</td>\n",
              "      <td>94</td>\n",
              "      <td>521</td>\n",
              "      <td>0.504326</td>\n",
              "      <td>0.522737</td>\n",
              "      <td>0.000685</td>\n",
              "      <td>0.677738</td>\n",
              "      <td>0.007839</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991</th>\n",
              "      <td>4.704918</td>\n",
              "      <td>5.683418</td>\n",
              "      <td>0.907104</td>\n",
              "      <td>183</td>\n",
              "      <td>1043</td>\n",
              "      <td>0.502049</td>\n",
              "      <td>0.495898</td>\n",
              "      <td>0.356655</td>\n",
              "      <td>0.661045</td>\n",
              "      <td>0.121240</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>992 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        means  variances  grammaticals  word_counts  char_counts  \\\n",
              "0    4.258621   4.726219      0.918103          232         1219   \n",
              "1    4.563265   4.841916      0.951020          245         1362   \n",
              "2    3.773585   5.043076      0.867925           53          252   \n",
              "3    4.276786   3.896604      0.848214          112          590   \n",
              "4    4.651961   6.192594      0.901961          408         2305   \n",
              "..        ...        ...           ...          ...          ...   \n",
              "987  4.555147   5.835194      0.900735          272         1510   \n",
              "988  4.694444   6.989969      0.888889           72          409   \n",
              "989  4.291209   4.898714      0.923077          182          962   \n",
              "990  4.553191   5.566320      0.819149           94          521   \n",
              "991  4.704918   5.683418      0.907104          183         1043   \n",
              "\n",
              "     out_semantic  out_coher  out_prompt  combined_score  coherence_score_nli  \\\n",
              "0        0.504168   0.201281    0.374818        0.808965             0.029003   \n",
              "1        0.505810   0.253076    0.337112        0.750977             0.080821   \n",
              "2        0.502608   0.305709    0.352617        0.383006             0.000000   \n",
              "3        0.502875   0.255067    0.001635        0.491345             0.053883   \n",
              "4        0.504047   0.486871    0.000599        0.621725             0.176764   \n",
              "..            ...        ...         ...             ...                  ...   \n",
              "987      0.502553   0.333560    0.376964        0.533332             0.211508   \n",
              "988      0.502181   0.489219    0.000623        0.539181             0.281535   \n",
              "989      0.503963   0.210969    0.382674        0.653201             0.117835   \n",
              "990      0.504326   0.522737    0.000685        0.677738             0.007839   \n",
              "991      0.502049   0.495898    0.356655        0.661045             0.121240   \n",
              "\n",
              "     normalized_score  \n",
              "0            1.000000  \n",
              "1            1.000000  \n",
              "2            0.611111  \n",
              "3            0.500000  \n",
              "4            0.700000  \n",
              "..                ...  \n",
              "987          0.500000  \n",
              "988          0.500000  \n",
              "989          1.000000  \n",
              "990          0.250000  \n",
              "991          0.750000  \n",
              "\n",
              "[992 rows x 11 columns]"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "main_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "0r0ZlG7oZRvj",
        "outputId": "8400434f-2f45-4fd3-f392-9b076238cff7"
      },
      "outputs": [],
      "source": [
        "# device = 'cuda'\n",
        "# model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMhhiCLhZRvj"
      },
      "outputs": [],
      "source": [
        "def get_final_score(essays, prompt):\n",
        "    main_data = pd.DataFrame()\n",
        "\n",
        "    means, variances, grammaticals, word_counts, char_counts = get_mean_score(essays[0]), get_variance_score(essays[0]), get_grammatical_score(essays[0]),get_word_count(essays[0]), get_char_count(essays[0])\n",
        "\n",
        "    val = []\n",
        "    for i in range(1):\n",
        "        val.append(prompt[i]+\".\"+essays[i])\n",
        "\n",
        "    val, lengths_batch = preprocess_essay(val)\n",
        "    val = val.to(device)\n",
        "    essays, lengths_batch = preprocess_essay(essays)\n",
        "    essays = essays.to(device)\n",
        "    out_semantic = model_semantic(essays, lengths_batch)\n",
        "    out_coher = model_coher(essays, lengths_batch)\n",
        "\n",
        "    out_prompt = model_prompt(val, lengths_batch)\n",
        "    out_semantic = out_semantic.cpu().detach().numpy()\n",
        "    out_coher = out_coher.cpu().detach().numpy()\n",
        "    out_prompt = out_prompt.cpu().detach().numpy()\n",
        "\n",
        "    coherence_nli = coherence_score_nli(essay)\n",
        "    score_combined_score = combined_score(essay, 500)\n",
        "    # score_vaibhav = mittal_is_a_model(essay)\n",
        "\n",
        "    main_data = pd.DataFrame()\n",
        "    temp_df = pd.DataFrame({\n",
        "        'means': means,\n",
        "        'variances': variances,\n",
        "        'grammaticals': grammaticals,\n",
        "        'word_counts': word_counts,\n",
        "        'char_counts': char_counts,\n",
        "        'out_semantic': out_semantic[0],\n",
        "        'out_coher': out_coher[0],\n",
        "        'out_prompt': out_prompt[0],\n",
        "        'coherence_nli' : coherence_nli,\n",
        "        'score_combined_score' : score_combined_score,\n",
        "        # 'score_vaibhav' : score_vaibhav,\n",
        "        # 'normalized_score': normalized_score\n",
        "      }, index=[0])\n",
        "\n",
        "    main_data = pd.concat([main_data, temp_df], ignore_index=True)\n",
        "    return main_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {},
      "outputs": [],
      "source": [
        "main_data_vaibhav = pd.DataFrame()\n",
        "\n",
        "total_rows_123=0\n",
        "\n",
        "for essay_id, essay_set, essays, prompt, normalized_score in tqdm(dataloader):\n",
        "    total_rows_123 += essay_id.size(0)\n",
        "\n",
        "    if total_rows_123 >= 1000:\n",
        "          break\n",
        "\n",
        "    vaibhav_lst =[]\n",
        "    for index in range(len(essays)):\n",
        "        vaibhav_lst.append(vaibhav(essays[index]))\n",
        "\n",
        "    \n",
        "    # print(\"normalized_score:\", normalized_score)\n",
        "\n",
        "    # Create the DataFrame\n",
        "    temp_df = pd.DataFrame({\n",
        "        'ranks': vaibhav_lst,\n",
        "    })\n",
        "    main_data_vaibhav = pd.concat([main_data_vaibhav, temp_df], ignore_index=True)\n",
        "    \n",
        "# main_data.to_csv('main_data.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ranks</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>380</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>381</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>382</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>384 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     ranks\n",
              "0        4\n",
              "1        4\n",
              "2        5\n",
              "3        4\n",
              "4       10\n",
              "..     ...\n",
              "379      5\n",
              "380      5\n",
              "381      5\n",
              "382      8\n",
              "383      5\n",
              "\n",
              "[384 rows x 1 columns]"
            ]
          },
          "execution_count": 166,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "main_data_vaibhav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\pchhl\\AppData\\Local\\Temp\\ipykernel_25820\\4213488995.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  final_dataframe['ranks'] = main_data_vaibhav['ranks']/10\n"
          ]
        }
      ],
      "source": [
        "final_dataframe = main_data[:384]\n",
        "final_dataframe['ranks'] = main_data_vaibhav['ranks']/10\n",
        "final_dataframe.to_csv(\"final_dataframe.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "# means\tvariances\tgrammaticals\tword_counts\tchar_counts\tout_semantic\tout_coher\tout_prompt\tcombined_score\tcoherence_score_nli\tnormalized_score\n",
        "X = main_data[['means', 'variances', 'grammaticals', 'word_counts', 'char_counts', 'out_semantic', 'out_coher', 'out_prompt', 'combined_score', 'coherence_score_nli','ranks']]\n",
        "y = main_data['normalized_score']\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\ttrain-rmse:0.24290\tvalid-rmse:0.27675\n",
            "[1]\ttrain-rmse:0.24166\tvalid-rmse:0.27547\n",
            "[2]\ttrain-rmse:0.24045\tvalid-rmse:0.27421\n",
            "[3]\ttrain-rmse:0.23925\tvalid-rmse:0.27297\n",
            "[4]\ttrain-rmse:0.23807\tvalid-rmse:0.27173\n",
            "[5]\ttrain-rmse:0.23691\tvalid-rmse:0.27053\n",
            "[6]\ttrain-rmse:0.23576\tvalid-rmse:0.26931\n",
            "[7]\ttrain-rmse:0.23463\tvalid-rmse:0.26810\n",
            "[8]\ttrain-rmse:0.23352\tvalid-rmse:0.26693\n",
            "[9]\ttrain-rmse:0.23241\tvalid-rmse:0.26575\n",
            "[10]\ttrain-rmse:0.23133\tvalid-rmse:0.26459\n",
            "[11]\ttrain-rmse:0.23026\tvalid-rmse:0.26345\n",
            "[12]\ttrain-rmse:0.22920\tvalid-rmse:0.26233\n",
            "[13]\ttrain-rmse:0.22816\tvalid-rmse:0.26126\n",
            "[14]\ttrain-rmse:0.22714\tvalid-rmse:0.26016\n",
            "[15]\ttrain-rmse:0.22613\tvalid-rmse:0.25908\n",
            "[16]\ttrain-rmse:0.22513\tvalid-rmse:0.25802\n",
            "[17]\ttrain-rmse:0.22416\tvalid-rmse:0.25700\n",
            "[18]\ttrain-rmse:0.22319\tvalid-rmse:0.25596\n",
            "[19]\ttrain-rmse:0.22224\tvalid-rmse:0.25494\n",
            "[20]\ttrain-rmse:0.22131\tvalid-rmse:0.25397\n",
            "[21]\ttrain-rmse:0.22037\tvalid-rmse:0.25296\n",
            "[22]\ttrain-rmse:0.21945\tvalid-rmse:0.25197\n",
            "[23]\ttrain-rmse:0.21854\tvalid-rmse:0.25092\n",
            "[24]\ttrain-rmse:0.21765\tvalid-rmse:0.24996\n",
            "[25]\ttrain-rmse:0.21677\tvalid-rmse:0.24893\n",
            "[26]\ttrain-rmse:0.21592\tvalid-rmse:0.24804\n",
            "[27]\ttrain-rmse:0.21506\tvalid-rmse:0.24711\n",
            "[28]\ttrain-rmse:0.21422\tvalid-rmse:0.24613\n",
            "[29]\ttrain-rmse:0.21339\tvalid-rmse:0.24523\n",
            "[30]\ttrain-rmse:0.21257\tvalid-rmse:0.24427\n",
            "[31]\ttrain-rmse:0.21178\tvalid-rmse:0.24344\n",
            "[32]\ttrain-rmse:0.21099\tvalid-rmse:0.24255\n",
            "[33]\ttrain-rmse:0.21020\tvalid-rmse:0.24171\n",
            "[34]\ttrain-rmse:0.20943\tvalid-rmse:0.24079\n",
            "[35]\ttrain-rmse:0.20866\tvalid-rmse:0.23999\n",
            "[36]\ttrain-rmse:0.20791\tvalid-rmse:0.23918\n",
            "[37]\ttrain-rmse:0.20717\tvalid-rmse:0.23840\n",
            "[38]\ttrain-rmse:0.20644\tvalid-rmse:0.23753\n",
            "[39]\ttrain-rmse:0.20572\tvalid-rmse:0.23678\n",
            "[40]\ttrain-rmse:0.20501\tvalid-rmse:0.23601\n",
            "[41]\ttrain-rmse:0.20431\tvalid-rmse:0.23527\n",
            "[42]\ttrain-rmse:0.20362\tvalid-rmse:0.23446\n",
            "[43]\ttrain-rmse:0.20294\tvalid-rmse:0.23376\n",
            "[44]\ttrain-rmse:0.20227\tvalid-rmse:0.23302\n",
            "[45]\ttrain-rmse:0.20161\tvalid-rmse:0.23229\n",
            "[46]\ttrain-rmse:0.20096\tvalid-rmse:0.23161\n",
            "[47]\ttrain-rmse:0.20032\tvalid-rmse:0.23086\n",
            "[48]\ttrain-rmse:0.19969\tvalid-rmse:0.23020\n",
            "[49]\ttrain-rmse:0.19907\tvalid-rmse:0.22957\n",
            "[50]\ttrain-rmse:0.19846\tvalid-rmse:0.22891\n",
            "[51]\ttrain-rmse:0.19786\tvalid-rmse:0.22828\n",
            "[52]\ttrain-rmse:0.19726\tvalid-rmse:0.22767\n",
            "[53]\ttrain-rmse:0.19667\tvalid-rmse:0.22706\n",
            "[54]\ttrain-rmse:0.19610\tvalid-rmse:0.22639\n",
            "[55]\ttrain-rmse:0.19553\tvalid-rmse:0.22579\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[56]\ttrain-rmse:0.19496\tvalid-rmse:0.22520\n",
            "[57]\ttrain-rmse:0.19441\tvalid-rmse:0.22462\n",
            "[58]\ttrain-rmse:0.19387\tvalid-rmse:0.22398\n",
            "[59]\ttrain-rmse:0.19333\tvalid-rmse:0.22341\n",
            "[60]\ttrain-rmse:0.19280\tvalid-rmse:0.22280\n",
            "[61]\ttrain-rmse:0.19229\tvalid-rmse:0.22226\n",
            "[62]\ttrain-rmse:0.19177\tvalid-rmse:0.22173\n",
            "[63]\ttrain-rmse:0.19126\tvalid-rmse:0.22114\n",
            "[64]\ttrain-rmse:0.19076\tvalid-rmse:0.22068\n",
            "[65]\ttrain-rmse:0.19027\tvalid-rmse:0.22011\n",
            "[66]\ttrain-rmse:0.18978\tvalid-rmse:0.21966\n",
            "[67]\ttrain-rmse:0.18931\tvalid-rmse:0.21915\n",
            "[68]\ttrain-rmse:0.18883\tvalid-rmse:0.21860\n",
            "[69]\ttrain-rmse:0.18837\tvalid-rmse:0.21811\n",
            "[70]\ttrain-rmse:0.18791\tvalid-rmse:0.21767\n",
            "[71]\ttrain-rmse:0.18746\tvalid-rmse:0.21719\n",
            "[72]\ttrain-rmse:0.18702\tvalid-rmse:0.21673\n",
            "[73]\ttrain-rmse:0.18658\tvalid-rmse:0.21626\n",
            "[74]\ttrain-rmse:0.18614\tvalid-rmse:0.21575\n",
            "[75]\ttrain-rmse:0.18571\tvalid-rmse:0.21534\n",
            "[76]\ttrain-rmse:0.18529\tvalid-rmse:0.21490\n",
            "[77]\ttrain-rmse:0.18488\tvalid-rmse:0.21443\n",
            "[78]\ttrain-rmse:0.18448\tvalid-rmse:0.21401\n",
            "[79]\ttrain-rmse:0.18407\tvalid-rmse:0.21365\n",
            "[80]\ttrain-rmse:0.18368\tvalid-rmse:0.21323\n",
            "[81]\ttrain-rmse:0.18329\tvalid-rmse:0.21281\n",
            "[82]\ttrain-rmse:0.18289\tvalid-rmse:0.21235\n",
            "[83]\ttrain-rmse:0.18251\tvalid-rmse:0.21190\n",
            "[84]\ttrain-rmse:0.18213\tvalid-rmse:0.21154\n",
            "[85]\ttrain-rmse:0.18175\tvalid-rmse:0.21109\n",
            "[86]\ttrain-rmse:0.18139\tvalid-rmse:0.21075\n",
            "[87]\ttrain-rmse:0.18102\tvalid-rmse:0.21035\n",
            "[88]\ttrain-rmse:0.18067\tvalid-rmse:0.21002\n",
            "[89]\ttrain-rmse:0.18032\tvalid-rmse:0.20964\n",
            "[90]\ttrain-rmse:0.17994\tvalid-rmse:0.20927\n",
            "[91]\ttrain-rmse:0.17959\tvalid-rmse:0.20882\n",
            "[92]\ttrain-rmse:0.17923\tvalid-rmse:0.20848\n",
            "[93]\ttrain-rmse:0.17889\tvalid-rmse:0.20807\n",
            "[94]\ttrain-rmse:0.17853\tvalid-rmse:0.20771\n",
            "[95]\ttrain-rmse:0.17820\tvalid-rmse:0.20728\n",
            "[96]\ttrain-rmse:0.17786\tvalid-rmse:0.20697\n",
            "[97]\ttrain-rmse:0.17754\tvalid-rmse:0.20662\n",
            "[98]\ttrain-rmse:0.17720\tvalid-rmse:0.20632\n",
            "[99]\ttrain-rmse:0.17688\tvalid-rmse:0.20600\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pchhl\\anaconda3\\lib\\site-packages\\xgboost\\core.py:726: FutureWarning: Pass `evals` as keyword args.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
        "\n",
        "param = {\n",
        "    'max_depth': 3,\n",
        "    'eta': 0.01,\n",
        "    'objective': 'reg:squarederror'\n",
        "}\n",
        "num_round = 100\n",
        "\n",
        "bst = xgb.train(param, dtrain, num_round, [(dtrain, 'train'), (dvalid, 'valid')])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<xgboost.core.Booster at 0x21b96040130>"
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>means</th>\n",
              "      <th>variances</th>\n",
              "      <th>grammaticals</th>\n",
              "      <th>word_counts</th>\n",
              "      <th>char_counts</th>\n",
              "      <th>out_semantic</th>\n",
              "      <th>out_coher</th>\n",
              "      <th>out_prompt</th>\n",
              "      <th>combined_score</th>\n",
              "      <th>coherence_score_nli</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>4.954955</td>\n",
              "      <td>7.196169</td>\n",
              "      <td>0.891892</td>\n",
              "      <td>111</td>\n",
              "      <td>660</td>\n",
              "      <td>0.500796</td>\n",
              "      <td>0.503431</td>\n",
              "      <td>0.346328</td>\n",
              "      <td>0.684430</td>\n",
              "      <td>0.310375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>331</th>\n",
              "      <td>5.120690</td>\n",
              "      <td>6.433710</td>\n",
              "      <td>0.887931</td>\n",
              "      <td>116</td>\n",
              "      <td>709</td>\n",
              "      <td>0.501566</td>\n",
              "      <td>0.483666</td>\n",
              "      <td>0.368868</td>\n",
              "      <td>0.784117</td>\n",
              "      <td>0.175243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>4.313043</td>\n",
              "      <td>4.690410</td>\n",
              "      <td>0.939130</td>\n",
              "      <td>345</td>\n",
              "      <td>1832</td>\n",
              "      <td>0.504080</td>\n",
              "      <td>0.292549</td>\n",
              "      <td>0.346097</td>\n",
              "      <td>0.565251</td>\n",
              "      <td>0.143300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309</th>\n",
              "      <td>4.830409</td>\n",
              "      <td>6.374748</td>\n",
              "      <td>0.918129</td>\n",
              "      <td>171</td>\n",
              "      <td>996</td>\n",
              "      <td>0.503389</td>\n",
              "      <td>0.489085</td>\n",
              "      <td>0.369265</td>\n",
              "      <td>0.872319</td>\n",
              "      <td>0.098921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>3.328125</td>\n",
              "      <td>2.230876</td>\n",
              "      <td>0.838542</td>\n",
              "      <td>192</td>\n",
              "      <td>830</td>\n",
              "      <td>0.503660</td>\n",
              "      <td>0.233364</td>\n",
              "      <td>0.381834</td>\n",
              "      <td>0.595867</td>\n",
              "      <td>0.170512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>705</th>\n",
              "      <td>4.257840</td>\n",
              "      <td>4.435261</td>\n",
              "      <td>0.846690</td>\n",
              "      <td>287</td>\n",
              "      <td>1508</td>\n",
              "      <td>0.502187</td>\n",
              "      <td>0.507885</td>\n",
              "      <td>0.002818</td>\n",
              "      <td>0.535295</td>\n",
              "      <td>0.203311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>4.990566</td>\n",
              "      <td>6.518779</td>\n",
              "      <td>0.896226</td>\n",
              "      <td>106</td>\n",
              "      <td>634</td>\n",
              "      <td>0.500003</td>\n",
              "      <td>0.509265</td>\n",
              "      <td>0.352399</td>\n",
              "      <td>0.494369</td>\n",
              "      <td>0.062507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>809</th>\n",
              "      <td>4.138462</td>\n",
              "      <td>3.780828</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>65</td>\n",
              "      <td>333</td>\n",
              "      <td>0.504424</td>\n",
              "      <td>0.266739</td>\n",
              "      <td>0.377860</td>\n",
              "      <td>0.428078</td>\n",
              "      <td>0.015809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237</th>\n",
              "      <td>3.828169</td>\n",
              "      <td>3.308502</td>\n",
              "      <td>0.847887</td>\n",
              "      <td>355</td>\n",
              "      <td>1713</td>\n",
              "      <td>0.504365</td>\n",
              "      <td>0.512918</td>\n",
              "      <td>0.050550</td>\n",
              "      <td>0.520719</td>\n",
              "      <td>0.327485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>754</th>\n",
              "      <td>5.130435</td>\n",
              "      <td>5.635161</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>46</td>\n",
              "      <td>281</td>\n",
              "      <td>0.502735</td>\n",
              "      <td>0.493073</td>\n",
              "      <td>0.000107</td>\n",
              "      <td>0.241110</td>\n",
              "      <td>0.205307</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>199 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        means  variances  grammaticals  word_counts  char_counts  \\\n",
              "213  4.954955   7.196169      0.891892          111          660   \n",
              "331  5.120690   6.433710      0.887931          116          709   \n",
              "501  4.313043   4.690410      0.939130          345         1832   \n",
              "309  4.830409   6.374748      0.918129          171          996   \n",
              "88   3.328125   2.230876      0.838542          192          830   \n",
              "..        ...        ...           ...          ...          ...   \n",
              "705  4.257840   4.435261      0.846690          287         1508   \n",
              "305  4.990566   6.518779      0.896226          106          634   \n",
              "809  4.138462   3.780828      0.923077           65          333   \n",
              "237  3.828169   3.308502      0.847887          355         1713   \n",
              "754  5.130435   5.635161      0.847826           46          281   \n",
              "\n",
              "     out_semantic  out_coher  out_prompt  combined_score  coherence_score_nli  \n",
              "213      0.500796   0.503431    0.346328        0.684430             0.310375  \n",
              "331      0.501566   0.483666    0.368868        0.784117             0.175243  \n",
              "501      0.504080   0.292549    0.346097        0.565251             0.143300  \n",
              "309      0.503389   0.489085    0.369265        0.872319             0.098921  \n",
              "88       0.503660   0.233364    0.381834        0.595867             0.170512  \n",
              "..            ...        ...         ...             ...                  ...  \n",
              "705      0.502187   0.507885    0.002818        0.535295             0.203311  \n",
              "305      0.500003   0.509265    0.352399        0.494369             0.062507  \n",
              "809      0.504424   0.266739    0.377860        0.428078             0.015809  \n",
              "237      0.504365   0.512918    0.050550        0.520719             0.327485  \n",
              "754      0.502735   0.493073    0.000107        0.241110             0.205307  \n",
              "\n",
              "[199 rows x 10 columns]"
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(X_valid)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pchhl\\anaconda3\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [23:33:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07f6e447eee219473-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ],
      "source": [
        "model_path = 'xgboost_model_.pth'\n",
        "bst.save_model(model_path)\n",
        "\n",
        "# Load the model later\n",
        "loaded_model = xgb.Booster()\n",
        "loaded_model.load_model(model_path)\n",
        "\n",
        "# Now you can use the loaded_model for predictions\n",
        "dpredict = xgb.DMatrix(X_valid)\n",
        "predictions = loaded_model.predict(dpredict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {},
      "outputs": [],
      "source": [
        "dpredict = xgb.DMatrix(X_valid)\n",
        "y_pred = bst.predict(dpredict)\n",
        "# print(y_pred.shape)\n",
        "# print(y_valid.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_final_score(essays, prompt):\n",
        "    main_data = pd.DataFrame()\n",
        "\n",
        "    means, variances, grammaticals, word_counts, char_counts = get_mean_score(essays[0]), get_variance_score(essays[0]), get_grammatical_score(essays[0]),get_word_count(essays[0]), get_char_count(essays[0])\n",
        "\n",
        "    val = []\n",
        "    for i in range(1):\n",
        "        val.append(prompt[i]+\".\"+essays[i])\n",
        "\n",
        "    val, lengths_batch = preprocess_essay(val)\n",
        "    val = val.to(device)\n",
        "    essays, lengths_batch = preprocess_essay(essays)\n",
        "    essays = essays.to(device)\n",
        "    out_semantic = model_semantic(essays, lengths_batch)\n",
        "    out_coher = model_coher(essays, lengths_batch)\n",
        "\n",
        "    out_prompt = model_prompt(val, lengths_batch)\n",
        "    out_semantic = out_semantic.cpu().detach().numpy()\n",
        "    out_coher = out_coher.cpu().detach().numpy()\n",
        "    out_prompt = out_prompt.cpu().detach().numpy()\n",
        "\n",
        "    main_data = pd.DataFrame()\n",
        "    temp_df = pd.DataFrame({\n",
        "        'means': means,\n",
        "        'variances': variances,\n",
        "        'grammaticals': grammaticals,\n",
        "        'word_counts': word_counts,\n",
        "        'char_counts': char_counts,\n",
        "        'out_semantic': out_semantic[0],\n",
        "        'out_coher': out_coher[0],\n",
        "        'out_prompt': out_prompt[0],\n",
        "        # 'normalized_score': normalized_score\n",
        "      }, index=[0])\n",
        "\n",
        "    main_data = pd.concat([main_data, temp_df], ignore_index=True)\n",
        "    return main_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get_final_score(essays, prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.6534078 , 0.6685848 , 0.5662235 , 0.7438714 , 0.6241441 ,\n",
              "       0.68078595, 0.68416196, 0.6890191 , 0.52516776, 0.640056  ,\n",
              "       0.6700448 , 0.32127282, 0.68078595, 0.48067266, 0.6677401 ,\n",
              "       0.32352638, 0.6481685 , 0.5472554 , 0.67674243, 0.6433277 ,\n",
              "       0.66454893, 0.35765594, 0.68078595, 0.55290973, 0.5235108 ,\n",
              "       0.66104245, 0.4181817 , 0.5235108 , 0.5183698 , 0.5239977 ,\n",
              "       0.4937937 , 0.6734772 , 0.5840133 , 0.6530848 , 0.69923294,\n",
              "       0.6249911 , 0.6555466 , 0.32453158, 0.52412045, 0.7015259 ,\n",
              "       0.6765273 , 0.6433277 , 0.33486572, 0.5147451 , 0.66241014,\n",
              "       0.6644684 , 0.5662235 , 0.6563565 , 0.7562974 , 0.6677401 ,\n",
              "       0.5929126 , 0.5929126 , 0.5307187 , 0.43094075, 0.6700448 ,\n",
              "       0.76540685, 0.625801  , 0.6717836 , 0.600708  , 0.48067266,\n",
              "       0.59337485, 0.5248448 , 0.6241441 , 0.6677401 , 0.68416196,\n",
              "       0.6433277 , 0.6433277 , 0.6156393 , 0.68416196, 0.32334176,\n",
              "       0.6677401 , 0.7355087 , 0.75522983, 0.47501794, 0.5929126 ,\n",
              "       0.5929126 , 0.6249911 , 0.38096893, 0.76193917, 0.6433277 ,\n",
              "       0.6145073 , 0.70052546, 0.67674243, 0.6433277 , 0.742218  ,\n",
              "       0.4288381 , 0.5533451 , 0.6249911 , 0.39843705, 0.66454893,\n",
              "       0.67751426, 0.7389519 , 0.6731513 , 0.6824795 , 0.55980444,\n",
              "       0.6966537 , 0.6534078 , 0.49545068, 0.6700448 , 0.4309635 ,\n",
              "       0.76073223, 0.600708  , 0.66104245, 0.70823526, 0.76073223,\n",
              "       0.6734772 , 0.5257774 , 0.4534791 , 0.625801  , 0.76073223,\n",
              "       0.5610497 , 0.45588115, 0.6805809 , 0.6824795 , 0.55371475,\n",
              "       0.46206576, 0.67674243, 0.5244595 , 0.6249911 , 0.55728793,\n",
              "       0.68078595, 0.69923294, 0.6481685 , 0.5016698 , 0.30648938,\n",
              "       0.6534078 , 0.48443538, 0.55541986, 0.5235108 , 0.3475496 ,\n",
              "       0.7190871 , 0.5472554 , 0.70823526, 0.69923294, 0.76073223,\n",
              "       0.54683656, 0.5147451 , 0.4276126 , 0.69923294, 0.625801  ,\n",
              "       0.64905834, 0.6931643 , 0.68078595, 0.37696776, 0.6522749 ,\n",
              "       0.4937937 , 0.67674243, 0.44530085, 0.5235108 , 0.39037246,\n",
              "       0.6258918 , 0.43326733, 0.58627987, 0.70823526, 0.6717836 ,\n",
              "       0.65777075, 0.62423486, 0.5235108 , 0.68023187, 0.68416196,\n",
              "       0.66185236, 0.501991  , 0.6717836 , 0.69923294, 0.35665074,\n",
              "       0.4974353 , 0.52906173, 0.6734772 , 0.70823526, 0.6249911 ,\n",
              "       0.64905834, 0.76073223, 0.6433277 , 0.65777075, 0.7173291 ,\n",
              "       0.6391662 , 0.6792078 , 0.6717836 , 0.70052546, 0.5533451 ,\n",
              "       0.50131047, 0.76193917, 0.58567023, 0.35706344, 0.344103  ,\n",
              "       0.5595545 , 0.46350336, 0.3549945 , 0.65233004, 0.6433277 ,\n",
              "       0.5183812 , 0.6433277 , 0.6241441 , 0.54682004, 0.54682004,\n",
              "       0.52516776, 0.47501794, 0.56170905, 0.37948096], dtype=float32)"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.4838198825320863\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_qwk(y_true, y_pred, max_rating=10, min_rating=0):\n",
        "    # Construct confusion matrix\n",
        "    conf_mat = np.zeros((max_rating + 1, max_rating + 1))\n",
        "    for a, p in zip(y_true, y_pred):\n",
        "        conf_mat[a][p] += 1\n",
        "\n",
        "    # Compute observed and expected agreement\n",
        "    num_ratings = max_rating - min_rating + 1\n",
        "    O = 0.0\n",
        "    E = 0.0\n",
        "    for i in range(num_ratings):\n",
        "        for j in range(num_ratings):\n",
        "            # Calculate weight\n",
        "            w = ((i - j) ** 2) / ((max_rating - min_rating) ** 2)\n",
        "            O += w * conf_mat[i][j]\n",
        "            E += w * (np.sum(conf_mat[i, :]) * np.sum(conf_mat[:, j])) / np.sum(conf_mat)\n",
        "\n",
        "    # Compute QWK\n",
        "    return 1.0 - O / E\n",
        "\n",
        "# Example usage\n",
        "y_true = np.array(y_valid)\n",
        "y_pred = np.array(y_pred)\n",
        "y_true = np.round(y_true*10).astype(int)\n",
        "y_pred = np.round(y_pred*10).astype(int)\n",
        "\n",
        "\n",
        "print(compute_qwk(y_true, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([7, 7, 6, 7, 6, 7, 7, 7, 5, 6, 7, 3, 7, 5, 7, 3, 6, 5, 7, 6, 7, 4,\n",
              "       7, 6, 5, 7, 4, 5, 5, 5, 5, 7, 6, 7, 7, 6, 7, 3, 5, 7, 7, 6, 3, 5,\n",
              "       7, 7, 6, 7, 8, 7, 6, 6, 5, 4, 7, 8, 6, 7, 6, 5, 6, 5, 6, 7, 7, 6,\n",
              "       6, 6, 7, 3, 7, 7, 8, 5, 6, 6, 6, 4, 8, 6, 6, 7, 7, 6, 7, 4, 6, 6,\n",
              "       4, 7, 7, 7, 7, 7, 6, 7, 7, 5, 7, 4, 8, 6, 7, 7, 8, 7, 5, 5, 6, 8,\n",
              "       6, 5, 7, 7, 6, 5, 7, 5, 6, 6, 7, 7, 6, 5, 3, 7, 5, 6, 5, 3, 7, 5,\n",
              "       7, 7, 8, 5, 5, 4, 7, 6, 6, 7, 7, 4, 7, 5, 7, 4, 5, 4, 6, 4, 6, 7,\n",
              "       7, 7, 6, 5, 7, 7, 7, 5, 7, 7, 4, 5, 5, 7, 7, 6, 6, 8, 6, 7, 7, 6,\n",
              "       7, 7, 7, 6, 5, 8, 6, 4, 3, 6, 5, 4, 7, 6, 5, 6, 6, 5, 5, 5, 5, 6,\n",
              "       4])"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 7 -> Real Score :  7.0\n",
            "Predicted Score : 5 -> Real Score :  5.0\n",
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 3 -> Real Score :  2.0\n",
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 5 -> Real Score :  4.0\n",
            "Predicted Score : 3 -> Real Score :  3.0\n",
            "Predicted Score : 6 -> Real Score :  7.0\n",
            "Predicted Score : 5 -> Real Score :  6.0\n",
            "Predicted Score : 7 -> Real Score :  6.0\n",
            "Predicted Score : 6 -> Real Score :  7.0\n",
            "Predicted Score : 6 -> Real Score :  5.0\n",
            "Predicted Score : 5 -> Real Score :  4.0\n",
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 4 -> Real Score :  3.0\n",
            "Predicted Score : 5 -> Real Score :  6.0\n",
            "Predicted Score : 5 -> Real Score :  4.0\n",
            "Predicted Score : 5 -> Real Score :  6.0\n",
            "Predicted Score : 5 -> Real Score :  6.0\n",
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 5 -> Real Score :  4.0\n",
            "Predicted Score : 6 -> Real Score :  6.0\n",
            "Predicted Score : 7 -> Real Score :  6.0\n",
            "Predicted Score : 7 -> Real Score :  7.0\n",
            "Predicted Score : 6 -> Real Score :  6.0\n",
            "Predicted Score : 5 -> Real Score :  5.0\n",
            "Predicted Score : 4 -> Real Score :  3.0\n",
            "Predicted Score : 7 -> Real Score :  7.0\n",
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 6 -> Real Score :  5.0\n",
            "Predicted Score : 5 -> Real Score :  4.0\n",
            "Predicted Score : 5 -> Real Score :  6.0\n",
            "Predicted Score : 6 -> Real Score :  7.0\n",
            "Predicted Score : 7 -> Real Score :  6.0\n",
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 6 -> Real Score :  7.0\n",
            "Predicted Score : 6 -> Real Score :  6.0\n",
            "Predicted Score : 6 -> Real Score :  7.0\n",
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 8 -> Real Score :  8.0\n",
            "Predicted Score : 6 -> Real Score :  6.0\n",
            "Predicted Score : 6 -> Real Score :  5.0\n",
            "Predicted Score : 4 -> Real Score :  3.0\n",
            "Predicted Score : 8 -> Real Score :  7.0\n",
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 6 -> Real Score :  7.0\n",
            "Predicted Score : 7 -> Real Score :  7.0\n",
            "Predicted Score : 4 -> Real Score :  5.0\n",
            "Predicted Score : 6 -> Real Score :  5.0\n",
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 7 -> Real Score :  7.0\n",
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 6 -> Real Score :  5.0\n",
            "Predicted Score : 7 -> Real Score :  7.0\n",
            "Predicted Score : 6 -> Real Score :  6.0\n",
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 8 -> Real Score :  8.0\n",
            "Predicted Score : 5 -> Real Score :  5.0\n",
            "Predicted Score : 8 -> Real Score :  8.0\n",
            "Predicted Score : 5 -> Real Score :  5.0\n",
            "Predicted Score : 6 -> Real Score :  5.0\n",
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 6 -> Real Score :  7.0\n",
            "Predicted Score : 6 -> Real Score :  6.0\n",
            "Predicted Score : 3 -> Real Score :  3.0\n",
            "Predicted Score : 5 -> Real Score :  4.0\n",
            "Predicted Score : 3 -> Real Score :  3.0\n",
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 5 -> Real Score :  6.0\n",
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 8 -> Real Score :  8.0\n",
            "Predicted Score : 4 -> Real Score :  5.0\n",
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 6 -> Real Score :  5.0\n",
            "Predicted Score : 6 -> Real Score :  6.0\n",
            "Predicted Score : 5 -> Real Score :  6.0\n",
            "Predicted Score : 7 -> Real Score :  6.0\n",
            "Predicted Score : 4 -> Real Score :  3.0\n",
            "Predicted Score : 5 -> Real Score :  4.0\n",
            "Predicted Score : 4 -> Real Score :  3.0\n",
            "Predicted Score : 6 -> Real Score :  5.0\n",
            "Predicted Score : 4 -> Real Score :  4.0\n",
            "Predicted Score : 6 -> Real Score :  6.0\n",
            "Predicted Score : 6 -> Real Score :  7.0\n",
            "Predicted Score : 5 -> Real Score :  4.0\n",
            "Predicted Score : 7 -> Real Score :  6.0\n",
            "Predicted Score : 7 -> Real Score :  7.0\n",
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 5 -> Real Score :  5.0\n",
            "Predicted Score : 7 -> Real Score :  7.0\n",
            "Predicted Score : 6 -> Real Score :  7.0\n",
            "Predicted Score : 6 -> Real Score :  6.0\n",
            "Predicted Score : 6 -> Real Score :  6.0\n",
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 6 -> Real Score :  5.0\n",
            "Predicted Score : 5 -> Real Score :  5.0\n",
            "Predicted Score : 6 -> Real Score :  7.0\n",
            "Predicted Score : 4 -> Real Score :  3.0\n",
            "Predicted Score : 3 -> Real Score :  2.0\n",
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 6 -> Real Score :  6.0\n",
            "Predicted Score : 6 -> Real Score :  6.0\n",
            "Predicted Score : 5 -> Real Score :  6.0\n",
            "Predicted Score : 5 -> Real Score :  6.0\n",
            "Predicted Score : 6 -> Real Score :  6.0\n",
            "109 199\n"
          ]
        }
      ],
      "source": [
        "y_true = np.array(y_valid)\n",
        "y_pred = np.array(y_pred)\n",
        "count=0\n",
        "for i in range(len(y_pred)):\n",
        "    print(f\"Predicted Score : {y_pred[i]} -> Real Score :  {np.round(y_true[i]*10)}\")\n",
        "\n",
        "print(count, len(y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Kendall Tau  Pearson Correlation  Spearman Correlation\n",
            "0     0.633349             0.728448              0.762087\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import kendalltau,spearmanr,pearsonr\n",
        "\n",
        "def kendall_tau(y_true, y_pred):\n",
        "    return kendalltau(y_true, y_pred)[0]\n",
        "\n",
        "def spearman(y_true, y_pred):\n",
        "    return spearmanr(y_true, y_pred)[0]\n",
        "\n",
        "def pearson(y_true, y_pred):\n",
        "    return pearsonr(y_true, y_pred)[0]\n",
        "\n",
        "\n",
        "kendall_ta = kendall_tau(y_true, y_pred)\n",
        "pearson_corr = pearson(y_true, y_pred)\n",
        "spearma_corr = spearman(y_true, y_pred)\n",
        "\n",
        "\n",
        "results_df = pd.DataFrame({\n",
        "    'Kendall Tau': [kendall_ta],\n",
        "    'Pearson Correlation': [pearson_corr],\n",
        "    'Spearman Correlation': [spearma_corr],\n",
        "})\n",
        "\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MODEL WITH DIFFERENT PARAMETERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "Agikco3TZRvk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "5XqNggSMZRvl",
        "outputId": "8443610b-2ed7-4bff-b8c2-83564b2a8b5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Loss: 41.5945\n",
            "Epoch [2/5], Loss: 41.5945\n",
            "Epoch [3/5], Loss: 41.5945\n",
            "Epoch [4/5], Loss: 41.5945\n",
            "Epoch [5/5], Loss: 41.5945\n",
            "OUTPUTS : \n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "================================================================================\n",
            "tensor([[0.5000],\n",
            "        [0.5000],\n",
            "        [0.4000],\n",
            "        [0.7500],\n",
            "        [0.9444],\n",
            "        [0.6667],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.5000],\n",
            "        [0.8000],\n",
            "        [0.7500],\n",
            "        [0.2500],\n",
            "        [0.7500],\n",
            "        [0.4000],\n",
            "        [0.9000],\n",
            "        [0.2778],\n",
            "        [0.6667],\n",
            "        [0.6000],\n",
            "        [0.6000],\n",
            "        [0.7000],\n",
            "        [1.0000],\n",
            "        [0.0000],\n",
            "        [1.0000],\n",
            "        [0.5000],\n",
            "        [0.4000],\n",
            "        [0.7500],\n",
            "        [0.3333],\n",
            "        [0.6000],\n",
            "        [0.4000],\n",
            "        [0.6000],\n",
            "        [0.6000],\n",
            "        [1.0000],\n",
            "        [0.7778],\n",
            "        [0.8333],\n",
            "        [0.7500],\n",
            "        [1.0000],\n",
            "        [0.0000],\n",
            "        [0.0000],\n",
            "        [0.4000],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.6000],\n",
            "        [0.0000],\n",
            "        [0.3333],\n",
            "        [0.3333],\n",
            "        [0.6000],\n",
            "        [0.4000],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.7000],\n",
            "        [0.4000],\n",
            "        [0.6000],\n",
            "        [0.5000],\n",
            "        [0.3333],\n",
            "        [0.6667],\n",
            "        [1.0000],\n",
            "        [0.7778],\n",
            "        [0.7500],\n",
            "        [0.5000],\n",
            "        [0.4000],\n",
            "        [0.3333],\n",
            "        [0.6000],\n",
            "        [0.6667],\n",
            "        [0.6000],\n",
            "        [0.7500],\n",
            "        [0.7000],\n",
            "        [0.6000],\n",
            "        [0.7000],\n",
            "        [0.7500],\n",
            "        [0.0000],\n",
            "        [0.8000],\n",
            "        [1.0000],\n",
            "        [0.8000],\n",
            "        [0.6667],\n",
            "        [0.4000],\n",
            "        [0.6000],\n",
            "        [0.5000],\n",
            "        [0.3333],\n",
            "        [0.7000],\n",
            "        [0.8000],\n",
            "        [0.2500],\n",
            "        [1.0000],\n",
            "        [0.8000],\n",
            "        [0.7000],\n",
            "        [0.6667],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [1.0000],\n",
            "        [0.2500],\n",
            "        [0.7500],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.6667],\n",
            "        [0.7500],\n",
            "        [0.5000],\n",
            "        [1.0000],\n",
            "        [0.6667],\n",
            "        [0.2500],\n",
            "        [1.0000],\n",
            "        [0.6667],\n",
            "        [1.0000],\n",
            "        [0.6000],\n",
            "        [0.7500],\n",
            "        [1.0000],\n",
            "        [0.7778],\n",
            "        [1.0000],\n",
            "        [0.5000],\n",
            "        [0.0000],\n",
            "        [0.3333],\n",
            "        [0.7778],\n",
            "        [0.2500],\n",
            "        [0.5000],\n",
            "        [0.9444],\n",
            "        [1.0000],\n",
            "        [0.5000],\n",
            "        [0.0000],\n",
            "        [0.8000],\n",
            "        [0.0000],\n",
            "        [0.6667],\n",
            "        [0.6000],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.2500],\n",
            "        [0.3333],\n",
            "        [0.5000],\n",
            "        [0.2000],\n",
            "        [0.3333],\n",
            "        [0.4000],\n",
            "        [0.3333],\n",
            "        [0.8000],\n",
            "        [0.6000],\n",
            "        [0.7500],\n",
            "        [1.0000],\n",
            "        [0.7500],\n",
            "        [0.6667],\n",
            "        [0.6667],\n",
            "        [0.5000],\n",
            "        [0.8000],\n",
            "        [0.5000],\n",
            "        [0.6000],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.5556],\n",
            "        [0.8889],\n",
            "        [0.6000],\n",
            "        [0.6000],\n",
            "        [0.3333],\n",
            "        [0.4000],\n",
            "        [0.3333],\n",
            "        [0.5000],\n",
            "        [0.4000],\n",
            "        [0.6111],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.6667],\n",
            "        [0.4000],\n",
            "        [0.6000],\n",
            "        [1.0000],\n",
            "        [0.6667],\n",
            "        [0.2500],\n",
            "        [0.8333],\n",
            "        [1.0000],\n",
            "        [0.2500],\n",
            "        [0.0000],\n",
            "        [0.5000],\n",
            "        [0.6667],\n",
            "        [1.0000],\n",
            "        [0.6667],\n",
            "        [0.6000],\n",
            "        [1.0000],\n",
            "        [0.6000],\n",
            "        [0.8333],\n",
            "        [1.0000],\n",
            "        [0.2500],\n",
            "        [1.0000],\n",
            "        [0.7500],\n",
            "        [1.0000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [1.0000],\n",
            "        [0.6667],\n",
            "        [0.3333],\n",
            "        [0.2000],\n",
            "        [0.3333],\n",
            "        [0.2500],\n",
            "        [0.0000],\n",
            "        [0.8000],\n",
            "        [0.6000],\n",
            "        [0.3333],\n",
            "        [0.6000],\n",
            "        [0.2500],\n",
            "        [0.6000],\n",
            "        [0.6000],\n",
            "        [0.2500],\n",
            "        [0.3333],\n",
            "        [0.6000],\n",
            "        [0.2500]])\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]]) tensor([[0.5000],\n",
            "        [0.5000],\n",
            "        [0.4000],\n",
            "        [0.7500],\n",
            "        [0.9444],\n",
            "        [0.6667],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.5000],\n",
            "        [0.8000],\n",
            "        [0.7500],\n",
            "        [0.2500],\n",
            "        [0.7500],\n",
            "        [0.4000],\n",
            "        [0.9000],\n",
            "        [0.2778],\n",
            "        [0.6667],\n",
            "        [0.6000],\n",
            "        [0.6000],\n",
            "        [0.7000],\n",
            "        [1.0000],\n",
            "        [0.0000],\n",
            "        [1.0000],\n",
            "        [0.5000],\n",
            "        [0.4000],\n",
            "        [0.7500],\n",
            "        [0.3333],\n",
            "        [0.6000],\n",
            "        [0.4000],\n",
            "        [0.6000],\n",
            "        [0.6000],\n",
            "        [1.0000],\n",
            "        [0.7778],\n",
            "        [0.8333],\n",
            "        [0.7500],\n",
            "        [1.0000],\n",
            "        [0.0000],\n",
            "        [0.0000],\n",
            "        [0.4000],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.6000],\n",
            "        [0.0000],\n",
            "        [0.3333],\n",
            "        [0.3333],\n",
            "        [0.6000],\n",
            "        [0.4000],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.7000],\n",
            "        [0.4000],\n",
            "        [0.6000],\n",
            "        [0.5000],\n",
            "        [0.3333],\n",
            "        [0.6667],\n",
            "        [1.0000],\n",
            "        [0.7778],\n",
            "        [0.7500],\n",
            "        [0.5000],\n",
            "        [0.4000],\n",
            "        [0.3333],\n",
            "        [0.6000],\n",
            "        [0.6667],\n",
            "        [0.6000],\n",
            "        [0.7500],\n",
            "        [0.7000],\n",
            "        [0.6000],\n",
            "        [0.7000],\n",
            "        [0.7500],\n",
            "        [0.0000],\n",
            "        [0.8000],\n",
            "        [1.0000],\n",
            "        [0.8000],\n",
            "        [0.6667],\n",
            "        [0.4000],\n",
            "        [0.6000],\n",
            "        [0.5000],\n",
            "        [0.3333],\n",
            "        [0.7000],\n",
            "        [0.8000],\n",
            "        [0.2500],\n",
            "        [1.0000],\n",
            "        [0.8000],\n",
            "        [0.7000],\n",
            "        [0.6667],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [1.0000],\n",
            "        [0.2500],\n",
            "        [0.7500],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.6667],\n",
            "        [0.7500],\n",
            "        [0.5000],\n",
            "        [1.0000],\n",
            "        [0.6667],\n",
            "        [0.2500],\n",
            "        [1.0000],\n",
            "        [0.6667],\n",
            "        [1.0000],\n",
            "        [0.6000],\n",
            "        [0.7500],\n",
            "        [1.0000],\n",
            "        [0.7778],\n",
            "        [1.0000],\n",
            "        [0.5000],\n",
            "        [0.0000],\n",
            "        [0.3333],\n",
            "        [0.7778],\n",
            "        [0.2500],\n",
            "        [0.5000],\n",
            "        [0.9444],\n",
            "        [1.0000],\n",
            "        [0.5000],\n",
            "        [0.0000],\n",
            "        [0.8000],\n",
            "        [0.0000],\n",
            "        [0.6667],\n",
            "        [0.6000],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.2500],\n",
            "        [0.3333],\n",
            "        [0.5000],\n",
            "        [0.2000],\n",
            "        [0.3333],\n",
            "        [0.4000],\n",
            "        [0.3333],\n",
            "        [0.8000],\n",
            "        [0.6000],\n",
            "        [0.7500],\n",
            "        [1.0000],\n",
            "        [0.7500],\n",
            "        [0.6667],\n",
            "        [0.6667],\n",
            "        [0.5000],\n",
            "        [0.8000],\n",
            "        [0.5000],\n",
            "        [0.6000],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.5556],\n",
            "        [0.8889],\n",
            "        [0.6000],\n",
            "        [0.6000],\n",
            "        [0.3333],\n",
            "        [0.4000],\n",
            "        [0.3333],\n",
            "        [0.5000],\n",
            "        [0.4000],\n",
            "        [0.6111],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.6667],\n",
            "        [0.4000],\n",
            "        [0.6000],\n",
            "        [1.0000],\n",
            "        [0.6667],\n",
            "        [0.2500],\n",
            "        [0.8333],\n",
            "        [1.0000],\n",
            "        [0.2500],\n",
            "        [0.0000],\n",
            "        [0.5000],\n",
            "        [0.6667],\n",
            "        [1.0000],\n",
            "        [0.6667],\n",
            "        [0.6000],\n",
            "        [1.0000],\n",
            "        [0.6000],\n",
            "        [0.8333],\n",
            "        [1.0000],\n",
            "        [0.2500],\n",
            "        [1.0000],\n",
            "        [0.7500],\n",
            "        [1.0000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [1.0000],\n",
            "        [0.6667],\n",
            "        [0.3333],\n",
            "        [0.2000],\n",
            "        [0.3333],\n",
            "        [0.2500],\n",
            "        [0.0000],\n",
            "        [0.8000],\n",
            "        [0.6000],\n",
            "        [0.3333],\n",
            "        [0.6000],\n",
            "        [0.2500],\n",
            "        [0.6000],\n",
            "        [0.6000],\n",
            "        [0.2500],\n",
            "        [0.3333],\n",
            "        [0.6000],\n",
            "        [0.2500]])\n",
            "Test Loss: 38.3166, Test Accuracy: 0.1960\n"
          ]
        }
      ],
      "source": [
        "# Split the data into training and testing sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "X_test = X_valid\n",
        "y_test = y_valid\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_sizes):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.weights = nn.ParameterList([\n",
        "            nn.Parameter(torch.randn(input_size, hidden_sizes[0]))\n",
        "        ])\n",
        "        self.biases = nn.ParameterList([\n",
        "            nn.Parameter(torch.zeros(hidden_sizes[0]))\n",
        "        ])\n",
        "        for i in range(1, len(hidden_sizes)):\n",
        "            self.weights.append(nn.Parameter(torch.randn(hidden_sizes[i-1], hidden_sizes[i])))\n",
        "            self.biases.append(nn.Parameter(torch.zeros(hidden_sizes[i])))\n",
        "        self.output_layer = nn.Linear(hidden_sizes[-1], 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for weight, bias in zip(self.weights, self.biases):\n",
        "            x = torch.relu(x @ weight + bias)\n",
        "        x = torch.sigmoid(self.output_layer(x))  # Apply sigmoid activation\n",
        "        return x\n",
        "\n",
        "\n",
        "input_size = X_train.shape[1]\n",
        "hidden_sizes = [32, 16]\n",
        "model_neural = NeuralNetwork(input_size, hidden_sizes)\n",
        "\n",
        "\n",
        "criterion = nn.BCELoss()  # Binary Cross Entropy Loss for binary classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    # Forward pass\n",
        "    outputs = model_neural(X_train_tensor)\n",
        "    loss = criterion(outputs, y_train_tensor.view(-1, 1))\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print training loss every epoch\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluate the model_neural on the test set\n",
        "with torch.no_grad():\n",
        "    test_outputs = model_neural(X_test_tensor)\n",
        "    print(\"OUTPUTS : \")\n",
        "    print(test_outputs)\n",
        "    print(\"=\"*80)\n",
        "    print(y_test_tensor.view(-1, 1))\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_outputs = model_neural(X_test_tensor)\n",
        "    test_loss = criterion(test_outputs, y_test_tensor.view(-1, 1))\n",
        "    predictions = (test_outputs >= 0.5).float()  # Threshold at 0.5 for binary classification\n",
        "    accuracy = (predictions == y_test_tensor.view(-1, 1)).float().mean()\n",
        "    print(predictions,y_test_tensor.view(-1, 1))\n",
        "\n",
        "    print(f'Test Loss: {test_loss.item():.4f}, Test Accuracy: {accuracy.item():.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "RgjIThE2ZRvl",
        "outputId": "f9071c41-5633-4ac3-e4c5-117b57f0b521"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[4.9550e+00, 7.1962e+00, 8.9189e-01,  ..., 5.0343e-01, 3.4633e-01,\n",
              "         6.8443e-01],\n",
              "        [5.1207e+00, 6.4337e+00, 8.8793e-01,  ..., 4.8367e-01, 3.6887e-01,\n",
              "         7.8412e-01],\n",
              "        [4.3130e+00, 4.6904e+00, 9.3913e-01,  ..., 2.9255e-01, 3.4610e-01,\n",
              "         5.6525e-01],\n",
              "        ...,\n",
              "        [4.1385e+00, 3.7808e+00, 9.2308e-01,  ..., 2.6674e-01, 3.7786e-01,\n",
              "         4.2808e-01],\n",
              "        [3.8282e+00, 3.3085e+00, 8.4789e-01,  ..., 5.1292e-01, 5.0550e-02,\n",
              "         5.2072e-01],\n",
              "        [5.1304e+00, 5.6352e+00, 8.4783e-01,  ..., 4.9307e-01, 1.0654e-04,\n",
              "         2.4111e-01]])"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "7wHAbEO7ZRvm"
      },
      "outputs": [],
      "source": [
        "def get_final_score(essays, prompt):\n",
        "    main_data = pd.DataFrame()\n",
        "    essays = [essays]\n",
        "    prompt = [prompt]\n",
        "\n",
        "        # coherence_score_nli.append(coherence_score_snli(essays[index]))\n",
        "    # print(type(essays[0]))\n",
        "    means, variances, grammaticals, word_counts, char_counts, coherence_nli = get_mean_score(essays[0]), get_variance_score(essays[0]), get_grammatical_score(essays[0]),get_word_count(essays[0]), get_char_count(essays[0]), coherence_score_snli(essays[0])\n",
        "\n",
        "    val = []\n",
        "    for i in range(1):\n",
        "        val.append(prompt[i]+\".\"+essays[i])\n",
        "\n",
        "\n",
        "    combined_score = model_combined(essays,300).cpu().detach().numpy()\n",
        "\n",
        "\n",
        "    val, lengths_batch = preprocess_essay(val)\n",
        "    val = val.to(device)\n",
        "    essays, lengths_batch = preprocess_essay(essays)\n",
        "    essays = essays.to(device)\n",
        "    out_semantic = model_semantic(essays, lengths_batch)\n",
        "    out_coher = model_coher(essays, lengths_batch)\n",
        "\n",
        "    out_prompt = model_prompt(val, lengths_batch)\n",
        "    out_semantic = out_semantic.cpu().detach().numpy()\n",
        "    out_coher = out_coher.cpu().detach().numpy()\n",
        "    out_prompt = out_prompt.cpu().detach().numpy()\n",
        "\n",
        "    # coherence_nli = coherence_score_nli(essay)\n",
        "    # score_vaibhav = mittal_is_a_model(essay)\n",
        "\n",
        "\n",
        "    # print(\"Shapes before creating DataFrame:\")\n",
        "    # print(\"out_semantic:\", out_semantic)\n",
        "    # print(\"out_coher:\", out_coher)\n",
        "    # print(\"out_prompt:\", out_prompt)\n",
        "    # print(\"combined_score:\", combined_score)\n",
        "    # print(\"coherence_score_nli:\", coherence_nli)\n",
        "    # print(\"normalized_score:\", normalized_score)\n",
        "\n",
        "    main_data = pd.DataFrame()\n",
        "    temp_df = pd.DataFrame({\n",
        "        'means': means,\n",
        "        'variances': variances,\n",
        "        'grammaticals': grammaticals,\n",
        "        'word_counts': word_counts,\n",
        "        'char_counts': char_counts,\n",
        "        'out_semantic': out_semantic[0],\n",
        "        'out_coher': out_coher[0],\n",
        "        'out_prompt': out_prompt[0],\n",
        "        'coherence_nli' : coherence_nli,\n",
        "        'combined_score' : combined_score[0][0],\n",
        "        # 'score_vaibhav' : score_vaibhav,\n",
        "        # 'normalized_score': normalized_score\n",
        "      }, index=[0])\n",
        "\n",
        "    main_data = pd.concat([main_data, temp_df], ignore_index=True)\n",
        "    return main_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6238198825320863\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_qwk(y_true, y_pred, max_rating=10, min_rating=0):\n",
        "    # Construct confusion matrix\n",
        "    conf_mat = np.zeros((max_rating + 1, max_rating + 1))\n",
        "    for a, p in zip(y_true, y_pred):\n",
        "        conf_mat[a][p] += 1\n",
        "\n",
        "    # Compute observed and expected agreement\n",
        "    num_ratings = max_rating - min_rating + 1\n",
        "    O = 0.0\n",
        "    E = 0.0\n",
        "    for i in range(num_ratings):\n",
        "        for j in range(num_ratings):\n",
        "            # Calculate weight\n",
        "            w = ((i - j) ** 2) / ((max_rating - min_rating) ** 2)\n",
        "            O += w * conf_mat[i][j]\n",
        "            E += w * (np.sum(conf_mat[i, :]) * np.sum(conf_mat[:, j])) / np.sum(conf_mat)\n",
        "\n",
        "    # Compute QWK\n",
        "    return 1.0 - O / E\n",
        "\n",
        "# Example usage\n",
        "y_true = np.array(y_valid)\n",
        "y_pred = np.array(y_pred)\n",
        "y_true = np.round(y_true*10).astype(int)\n",
        "y_pred = np.round(y_pred*10).astype(int)\n",
        "\n",
        "\n",
        "print(compute_qwk(y_true, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "pyZsbO4aZRvm",
        "outputId": "af4b6b81-3c76-45a1-82d8-990d5609bb21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>means</th>\n",
              "      <th>variances</th>\n",
              "      <th>grammaticals</th>\n",
              "      <th>word_counts</th>\n",
              "      <th>char_counts</th>\n",
              "      <th>out_semantic</th>\n",
              "      <th>out_coher</th>\n",
              "      <th>out_prompt</th>\n",
              "      <th>coherence_nli</th>\n",
              "      <th>combined_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.126016</td>\n",
              "      <td>4.573551</td>\n",
              "      <td>0.861789</td>\n",
              "      <td>246</td>\n",
              "      <td>1260</td>\n",
              "      <td>0.48984</td>\n",
              "      <td>0.186854</td>\n",
              "      <td>0.008063</td>\n",
              "      <td>0.188973</td>\n",
              "      <td>0.669489</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      means  variances  grammaticals  word_counts  char_counts  out_semantic  \\\n",
              "0  4.126016   4.573551      0.861789          246         1260       0.48984   \n",
              "\n",
              "   out_coher  out_prompt  coherence_nli  combined_score  \n",
              "0   0.186854    0.008063       0.188973        0.669489  "
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "idx = 5\n",
        "ess = custom_df['essay'].iloc[idx]\n",
        "prp = custom_df['prompt'].iloc[idx]\n",
        "\n",
        "# print(ess)\n",
        "# print(prp)\n",
        "output = get_final_score(ess, prp)\n",
        "print(custom_df['normalized_score'].iloc[idx])\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JO2FR5dZRvm",
        "outputId": "9292040c-01b5-42ae-8918-601f153cccb2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>means</th>\n",
              "      <th>variances</th>\n",
              "      <th>grammaticals</th>\n",
              "      <th>word_counts</th>\n",
              "      <th>char_counts</th>\n",
              "      <th>out_semantic</th>\n",
              "      <th>out_coher</th>\n",
              "      <th>out_prompt</th>\n",
              "      <th>coherence_nli</th>\n",
              "      <th>score_combined_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.126016</td>\n",
              "      <td>4.573551</td>\n",
              "      <td>0.861789</td>\n",
              "      <td>246</td>\n",
              "      <td>1260</td>\n",
              "      <td>0.494453</td>\n",
              "      <td>0.498256</td>\n",
              "      <td>0.507619</td>\n",
              "      <td>0.188973</td>\n",
              "      <td>0.663241</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      means  variances  grammaticals  word_counts  char_counts  out_semantic  \\\n",
              "0  4.126016   4.573551      0.861789          246         1260      0.494453   \n",
              "\n",
              "   out_coher  out_prompt  coherence_nli  score_combined_score  \n",
              "0   0.498256    0.507619       0.188973              0.663241  "
            ]
          },
          "execution_count": 189,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "zbyPCR5dZRvn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### COMBINED MODEL 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_combined_2 = final_dataframe[['means', 'variances', 'grammaticals', 'word_counts', 'char_counts', 'out_coher', 'out_prompt', 'combined_score']]\n",
        "y_combined_2 = final_dataframe['normalized_score']\n",
        "\n",
        "X_train_2, X_valid_2, y_train_2, y_valid_2 = train_test_split(X_combined_2, y_combined_2, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\ttrain-rmse:0.24699\tvalid-rmse:0.27920\n",
            "[1]\ttrain-rmse:0.24565\tvalid-rmse:0.27796\n",
            "[2]\ttrain-rmse:0.24434\tvalid-rmse:0.27672\n",
            "[3]\ttrain-rmse:0.24304\tvalid-rmse:0.27551\n",
            "[4]\ttrain-rmse:0.24176\tvalid-rmse:0.27424\n",
            "[5]\ttrain-rmse:0.24050\tvalid-rmse:0.27307\n",
            "[6]\ttrain-rmse:0.23925\tvalid-rmse:0.27179\n",
            "[7]\ttrain-rmse:0.23802\tvalid-rmse:0.27065\n",
            "[8]\ttrain-rmse:0.23681\tvalid-rmse:0.26947\n",
            "[9]\ttrain-rmse:0.23560\tvalid-rmse:0.26828\n",
            "[10]\ttrain-rmse:0.23441\tvalid-rmse:0.26709\n",
            "[11]\ttrain-rmse:0.23323\tvalid-rmse:0.26593\n",
            "[12]\ttrain-rmse:0.23207\tvalid-rmse:0.26476\n",
            "[13]\ttrain-rmse:0.23093\tvalid-rmse:0.26363\n",
            "[14]\ttrain-rmse:0.22980\tvalid-rmse:0.26248\n",
            "[15]\ttrain-rmse:0.22869\tvalid-rmse:0.26137\n",
            "[16]\ttrain-rmse:0.22759\tvalid-rmse:0.26025\n",
            "[17]\ttrain-rmse:0.22651\tvalid-rmse:0.25915\n",
            "[18]\ttrain-rmse:0.22544\tvalid-rmse:0.25808\n",
            "[19]\ttrain-rmse:0.22439\tvalid-rmse:0.25708\n",
            "[20]\ttrain-rmse:0.22336\tvalid-rmse:0.25605\n",
            "[21]\ttrain-rmse:0.22234\tvalid-rmse:0.25503\n",
            "[22]\ttrain-rmse:0.22133\tvalid-rmse:0.25397\n",
            "[23]\ttrain-rmse:0.22033\tvalid-rmse:0.25304\n",
            "[24]\ttrain-rmse:0.21935\tvalid-rmse:0.25205\n",
            "[25]\ttrain-rmse:0.21838\tvalid-rmse:0.25110\n",
            "[26]\ttrain-rmse:0.21743\tvalid-rmse:0.25014\n",
            "[27]\ttrain-rmse:0.21649\tvalid-rmse:0.24924\n",
            "[28]\ttrain-rmse:0.21556\tvalid-rmse:0.24826\n",
            "[29]\ttrain-rmse:0.21464\tvalid-rmse:0.24736\n",
            "[30]\ttrain-rmse:0.21374\tvalid-rmse:0.24643\n",
            "[31]\ttrain-rmse:0.21285\tvalid-rmse:0.24560\n",
            "[32]\ttrain-rmse:0.21196\tvalid-rmse:0.24464\n",
            "[33]\ttrain-rmse:0.21108\tvalid-rmse:0.24383\n",
            "[34]\ttrain-rmse:0.21023\tvalid-rmse:0.24291\n",
            "[35]\ttrain-rmse:0.20938\tvalid-rmse:0.24206\n",
            "[36]\ttrain-rmse:0.20855\tvalid-rmse:0.24123\n",
            "[37]\ttrain-rmse:0.20772\tvalid-rmse:0.24045\n",
            "[38]\ttrain-rmse:0.20691\tvalid-rmse:0.23963\n",
            "[39]\ttrain-rmse:0.20610\tvalid-rmse:0.23885\n",
            "[40]\ttrain-rmse:0.20531\tvalid-rmse:0.23801\n",
            "[41]\ttrain-rmse:0.20452\tvalid-rmse:0.23729\n",
            "[42]\ttrain-rmse:0.20376\tvalid-rmse:0.23651\n",
            "[43]\ttrain-rmse:0.20299\tvalid-rmse:0.23581\n",
            "[44]\ttrain-rmse:0.20225\tvalid-rmse:0.23501\n",
            "[45]\ttrain-rmse:0.20150\tvalid-rmse:0.23433\n",
            "[46]\ttrain-rmse:0.20078\tvalid-rmse:0.23362\n",
            "[47]\ttrain-rmse:0.20006\tvalid-rmse:0.23278\n",
            "[48]\ttrain-rmse:0.19934\tvalid-rmse:0.23209\n",
            "[49]\ttrain-rmse:0.19862\tvalid-rmse:0.23137\n",
            "[50]\ttrain-rmse:0.19792\tvalid-rmse:0.23072\n",
            "[51]\ttrain-rmse:0.19724\tvalid-rmse:0.23004\n",
            "[52]\ttrain-rmse:0.19656\tvalid-rmse:0.22944\n",
            "[53]\ttrain-rmse:0.19588\tvalid-rmse:0.22881\n",
            "[54]\ttrain-rmse:0.19523\tvalid-rmse:0.22816\n",
            "[55]\ttrain-rmse:0.19456\tvalid-rmse:0.22754\n",
            "[56]\ttrain-rmse:0.19393\tvalid-rmse:0.22695\n",
            "[57]\ttrain-rmse:0.19330\tvalid-rmse:0.22628\n",
            "[58]\ttrain-rmse:0.19268\tvalid-rmse:0.22571\n",
            "[59]\ttrain-rmse:0.19205\tvalid-rmse:0.22509\n",
            "[60]\ttrain-rmse:0.19144\tvalid-rmse:0.22454\n",
            "[61]\ttrain-rmse:0.19085\tvalid-rmse:0.22398\n",
            "[62]\ttrain-rmse:0.19024\tvalid-rmse:0.22339\n",
            "[63]\ttrain-rmse:0.18966\tvalid-rmse:0.22280\n",
            "[64]\ttrain-rmse:0.18909\tvalid-rmse:0.22224\n",
            "[65]\ttrain-rmse:0.18852\tvalid-rmse:0.22164\n",
            "[66]\ttrain-rmse:0.18795\tvalid-rmse:0.22110\n",
            "[67]\ttrain-rmse:0.18740\tvalid-rmse:0.22064\n",
            "[68]\ttrain-rmse:0.18686\tvalid-rmse:0.22012\n",
            "[69]\ttrain-rmse:0.18631\tvalid-rmse:0.21959\n",
            "[70]\ttrain-rmse:0.18578\tvalid-rmse:0.21902\n",
            "[71]\ttrain-rmse:0.18526\tvalid-rmse:0.21851\n",
            "[72]\ttrain-rmse:0.18475\tvalid-rmse:0.21799\n",
            "[73]\ttrain-rmse:0.18423\tvalid-rmse:0.21749\n",
            "[74]\ttrain-rmse:0.18373\tvalid-rmse:0.21698\n",
            "[75]\ttrain-rmse:0.18324\tvalid-rmse:0.21654\n",
            "[76]\ttrain-rmse:0.18273\tvalid-rmse:0.21604\n",
            "[77]\ttrain-rmse:0.18226\tvalid-rmse:0.21554\n",
            "[78]\ttrain-rmse:0.18177\tvalid-rmse:0.21508\n",
            "[79]\ttrain-rmse:0.18124\tvalid-rmse:0.21489\n",
            "[80]\ttrain-rmse:0.18068\tvalid-rmse:0.21478\n",
            "[81]\ttrain-rmse:0.18021\tvalid-rmse:0.21432\n",
            "[82]\ttrain-rmse:0.17967\tvalid-rmse:0.21421\n",
            "[83]\ttrain-rmse:0.17913\tvalid-rmse:0.21412\n",
            "[84]\ttrain-rmse:0.17870\tvalid-rmse:0.21368\n",
            "[85]\ttrain-rmse:0.17818\tvalid-rmse:0.21360\n",
            "[86]\ttrain-rmse:0.17775\tvalid-rmse:0.21319\n",
            "[87]\ttrain-rmse:0.17724\tvalid-rmse:0.21312\n",
            "[88]\ttrain-rmse:0.17682\tvalid-rmse:0.21275\n",
            "[89]\ttrain-rmse:0.17633\tvalid-rmse:0.21269\n",
            "[90]\ttrain-rmse:0.17590\tvalid-rmse:0.21230\n",
            "[91]\ttrain-rmse:0.17542\tvalid-rmse:0.21225\n",
            "[92]\ttrain-rmse:0.17494\tvalid-rmse:0.21222\n",
            "[93]\ttrain-rmse:0.17455\tvalid-rmse:0.21179\n",
            "[94]\ttrain-rmse:0.17409\tvalid-rmse:0.21176\n",
            "[95]\ttrain-rmse:0.17369\tvalid-rmse:0.21139\n",
            "[96]\ttrain-rmse:0.17324\tvalid-rmse:0.21137\n",
            "[97]\ttrain-rmse:0.17279\tvalid-rmse:0.21136\n",
            "[98]\ttrain-rmse:0.17243\tvalid-rmse:0.21101\n",
            "[99]\ttrain-rmse:0.17199\tvalid-rmse:0.21100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pchhl\\anaconda3\\lib\\site-packages\\xgboost\\core.py:726: FutureWarning: Pass `evals` as keyword args.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "dtrain_2 = xgb.DMatrix(X_train_2, label=y_train_2)\n",
        "dvalid_2 = xgb.DMatrix(X_valid_2, label=y_valid_2)\n",
        "\n",
        "param = {\n",
        "    'max_depth': 3,\n",
        "    'eta': 0.01,\n",
        "    'objective': 'reg:squarederror'\n",
        "}\n",
        "num_round = 100\n",
        "\n",
        "bst_2 = xgb.train(param, dtrain_2, num_round, [(dtrain_2, 'train'), (dvalid_2, 'valid')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pchhl\\anaconda3\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [22:46:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07f6e447eee219473-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ],
      "source": [
        "model_path_2 = 'xgboost_combined_2.pth'\n",
        "bst_2.save_model(model_path_2)\n",
        "\n",
        "# Load the model later\n",
        "loaded_model_2 = xgb.Booster()\n",
        "loaded_model_2.load_model(model_path_2)\n",
        "\n",
        "# Now you can use the loaded_model for predictions\n",
        "dpredict_2 = xgb.DMatrix(X_valid_2)\n",
        "predictions_2 = loaded_model_2.predict(dpredict_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.47211623, 0.65657955, 0.49490345, 0.61460227, 0.6082697 ,\n",
              "       0.7605865 , 0.3573508 , 0.50391567, 0.50992835, 0.50992835,\n",
              "       0.67913187, 0.60893893, 0.75849617, 0.60893893, 0.6288318 ,\n",
              "       0.7605865 , 0.7438693 , 0.61460227, 0.51894057, 0.7099762 ,\n",
              "       0.60893893, 0.62316847, 0.53608507, 0.67786807, 0.6074012 ,\n",
              "       0.6586952 , 0.60980743, 0.40012643, 0.72505605, 0.74022835,\n",
              "       0.630301  , 0.75849617, 0.6375021 , 0.53608507, 0.7080497 ,\n",
              "       0.57049096, 0.62316847, 0.50992835, 0.50992835, 0.74022835,\n",
              "       0.60893893, 0.60893893, 0.51894057, 0.5698185 , 0.60893893,\n",
              "       0.50992835, 0.57171386, 0.43939218, 0.6717061 , 0.39257175,\n",
              "       0.3573508 , 0.61614   , 0.52106017, 0.61614   , 0.62316847,\n",
              "       0.7051462 , 0.6226902 , 0.36454338, 0.50992835, 0.75849617,\n",
              "       0.65657955, 0.6630562 , 0.6586952 , 0.37356657, 0.7600468 ,\n",
              "       0.530264  , 0.7099762 , 0.42266962, 0.7543361 , 0.49490345,\n",
              "       0.61614   , 0.51894057, 0.60980743, 0.43939218, 0.6586952 ,\n",
              "       0.50992835, 0.6014705 ], dtype=float32)"
            ]
          },
          "execution_count": 245,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.49744998038446453\n"
          ]
        }
      ],
      "source": [
        "y_true = np.array(y_valid_2)\n",
        "y_pred = np.array(predictions_2)\n",
        "y_true = np.round(y_true*10).astype(int)\n",
        "y_pred = np.round(y_pred*10).astype(int)\n",
        "\n",
        "\n",
        "print(compute_qwk(y_true, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### COMBINED MODEL 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_combined_3 = final_dataframe[[ 'out_semantic', 'out_coher', 'out_prompt', 'combined_score', 'coherence_score_nli', 'ranks']]\n",
        "y_combined_3 = final_dataframe['normalized_score']\n",
        "\n",
        "X_train_3, X_valid_3, y_train_3, y_valid_3 = train_test_split(X_combined_3, y_combined_3, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\ttrain-rmse:0.24700\tvalid-rmse:0.27911\n",
            "[1]\ttrain-rmse:0.24567\tvalid-rmse:0.27778\n",
            "[2]\ttrain-rmse:0.24436\tvalid-rmse:0.27645\n",
            "[3]\ttrain-rmse:0.24306\tvalid-rmse:0.27516\n",
            "[4]\ttrain-rmse:0.24179\tvalid-rmse:0.27387\n",
            "[5]\ttrain-rmse:0.24053\tvalid-rmse:0.27261\n",
            "[6]\ttrain-rmse:0.23929\tvalid-rmse:0.27135\n",
            "[7]\ttrain-rmse:0.23807\tvalid-rmse:0.27017\n",
            "[8]\ttrain-rmse:0.23686\tvalid-rmse:0.26889\n",
            "[9]\ttrain-rmse:0.23565\tvalid-rmse:0.26773\n",
            "[10]\ttrain-rmse:0.23445\tvalid-rmse:0.26652\n",
            "[11]\ttrain-rmse:0.23327\tvalid-rmse:0.26534\n",
            "[12]\ttrain-rmse:0.23210\tvalid-rmse:0.26418\n",
            "[13]\ttrain-rmse:0.23095\tvalid-rmse:0.26302\n",
            "[14]\ttrain-rmse:0.22981\tvalid-rmse:0.26184\n",
            "[15]\ttrain-rmse:0.22869\tvalid-rmse:0.26072\n",
            "[16]\ttrain-rmse:0.22759\tvalid-rmse:0.25966\n",
            "[17]\ttrain-rmse:0.22649\tvalid-rmse:0.25853\n",
            "[18]\ttrain-rmse:0.22542\tvalid-rmse:0.25749\n",
            "[19]\ttrain-rmse:0.22436\tvalid-rmse:0.25639\n",
            "[20]\ttrain-rmse:0.22332\tvalid-rmse:0.25539\n",
            "[21]\ttrain-rmse:0.22228\tvalid-rmse:0.25432\n",
            "[22]\ttrain-rmse:0.22127\tvalid-rmse:0.25333\n",
            "[23]\ttrain-rmse:0.22026\tvalid-rmse:0.25228\n",
            "[24]\ttrain-rmse:0.21928\tvalid-rmse:0.25127\n",
            "[25]\ttrain-rmse:0.21830\tvalid-rmse:0.25033\n",
            "[26]\ttrain-rmse:0.21734\tvalid-rmse:0.24932\n",
            "[27]\ttrain-rmse:0.21639\tvalid-rmse:0.24845\n",
            "[28]\ttrain-rmse:0.21546\tvalid-rmse:0.24747\n",
            "[29]\ttrain-rmse:0.21454\tvalid-rmse:0.24654\n",
            "[30]\ttrain-rmse:0.21363\tvalid-rmse:0.24565\n",
            "[31]\ttrain-rmse:0.21273\tvalid-rmse:0.24471\n",
            "[32]\ttrain-rmse:0.21185\tvalid-rmse:0.24385\n",
            "[33]\ttrain-rmse:0.21098\tvalid-rmse:0.24289\n",
            "[34]\ttrain-rmse:0.21012\tvalid-rmse:0.24206\n",
            "[35]\ttrain-rmse:0.20927\tvalid-rmse:0.24113\n",
            "[36]\ttrain-rmse:0.20844\tvalid-rmse:0.24032\n",
            "[37]\ttrain-rmse:0.20762\tvalid-rmse:0.23941\n",
            "[38]\ttrain-rmse:0.20680\tvalid-rmse:0.23858\n",
            "[39]\ttrain-rmse:0.20600\tvalid-rmse:0.23770\n",
            "[40]\ttrain-rmse:0.20522\tvalid-rmse:0.23688\n",
            "[41]\ttrain-rmse:0.20444\tvalid-rmse:0.23612\n",
            "[42]\ttrain-rmse:0.20367\tvalid-rmse:0.23526\n",
            "[43]\ttrain-rmse:0.20291\tvalid-rmse:0.23453\n",
            "[44]\ttrain-rmse:0.20217\tvalid-rmse:0.23376\n",
            "[45]\ttrain-rmse:0.20143\tvalid-rmse:0.23299\n",
            "[46]\ttrain-rmse:0.20071\tvalid-rmse:0.23229\n",
            "[47]\ttrain-rmse:0.19999\tvalid-rmse:0.23157\n",
            "[48]\ttrain-rmse:0.19928\tvalid-rmse:0.23088\n",
            "[49]\ttrain-rmse:0.19858\tvalid-rmse:0.23021\n",
            "[50]\ttrain-rmse:0.19789\tvalid-rmse:0.22955\n",
            "[51]\ttrain-rmse:0.19721\tvalid-rmse:0.22887\n",
            "[52]\ttrain-rmse:0.19655\tvalid-rmse:0.22814\n",
            "[53]\ttrain-rmse:0.19589\tvalid-rmse:0.22746\n",
            "[54]\ttrain-rmse:0.19524\tvalid-rmse:0.22685\n",
            "[55]\ttrain-rmse:0.19460\tvalid-rmse:0.22618\n",
            "[56]\ttrain-rmse:0.19396\tvalid-rmse:0.22556\n",
            "[57]\ttrain-rmse:0.19334\tvalid-rmse:0.22496\n",
            "[58]\ttrain-rmse:0.19273\tvalid-rmse:0.22428\n",
            "[59]\ttrain-rmse:0.19212\tvalid-rmse:0.22370\n",
            "[60]\ttrain-rmse:0.19152\tvalid-rmse:0.22309\n",
            "[61]\ttrain-rmse:0.19093\tvalid-rmse:0.22249\n",
            "[62]\ttrain-rmse:0.19034\tvalid-rmse:0.22188\n",
            "[63]\ttrain-rmse:0.18977\tvalid-rmse:0.22129\n",
            "[64]\ttrain-rmse:0.18921\tvalid-rmse:0.22074\n",
            "[65]\ttrain-rmse:0.18865\tvalid-rmse:0.22016\n",
            "[66]\ttrain-rmse:0.18810\tvalid-rmse:0.21955\n",
            "[67]\ttrain-rmse:0.18757\tvalid-rmse:0.21908\n",
            "[68]\ttrain-rmse:0.18703\tvalid-rmse:0.21854\n",
            "[69]\ttrain-rmse:0.18649\tvalid-rmse:0.21799\n",
            "[70]\ttrain-rmse:0.18597\tvalid-rmse:0.21740\n",
            "[71]\ttrain-rmse:0.18545\tvalid-rmse:0.21694\n",
            "[72]\ttrain-rmse:0.18495\tvalid-rmse:0.21655\n",
            "[73]\ttrain-rmse:0.18441\tvalid-rmse:0.21601\n",
            "[74]\ttrain-rmse:0.18393\tvalid-rmse:0.21561\n",
            "[75]\ttrain-rmse:0.18340\tvalid-rmse:0.21510\n",
            "[76]\ttrain-rmse:0.18293\tvalid-rmse:0.21460\n",
            "[77]\ttrain-rmse:0.18241\tvalid-rmse:0.21406\n",
            "[78]\ttrain-rmse:0.18194\tvalid-rmse:0.21362\n",
            "[79]\ttrain-rmse:0.18149\tvalid-rmse:0.21324\n",
            "[80]\ttrain-rmse:0.18099\tvalid-rmse:0.21272\n",
            "[81]\ttrain-rmse:0.18053\tvalid-rmse:0.21222\n",
            "[82]\ttrain-rmse:0.18005\tvalid-rmse:0.21171\n",
            "[83]\ttrain-rmse:0.17958\tvalid-rmse:0.21120\n",
            "[84]\ttrain-rmse:0.17914\tvalid-rmse:0.21073\n",
            "[85]\ttrain-rmse:0.17871\tvalid-rmse:0.21038\n",
            "[86]\ttrain-rmse:0.17826\tvalid-rmse:0.20992\n",
            "[87]\ttrain-rmse:0.17785\tvalid-rmse:0.20959\n",
            "[88]\ttrain-rmse:0.17740\tvalid-rmse:0.20912\n",
            "[89]\ttrain-rmse:0.17699\tvalid-rmse:0.20869\n",
            "[90]\ttrain-rmse:0.17659\tvalid-rmse:0.20830\n",
            "[91]\ttrain-rmse:0.17616\tvalid-rmse:0.20791\n",
            "[92]\ttrain-rmse:0.17574\tvalid-rmse:0.20747\n",
            "[93]\ttrain-rmse:0.17536\tvalid-rmse:0.20726\n",
            "[94]\ttrain-rmse:0.17499\tvalid-rmse:0.20701\n",
            "[95]\ttrain-rmse:0.17458\tvalid-rmse:0.20658\n",
            "[96]\ttrain-rmse:0.17422\tvalid-rmse:0.20631\n",
            "[97]\ttrain-rmse:0.17382\tvalid-rmse:0.20592\n",
            "[98]\ttrain-rmse:0.17346\tvalid-rmse:0.20559\n",
            "[99]\ttrain-rmse:0.17310\tvalid-rmse:0.20540\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pchhl\\anaconda3\\lib\\site-packages\\xgboost\\core.py:726: FutureWarning: Pass `evals` as keyword args.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "dtrain_3 = xgb.DMatrix(X_train_3, label=y_train_3)\n",
        "dvalid_3 = xgb.DMatrix(X_valid_3, label=y_valid_3)\n",
        "\n",
        "param = {\n",
        "    'max_depth': 3,\n",
        "    'eta': 0.01,\n",
        "    'objective': 'reg:squarederror'\n",
        "}\n",
        "num_round = 100\n",
        "\n",
        "bst_3 = xgb.train(param, dtrain_3, num_round, [(dtrain_3, 'train'), (dvalid_3, 'valid')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pchhl\\anaconda3\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [22:46:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07f6e447eee219473-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ],
      "source": [
        "model_path_3 = 'xgboost_combined_3.pth'\n",
        "bst_3.save_model(model_path_3)\n",
        "\n",
        "# Load the model later\n",
        "loaded_model_3 = xgb.Booster()\n",
        "loaded_model_3.load_model(model_path_3)\n",
        "\n",
        "# Now you can use the loaded_model for predictions\n",
        "dpredict_3 = xgb.DMatrix(X_valid_3)\n",
        "predictions_3 = loaded_model_3.predict(dpredict_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5486859519757987\n"
          ]
        }
      ],
      "source": [
        "y_true = np.array(y_valid_3)\n",
        "y_pred = np.array(predictions_3)\n",
        "y_true = np.round(y_true*10).astype(int)\n",
        "y_pred = np.round(y_pred*10).astype(int)\n",
        "\n",
        "\n",
        "print(compute_qwk(y_true, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### COMBINED MODEL 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_combined_4 = final_dataframe[[ 'out_prompt', 'combined_score', 'coherence_score_nli', 'ranks']]\n",
        "y_combined_4 = final_dataframe['normalized_score']\n",
        "\n",
        "X_train_4, X_valid_4, y_train_4, y_valid_4 = train_test_split(X_combined_4, y_combined_4, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\ttrain-rmse:0.24700\tvalid-rmse:0.27911\n",
            "[1]\ttrain-rmse:0.24567\tvalid-rmse:0.27778\n",
            "[2]\ttrain-rmse:0.24436\tvalid-rmse:0.27645\n",
            "[3]\ttrain-rmse:0.24306\tvalid-rmse:0.27516\n",
            "[4]\ttrain-rmse:0.24179\tvalid-rmse:0.27387\n",
            "[5]\ttrain-rmse:0.24053\tvalid-rmse:0.27261\n",
            "[6]\ttrain-rmse:0.23929\tvalid-rmse:0.27135\n",
            "[7]\ttrain-rmse:0.23807\tvalid-rmse:0.27017\n",
            "[8]\ttrain-rmse:0.23686\tvalid-rmse:0.26889\n",
            "[9]\ttrain-rmse:0.23565\tvalid-rmse:0.26773\n",
            "[10]\ttrain-rmse:0.23445\tvalid-rmse:0.26652\n",
            "[11]\ttrain-rmse:0.23327\tvalid-rmse:0.26534\n",
            "[12]\ttrain-rmse:0.23210\tvalid-rmse:0.26418\n",
            "[13]\ttrain-rmse:0.23095\tvalid-rmse:0.26302\n",
            "[14]\ttrain-rmse:0.22981\tvalid-rmse:0.26184\n",
            "[15]\ttrain-rmse:0.22869\tvalid-rmse:0.26072\n",
            "[16]\ttrain-rmse:0.22759\tvalid-rmse:0.25966\n",
            "[17]\ttrain-rmse:0.22649\tvalid-rmse:0.25853\n",
            "[18]\ttrain-rmse:0.22542\tvalid-rmse:0.25749\n",
            "[19]\ttrain-rmse:0.22436\tvalid-rmse:0.25639\n",
            "[20]\ttrain-rmse:0.22332\tvalid-rmse:0.25539\n",
            "[21]\ttrain-rmse:0.22228\tvalid-rmse:0.25432\n",
            "[22]\ttrain-rmse:0.22127\tvalid-rmse:0.25329\n",
            "[23]\ttrain-rmse:0.22026\tvalid-rmse:0.25224\n",
            "[24]\ttrain-rmse:0.21928\tvalid-rmse:0.25123\n",
            "[25]\ttrain-rmse:0.21830\tvalid-rmse:0.25029\n",
            "[26]\ttrain-rmse:0.21734\tvalid-rmse:0.24928\n",
            "[27]\ttrain-rmse:0.21639\tvalid-rmse:0.24838\n",
            "[28]\ttrain-rmse:0.21546\tvalid-rmse:0.24740\n",
            "[29]\ttrain-rmse:0.21454\tvalid-rmse:0.24646\n",
            "[30]\ttrain-rmse:0.21362\tvalid-rmse:0.24551\n",
            "[31]\ttrain-rmse:0.21273\tvalid-rmse:0.24465\n",
            "[32]\ttrain-rmse:0.21185\tvalid-rmse:0.24373\n",
            "[33]\ttrain-rmse:0.21098\tvalid-rmse:0.24283\n",
            "[34]\ttrain-rmse:0.21012\tvalid-rmse:0.24205\n",
            "[35]\ttrain-rmse:0.20928\tvalid-rmse:0.24112\n",
            "[36]\ttrain-rmse:0.20845\tvalid-rmse:0.24027\n",
            "[37]\ttrain-rmse:0.20762\tvalid-rmse:0.23936\n",
            "[38]\ttrain-rmse:0.20681\tvalid-rmse:0.23853\n",
            "[39]\ttrain-rmse:0.20601\tvalid-rmse:0.23765\n",
            "[40]\ttrain-rmse:0.20522\tvalid-rmse:0.23683\n",
            "[41]\ttrain-rmse:0.20445\tvalid-rmse:0.23603\n",
            "[42]\ttrain-rmse:0.20368\tvalid-rmse:0.23517\n",
            "[43]\ttrain-rmse:0.20292\tvalid-rmse:0.23435\n",
            "[44]\ttrain-rmse:0.20218\tvalid-rmse:0.23363\n",
            "[45]\ttrain-rmse:0.20144\tvalid-rmse:0.23282\n",
            "[46]\ttrain-rmse:0.20072\tvalid-rmse:0.23213\n",
            "[47]\ttrain-rmse:0.20000\tvalid-rmse:0.23137\n",
            "[48]\ttrain-rmse:0.19929\tvalid-rmse:0.23065\n",
            "[49]\ttrain-rmse:0.19860\tvalid-rmse:0.22990\n",
            "[50]\ttrain-rmse:0.19791\tvalid-rmse:0.22920\n",
            "[51]\ttrain-rmse:0.19723\tvalid-rmse:0.22849\n",
            "[52]\ttrain-rmse:0.19657\tvalid-rmse:0.22780\n",
            "[53]\ttrain-rmse:0.19591\tvalid-rmse:0.22710\n",
            "[54]\ttrain-rmse:0.19527\tvalid-rmse:0.22639\n",
            "[55]\ttrain-rmse:0.19463\tvalid-rmse:0.22570\n",
            "[56]\ttrain-rmse:0.19400\tvalid-rmse:0.22505\n",
            "[57]\ttrain-rmse:0.19338\tvalid-rmse:0.22445\n",
            "[58]\ttrain-rmse:0.19276\tvalid-rmse:0.22378\n",
            "[59]\ttrain-rmse:0.19216\tvalid-rmse:0.22316\n",
            "[60]\ttrain-rmse:0.19157\tvalid-rmse:0.22253\n",
            "[61]\ttrain-rmse:0.19097\tvalid-rmse:0.22192\n",
            "[62]\ttrain-rmse:0.19039\tvalid-rmse:0.22132\n",
            "[63]\ttrain-rmse:0.18982\tvalid-rmse:0.22073\n",
            "[64]\ttrain-rmse:0.18926\tvalid-rmse:0.22015\n",
            "[65]\ttrain-rmse:0.18870\tvalid-rmse:0.21958\n",
            "[66]\ttrain-rmse:0.18816\tvalid-rmse:0.21897\n",
            "[67]\ttrain-rmse:0.18762\tvalid-rmse:0.21837\n",
            "[68]\ttrain-rmse:0.18709\tvalid-rmse:0.21780\n",
            "[69]\ttrain-rmse:0.18657\tvalid-rmse:0.21730\n",
            "[70]\ttrain-rmse:0.18605\tvalid-rmse:0.21672\n",
            "[71]\ttrain-rmse:0.18554\tvalid-rmse:0.21615\n",
            "[72]\ttrain-rmse:0.18504\tvalid-rmse:0.21562\n",
            "[73]\ttrain-rmse:0.18453\tvalid-rmse:0.21510\n",
            "[74]\ttrain-rmse:0.18402\tvalid-rmse:0.21453\n",
            "[75]\ttrain-rmse:0.18352\tvalid-rmse:0.21394\n",
            "[76]\ttrain-rmse:0.18304\tvalid-rmse:0.21347\n",
            "[77]\ttrain-rmse:0.18257\tvalid-rmse:0.21315\n",
            "[78]\ttrain-rmse:0.18211\tvalid-rmse:0.21282\n",
            "[79]\ttrain-rmse:0.18163\tvalid-rmse:0.21224\n",
            "[80]\ttrain-rmse:0.18115\tvalid-rmse:0.21167\n",
            "[81]\ttrain-rmse:0.18070\tvalid-rmse:0.21137\n",
            "[82]\ttrain-rmse:0.18024\tvalid-rmse:0.21082\n",
            "[83]\ttrain-rmse:0.17980\tvalid-rmse:0.21034\n",
            "[84]\ttrain-rmse:0.17937\tvalid-rmse:0.21006\n",
            "[85]\ttrain-rmse:0.17893\tvalid-rmse:0.20952\n",
            "[86]\ttrain-rmse:0.17851\tvalid-rmse:0.20926\n",
            "[87]\ttrain-rmse:0.17808\tvalid-rmse:0.20874\n",
            "[88]\ttrain-rmse:0.17768\tvalid-rmse:0.20845\n",
            "[89]\ttrain-rmse:0.17725\tvalid-rmse:0.20796\n",
            "[90]\ttrain-rmse:0.17684\tvalid-rmse:0.20747\n",
            "[91]\ttrain-rmse:0.17644\tvalid-rmse:0.20707\n",
            "[92]\ttrain-rmse:0.17604\tvalid-rmse:0.20658\n",
            "[93]\ttrain-rmse:0.17566\tvalid-rmse:0.20634\n",
            "[94]\ttrain-rmse:0.17528\tvalid-rmse:0.20592\n",
            "[95]\ttrain-rmse:0.17491\tvalid-rmse:0.20569\n",
            "[96]\ttrain-rmse:0.17453\tvalid-rmse:0.20524\n",
            "[97]\ttrain-rmse:0.17417\tvalid-rmse:0.20504\n",
            "[98]\ttrain-rmse:0.17380\tvalid-rmse:0.20459\n",
            "[99]\ttrain-rmse:0.17340\tvalid-rmse:0.20421\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pchhl\\anaconda3\\lib\\site-packages\\xgboost\\core.py:726: FutureWarning: Pass `evals` as keyword args.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "dtrain_4 = xgb.DMatrix(X_train_4, label=y_train_3)\n",
        "dvalid_4 = xgb.DMatrix(X_valid_4, label=y_valid_3)\n",
        "\n",
        "param = {\n",
        "    'max_depth': 3,\n",
        "    'eta': 0.01,\n",
        "    'objective': 'reg:squarederror'\n",
        "}\n",
        "num_round = 100\n",
        "\n",
        "bst_4 = xgb.train(param, dtrain_4, num_round, [(dtrain_4, 'train'), (dvalid_4, 'valid')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 268,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pchhl\\anaconda3\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [22:49:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07f6e447eee219473-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ],
      "source": [
        "model_path_4 = 'xgboost_combined_4.pth'\n",
        "bst_4.save_model(model_path_4)\n",
        "\n",
        "# Load the model later\n",
        "loaded_model_4 = xgb.Booster()\n",
        "loaded_model_4.load_model(model_path_4)\n",
        "\n",
        "# Now you can use the loaded_model for predictions\n",
        "dpredict_4 = xgb.DMatrix(X_valid_4)\n",
        "predictions_4 = loaded_model_4.predict(dpredict_4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5486859519757987\n"
          ]
        }
      ],
      "source": [
        "y_true = np.array(y_valid_4)\n",
        "y_pred = np.array(predictions_4)\n",
        "y_true = np.round(y_true*10).astype(int)\n",
        "y_pred = np.round(y_pred*10).astype(int)\n",
        "\n",
        "\n",
        "print(compute_qwk(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Score : 5 -> Real Score :  5.0\n",
            "Predicted Score : 5 -> Real Score :  4.0\n",
            "Predicted Score : 7 -> Real Score :  7.0\n",
            "Predicted Score : 5 -> Real Score :  5.0\n",
            "Predicted Score : 8 -> Real Score :  8.0\n",
            "Predicted Score : 7 -> Real Score :  7.0\n",
            "Predicted Score : 6 -> Real Score :  6.0\n",
            "Predicted Score : 5 -> Real Score :  6.0\n",
            "Predicted Score : 7 -> Real Score :  7.0\n",
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 6 -> Real Score :  6.0\n",
            "Predicted Score : 7 -> Real Score :  8.0\n",
            "Predicted Score : 5 -> Real Score :  4.0\n",
            "Predicted Score : 6 -> Real Score :  6.0\n",
            "Predicted Score : 5 -> Real Score :  6.0\n",
            "Predicted Score : 5 -> Real Score :  4.0\n",
            "Predicted Score : 4 -> Real Score :  4.0\n",
            "Predicted Score : 6 -> Real Score :  6.0\n",
            "Predicted Score : 5 -> Real Score :  5.0\n",
            "Predicted Score : 6 -> Real Score :  7.0\n",
            "Predicted Score : 5 -> Real Score :  5.0\n",
            "Predicted Score : 7 -> Real Score :  6.0\n",
            "Predicted Score : 6 -> Real Score :  7.0\n",
            "Predicted Score : 8 -> Real Score :  8.0\n",
            "Predicted Score : 7 -> Real Score :  6.0\n",
            "Predicted Score : 8 -> Real Score :  8.0\n",
            "Predicted Score : 5 -> Real Score :  6.0\n",
            "Predicted Score : 5 -> Real Score :  5.0\n"
          ]
        }
      ],
      "source": [
        "y_true = np.array(y_valid)\n",
        "y_pred = np.array(y_pred)\n",
        "count=0\n",
        "for i in range(len(y_pred)):\n",
        "    print(f\"Predicted Score : {y_pred[i]} -> Real Score :  {np.round(y_true[i]*10)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
